diff --git a/ARCHITECTURE-mapping-engine.md b/ARCHITECTURE-mapping-engine.md
new file mode 100644
index 0000000..675c554
--- /dev/null
+++ b/ARCHITECTURE-mapping-engine.md
@@ -0,0 +1,511 @@
+# Mapping Engine Architecture
+
+**Version:** 1.0.0
+**Date:** 2026-01-12
+**Purpose:** Technical architecture for the cross-platform template conversion system
+
+---
+
+## Overview
+
+The Mapping Engine transforms templates written in the Standard Schema (superset format) into native formats for Claude Code, Windsurf, and GitHub Copilot. It implements a plugin-based adapter architecture that enables extensibility for future platforms.
+
+**Key Design Principles:**
+
+1. **Deterministic Transformation** - Same input always produces same output
+2. **Graceful Degradation** - Emit warnings for unsupported features instead of failing
+3. **Plugin Architecture** - Platform adapters are pluggable components
+4. **Clear Separation** - Parse → Validate → Transform → Generate pipeline
+
+---
+
+## Component Diagram
+
+```
+┌─────────────────────────────────────────────────────────────────────────────┐
+│                              MAPPING ENGINE                                  │
+├─────────────────────────────────────────────────────────────────────────────┤
+│                                                                             │
+│  ┌──────────────┐     ┌──────────────┐     ┌──────────────────────────┐   │
+│  │              │     │              │     │    Platform Adapters     │   │
+│  │    Parser    │────▶│   Validator  │────▶│                          │   │
+│  │              │     │              │     │  ┌────────────────────┐  │   │
+│  │  gray-matter │     │  Schema      │     │  │ Claude Code Adapter│  │   │
+│  │  extraction  │     │  Validation  │     │  ├────────────────────┤  │   │
+│  │              │     │              │     │  │ Windsurf Adapter   │  │   │
+│  └──────────────┘     └──────────────┘     │  ├────────────────────┤  │   │
+│         │                    │              │  │ Copilot Adapter    │  │   │
+│         │                    │              │  └────────────────────┘  │   │
+│         ▼                    ▼              │            │             │   │
+│  ┌──────────────────────────────────────┐  │            ▼             │   │
+│  │           ParsedTemplate             │  │  ┌────────────────────┐  │   │
+│  │  ┌─────────────┐ ┌────────────────┐  │  │  │  File Generator    │  │   │
+│  │  │  metadata   │ │    content     │  │──│  │                    │  │   │
+│  │  │  (YAML)     │ │   (Markdown)   │  │  │  │  Platform-specific │  │   │
+│  │  └─────────────┘ └────────────────┘  │  │  │  output files      │  │   │
+│  └──────────────────────────────────────┘  │  └────────────────────┘  │   │
+│                                            └──────────────────────────┘   │
+│                                                                             │
+├─────────────────────────────────────────────────────────────────────────────┤
+│                           Emulation Layer                                   │
+│  ┌─────────────────────────────────────────────────────────────────────┐   │
+│  │  • Skill Emulation (Windsurf)     • Permission Emulation            │   │
+│  │  • Workflow Emulation (Claude)    • Context Isolation Emulation     │   │
+│  │  • Working Set Batching (Copilot) • Hook-to-Instruction Conversion  │   │
+│  └─────────────────────────────────────────────────────────────────────┘   │
+└─────────────────────────────────────────────────────────────────────────────┘
+```
+
+---
+
+## Data Flow
+
+```
+┌─────────────────┐
+│  Input Template │
+│  (.md file)     │
+└────────┬────────┘
+         │
+         ▼
+┌─────────────────────────────────────────────────────────────────────┐
+│                    1. PARSE STAGE                                    │
+│  ┌─────────────────────────────────────────────────────────────┐    │
+│  │  • Extract YAML frontmatter using gray-matter library       │    │
+│  │  • Parse YAML to TemplateMetadata object                    │    │
+│  │  • Extract markdown body as content string                  │    │
+│  │  • Handle parse errors with descriptive messages            │    │
+│  └─────────────────────────────────────────────────────────────┘    │
+└────────┬────────────────────────────────────────────────────────────┘
+         │
+         ▼
+┌─────────────────┐
+│ ParsedTemplate  │
+│ {metadata,      │
+│  content,       │
+│  sourcePath}    │
+└────────┬────────┘
+         │
+         ▼
+┌─────────────────────────────────────────────────────────────────────┐
+│                    2. VALIDATE STAGE                                 │
+│  ┌─────────────────────────────────────────────────────────────┐    │
+│  │  • Check schema compliance against STANDARD-SCHEMA.md       │    │
+│  │  • Validate required fields (name for Claude Code, etc.)    │    │
+│  │  • Check platform compatibility markers                     │    │
+│  │  • Verify field values (trigger types, model names, etc.)   │    │
+│  │  • Generate validation warnings/errors                      │    │
+│  └─────────────────────────────────────────────────────────────┘    │
+└────────┬────────────────────────────────────────────────────────────┘
+         │
+         ▼
+┌─────────────────────────────────────────────────────────────────────┐
+│                    3. TRANSFORM STAGE                                │
+│  ┌─────────────────────────────────────────────────────────────┐    │
+│  │  For each target platform:                                  │    │
+│  │    • Select appropriate platform adapter                    │    │
+│  │    • Map superset fields to platform-native fields          │    │
+│  │    • Drop unsupported/platform-specific fields              │    │
+│  │    • Generate transformation warnings                       │    │
+│  └─────────────────────────────────────────────────────────────┘    │
+└────────┬────────────────────────────────────────────────────────────┘
+         │
+         ▼
+┌─────────────────────────────────────────────────────────────────────┐
+│                    4. EMULATE STAGE                                  │
+│  ┌─────────────────────────────────────────────────────────────┐    │
+│  │  Apply workaround patterns from WORKAROUND-PATTERNS.md:     │    │
+│  │                                                             │    │
+│  │  Claude Code:                                               │    │
+│  │    • Convert trigger: model_decision → skill description    │    │
+│  │    • Convert multi-file globs → explicit Read instructions  │    │
+│  │                                                             │    │
+│  │  Windsurf:                                                  │    │
+│  │    • Convert allowed-tools → Advisory Instructions section  │    │
+│  │    • Convert context: fork → Context Markers                │    │
+│  │    • Convert agent → Persona Rules file                     │    │
+│  │    • Convert permissions → Glob-triggered warning rules     │    │
+│  │    • Convert hooks → Manual workflow steps                  │    │
+│  │                                                             │    │
+│  │  GitHub Copilot:                                            │    │
+│  │    • Convert allowed-tools → Constraints section            │    │
+│  │    • Convert context: fork → Batch Execution Protocol       │    │
+│  │    • Convert agent → Inline Persona section                 │    │
+│  │    • Add Working Set Advisory if >10 files                  │    │
+│  │    • Add Context Window warning if >4000 chars              │    │
+│  └─────────────────────────────────────────────────────────────┘    │
+└────────┬────────────────────────────────────────────────────────────┘
+         │
+         ▼
+┌─────────────────────────────────────────────────────────────────────┐
+│                    5. GENERATE STAGE                                 │
+│  ┌─────────────────────────────────────────────────────────────┐    │
+│  │  Generate platform-specific output files:                   │    │
+│  │                                                             │    │
+│  │  Claude Code:                                               │    │
+│  │    • .claude/skills/{name}/SKILL.md                        │    │
+│  │    • .claude/settings.json (if permissions)                │    │
+│  │    • .claude/agents/{agent}.md (if agent reference)        │    │
+│  │                                                             │    │
+│  │  Windsurf:                                                  │    │
+│  │    • .windsurf/workflows/{name}.md                         │    │
+│  │    • .windsurf/rules/agent-{agent}.md (if agent)           │    │
+│  │    • .windsurf/rules/permissions-{name}.md (if permissions)│    │
+│  │                                                             │    │
+│  │  GitHub Copilot:                                            │    │
+│  │    • .github/prompts/{name}.prompt.md                      │    │
+│  │    • .github/instructions/{name}.instructions.md           │    │
+│  │    • .github/copilot-instructions.md (if alwaysApply)      │    │
+│  └─────────────────────────────────────────────────────────────┘    │
+└────────┬────────────────────────────────────────────────────────────┘
+         │
+         ▼
+┌───────────────────────────┐
+│    ConversionResult       │
+│  {                        │
+│    sourcePath,            │
+│    template,              │
+│    results: Map<Platform, │
+│      TransformationResult>│
+│    allWarnings,           │
+│    success                │
+│  }                        │
+└───────────────────────────┘
+```
+
+---
+
+## Module Structure
+
+```
+packages/cli/src/lib/template-mapper/
+├── index.ts                    # Public API exports
+├── types.ts                    # Type definitions (TemplateMetadata, etc.)
+├── parser.ts                   # YAML frontmatter + markdown parser
+├── validator.ts                # Schema validation
+├── engine.ts                   # MappingEngine implementation
+├── emulation/                  # Emulation pattern implementations
+│   ├── index.ts
+│   ├── skill-emulation.ts      # Skill → Windsurf workflow
+│   ├── workflow-emulation.ts   # Workflow → Claude Code skill
+│   └── working-set.ts          # Copilot batching patterns
+└── adapters/                   # Platform-specific adapters
+    ├── index.ts
+    ├── claude-code.ts          # Claude Code adapter
+    ├── windsurf.ts             # Windsurf adapter
+    └── github-copilot.ts       # GitHub Copilot adapter
+```
+
+---
+
+## Key Components
+
+### 1. Parser (`parser.ts`)
+
+**Responsibilities:**
+- Extract YAML frontmatter from markdown files using `gray-matter` library
+- Parse YAML to strongly-typed `TemplateMetadata` object
+- Handle malformed YAML with descriptive error messages
+- Extract markdown body content as string
+
+**Interface:**
+```typescript
+export function parseTemplate(filePath: string): Promise<ParsedTemplate>
+export function parseTemplateString(content: string): ParsedTemplate
+```
+
+**Error Handling:**
+- Invalid YAML syntax → `ParseError` with line/column info
+- Missing frontmatter delimiters → `ParseError` with suggestion
+- File not found → `FileNotFoundError`
+
+### 2. Validator (`validator.ts`)
+
+**Responsibilities:**
+- Validate metadata against STANDARD-SCHEMA.md specification
+- Check required fields per platform
+- Validate field values (enums, patterns)
+- Generate validation issues with suggestions
+
+**Interface:**
+```typescript
+export function validateSchema(metadata: TemplateMetadata): ValidationIssue[]
+export function validateForPlatform(metadata: TemplateMetadata, platform: Platform): ValidationIssue[]
+```
+
+**Validation Rules:**
+- `name`: Required for Claude Code, max 64 chars, alphanumeric + hyphens/underscores
+- `description`: Max 500 chars recommended
+- `trigger`: Must be one of: manual, always_on, model_decision, glob
+- `globs`: Required when trigger is 'glob'
+- `allowed-tools`: Must be valid Claude Code tool names
+- `model`: Must be valid model identifier for target platform
+
+### 3. Platform Adapters
+
+Each adapter implements the `PlatformAdapter` interface:
+
+```typescript
+interface PlatformAdapter {
+  readonly platform: Platform
+  transform(template: ParsedTemplate, options?: TransformOptions): TransformationResult
+  validate(template: ParsedTemplate): TransformationWarning[]
+  getOutputPath(template: ParsedTemplate): string
+}
+```
+
+#### Claude Code Adapter (`adapters/claude-code.ts`)
+
+**Field Mapping (per PLATFORM-ADAPTERS.md Section 1.1):**
+| Superset Field | Claude Code Field | Action |
+|----------------|-------------------|--------|
+| name | name | Direct copy |
+| description | description | Direct copy |
+| version | version | Direct copy |
+| allowed-tools | allowed-tools | Direct copy |
+| model | model | Direct copy |
+| context | context | Direct copy |
+| agent | agent | Direct copy |
+| permissions | settings.json | Merge into project settings |
+| trigger | *(dropped)* | Windsurf-only |
+| globs | *(dropped)* | Windsurf-only |
+| applyTo | *(dropped)* | Copilot-only |
+
+**Output Files:**
+- Main: `.claude/skills/{name}/SKILL.md`
+- Settings: `.claude/settings.json` (merged, if permissions specified)
+- Agent: `.claude/agents/{agent}.md` (if agent reference exists)
+
+#### Windsurf Adapter (`adapters/windsurf.ts`)
+
+**Field Mapping (per PLATFORM-ADAPTERS.md Section 2.1):**
+| Superset Field | Windsurf Field | Action |
+|----------------|----------------|--------|
+| name | *(filename)* | Use as filename |
+| description | description | Direct copy |
+| trigger | trigger | Direct copy |
+| globs | globs | Direct copy |
+| labels | labels | Direct copy |
+| alwaysApply | alwaysApply | Direct copy |
+| allowed-tools | *(emulated)* | → Advisory Instructions |
+| context | *(emulated)* | → Context Markers |
+| agent | *(emulated)* | → Persona Rules file |
+| permissions | *(emulated)* | → Glob-triggered warnings |
+
+**Emulation Patterns Applied:**
+1. Tool restrictions → "## Tool Restrictions (Advisory)" section
+2. Context isolation → "[CONTEXT: Isolated Execution]" markers
+3. Custom agents → `.windsurf/rules/agent-{name}.md` companion file
+4. Permissions → `.windsurf/rules/permissions-{name}.md` companion file
+
+**Output Files:**
+- Main: `.windsurf/workflows/{name}.md`
+- Agent: `.windsurf/rules/agent-{agent}.md` (if agent)
+- Permissions: `.windsurf/rules/permissions-{name}.md` (if permissions)
+
+**Character Limit Handling:**
+- Check output length against 12,000 char limit
+- If exceeded, split at markdown heading boundaries
+- Generate continuation files: `{name}-part-2.md`, etc.
+
+#### GitHub Copilot Adapter (`adapters/github-copilot.ts`)
+
+**Field Mapping (per PLATFORM-ADAPTERS.md Section 3.1):**
+| Superset Field | Copilot Field | Action |
+|----------------|---------------|--------|
+| name | *(filename)* | Use as filename |
+| description | description | Direct copy |
+| applyTo | applyTo | Direct copy (normalize to array) |
+| excludeAgent | excludeAgent | Direct copy (normalize to array) |
+| mode | mode | Direct copy |
+| globs | applyTo | Convert |
+| allowed-tools | *(emulated)* | → Constraints section |
+| context | *(emulated)* | → Batch Protocol |
+| agent | *(emulated)* | → Inline Persona |
+
+**Limit Warnings:**
+- Working set: Warn if template may touch >10 files
+- Context: Warn if body >4000 chars
+- Add batching guidance for large operations
+
+**Output Files:**
+- Main: `.github/prompts/{name}.prompt.md`
+- Instructions: `.github/instructions/{name}.instructions.md` (if applyTo)
+- Global: `.github/copilot-instructions.md` (if alwaysApply)
+
+### 4. Mapping Engine (`engine.ts`)
+
+**Responsibilities:**
+- Orchestrate the full conversion pipeline
+- Manage adapter registry
+- Coordinate parse → validate → transform → generate flow
+- Aggregate results and warnings
+
+**Interface:**
+```typescript
+class MappingEngineImpl implements MappingEngine {
+  parse(filePath: string, options?: ParseOptions): Promise<ParsedTemplate>
+  parseString(content: string, options?: ParseOptions): ParsedTemplate
+  convert(template: ParsedTemplate | string, options?: TransformOptions): Promise<ConversionResult>
+  getAdapter(platform: Platform): PlatformAdapter
+  registerAdapter(adapter: PlatformAdapter): void
+}
+
+export function createMappingEngine(): MappingEngine
+```
+
+---
+
+## Error Handling Strategy
+
+### Error Categories
+
+1. **Parse Errors** - Invalid YAML, missing delimiters
+   - Return descriptive error with line/column
+   - Suggest common fixes
+
+2. **Validation Errors** - Schema violations
+   - Collect all issues before failing
+   - Provide field-level suggestions
+
+3. **Transformation Errors** - Adapter failures
+   - Fail gracefully with error in result
+   - Continue processing other platforms
+
+4. **File System Errors** - I/O issues
+   - Clear error messages with paths
+   - Suggest permission fixes
+
+### Warning vs Error Policy
+
+| Situation | Response |
+|-----------|----------|
+| Missing required field | Error (strict mode) or Warning |
+| Unknown field | Warning (may be future field) |
+| Unsupported feature | Warning + emulation |
+| Platform limit exceeded | Warning + guidance |
+| Advisory-only security | Warning + documentation |
+
+---
+
+## Extension Points
+
+### Adding New Platforms
+
+1. Create adapter file: `adapters/{platform}.ts`
+2. Implement `PlatformAdapter` interface
+3. Register with engine: `engine.registerAdapter(new NewPlatformAdapter())`
+4. Add platform to `Platform` type and `PLATFORMS` constant
+
+### Adding New Emulation Patterns
+
+1. Create pattern file: `emulation/{pattern-name}.ts`
+2. Export pattern application function
+3. Import and call from relevant adapter(s)
+4. Document pattern in WORKAROUND-PATTERNS.md
+
+### Custom Validators
+
+1. Implement `SchemaValidator` interface
+2. Register with engine configuration
+3. Validators chain: base → platform-specific → custom
+
+---
+
+## CLI Integration
+
+The mapping engine integrates with the CLI via the `convert` command:
+
+```
+aiwcli convert <source> --to <platform> [options]
+
+Arguments:
+  source              Path to template file or directory
+
+Options:
+  --to, -t <platform> Target platform(s): claude-code, windsurf, github-copilot
+  --output, -o <dir>  Output directory (default: current directory)
+  --strict            Fail on any incompatibility
+  --dry-run           Show what would be generated without writing files
+  --verbose           Show detailed transformation logs
+```
+
+**Command Flow:**
+1. Parse `--to` argument to determine target platforms
+2. Load and parse source template
+3. Call `engine.convert()` with options
+4. Display warnings and results
+5. Write output files (unless `--dry-run`)
+
+---
+
+## Testing Strategy
+
+### Unit Tests
+
+- **Parser Tests:** Valid input, invalid YAML, missing fields, edge cases
+- **Validator Tests:** Each validation rule, field constraints
+- **Adapter Tests:** Field mapping, emulation patterns, output structure
+- **Engine Tests:** Pipeline orchestration, multi-platform conversion
+
+### Integration Tests
+
+- **End-to-End:** Convert example templates, verify output
+- **Round-Trip:** Standard → Claude Code → verify format
+- **Cross-Platform:** Same template to all platforms, compare outputs
+
+### Test Data
+
+- Use templates from `examples/` directory
+- Create fixtures for edge cases
+- Test with actual skill/workflow files from Phase 3
+
+---
+
+## Dependencies
+
+**Required:**
+- `gray-matter` - YAML frontmatter parsing
+- `js-yaml` (via gray-matter) - YAML parsing
+
+**Already in project:**
+- `@oclif/core` - CLI framework
+- `chalk` - Output coloring
+- TypeScript - Type safety
+
+---
+
+## Security Considerations
+
+1. **File Path Validation** - Prevent path traversal attacks
+2. **Output Sanitization** - No user input in generated code paths
+3. **Permission Warnings** - Clearly document advisory-only security
+4. **No Code Execution** - Parser doesn't execute template content
+
+---
+
+## Performance Considerations
+
+1. **Lazy Loading** - Adapters loaded on demand
+2. **Streaming** - For large files, stream content
+3. **Caching** - Cache parsed templates if converting multiple times
+4. **Parallel Processing** - Convert to multiple platforms concurrently
+
+---
+
+## Future Enhancements
+
+1. **Watch Mode** - Auto-convert on file changes
+2. **Reverse Conversion** - Platform-native → Standard format
+3. **Template Marketplace** - Share/discover templates
+4. **IDE Extensions** - VSCode/Windsurf/Cursor integrations
+5. **Validation Web UI** - Browser-based template validator
+
+---
+
+## Sources
+
+- STANDARD-SCHEMA.md - Superset schema specification
+- STANDARD-STRUCTURE.md - Directory layout conventions
+- PLATFORM-ADAPTERS.md - Transformation rules
+- WORKAROUND-PATTERNS.md - Emulation patterns
+- GAP-ANALYSIS.md - Capability gaps documentation
diff --git a/CONTENT-SCHEMA.md b/CONTENT-SCHEMA.md
new file mode 100644
index 0000000..676f510
--- /dev/null
+++ b/CONTENT-SCHEMA.md
@@ -0,0 +1,586 @@
+# Content Schema: Semantic Constructs for Cross-Platform Transformation
+
+**Version:** 1.0.0
+**Date:** 2026-01-12
+**Purpose:** Define all semantic constructs appearing in workflow/skill content that require transformation between AI assistant platforms (Claude Code, Windsurf, GitHub Copilot)
+
+---
+
+## Overview
+
+This schema defines semantic constructs found in the markdown body of workflows and skills that contain platform-specific syntax. Unlike YAML frontmatter metadata (handled by Phase 4), these constructs appear in the actual instructional content and become nonsensical when viewed on platforms that lack the referenced capabilities.
+
+**Scope:**
+- Markdown content body (not frontmatter)
+- Platform-specific syntax and references
+- Constructs that require transformation or advisory notes
+
+**Detection Guidelines:**
+- Skip constructs inside fenced code blocks (```...```)
+- Apply transformations only to instructional prose
+- Preserve original semantics through platform-appropriate equivalents
+
+---
+
+## Construct Categories
+
+1. **Agent & Execution** - Subagent spawning, context management
+2. **Tool & Permission** - Tool calls, restrictions, allowed operations
+3. **Activation & Invocation** - Triggers, manual invocation guidance
+4. **Context & Discovery** - Multi-file context, glob patterns
+5. **Workflow Orchestration** - Skill chaining, progress tracking
+
+---
+
+# Construct: agent-spawn
+
+## Description
+References to spawning, creating, or delegating work to subagents or separate execution contexts. This includes references to the Task tool, agent forking, and parallel execution patterns.
+
+## Source Platform
+**claude-code** - Native subagent spawning via Task tool and `context: fork`
+
+## Detection Pattern
+```regex
+(?i)(spawn\s+agent|subagent|Task\s+tool|context:\s*fork|parallel\s+agent|delegate\s+to\s+agent|isolated\s+context|separate\s+context|spawn\s+a?\s*(new\s+)?agent)
+```
+
+## Examples
+- Example 1: `spawn agent to handle security review` (from WORKAROUND-PATTERNS.md, Pattern 1)
+- Example 2: `Cannot spawn parallel isolated contexts` (from WORKAROUND-PATTERNS.md, Known Limitations)
+- Example 3: `Via Task tool with subagent_type parameter` (from RESEARCH-claude-code.md, Section 4)
+- Example 4: `Via context: fork in skill frontmatter` (from RESEARCH-claude-code.md)
+
+## Transformation Notes
+- **To Windsurf:** Add advisory note: "Subagent spawning not supported. Execute sequentially in single Cascade session."
+- **To Copilot:** Add advisory note: "Subagent execution not available. Process as sequential workflow steps."
+- Replace "spawn agent" with "execute the following steps" or similar sequential phrasing
+
+---
+
+# Construct: tool-call
+
+## Description
+Explicit references to using specific tools by name, including the tool invocation syntax patterns. These references guide the AI on which tools to use for specific operations.
+
+## Source Platform
+**claude-code** - Rich tool ecosystem with explicit tool names
+
+## Detection Pattern
+```regex
+(?i)(use\s+(the\s+)?(Read|Write|Edit|Grep|Glob|Bash|Task|WebFetch|WebSearch|AskUserQuestion)\s+tool|call\s+(the\s+)?(Read|Write|Edit|Grep|Glob|Bash|Task)\s+tool|(Read|Write|Edit|Grep|Glob|Bash)\s*\(|run\s+(Read|Grep|Glob))
+```
+
+## Examples
+- Example 1: `Use Glob to discover files before Reading them` (from WORKAROUND-PATTERNS.md, Pattern 2)
+- Example 2: `AI uses Glob to scan for *.test.ts files` (from examples/skill-example.md)
+- Example 3: `Glob: src/api/**/*.ts` (from WORKAROUND-PATTERNS.md, Step 0 protocol)
+- Example 4: `Grep: pattern="query|findMany" path="src/"` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- **To Windsurf:** Rephrase as action descriptions: "Search for files matching..." instead of "Use Glob tool"
+- **To Copilot:** Keep generic tool references but clarify as recommendations: "Search for" or "Read" without specific tool names
+- Preserve semantic intent while removing platform-specific tool syntax
+
+---
+
+# Construct: context-switch
+
+## Description
+References to context management including forking contexts, inheriting parent context, or creating isolated execution environments. Controls how conversation history and state flow between operations.
+
+## Source Platform
+**claude-code** - Native context control via `context: fork` and `context: inherit`
+
+## Detection Pattern
+```regex
+(?i)(context:\s*(fork|inherit)|fork\s+context|inherit\s+context|isolated\s+context|separate\s+context|context\s+isolation|context\s+window|fresh\s+context|clean\s+context|shared\s+context)
+```
+
+## Examples
+- Example 1: `This workflow uses inherited context (normal Cascade session)` (from WORKAROUND-PATTERNS.md, Windsurf adaptation)
+- Example 2: `context: fork can only be simulated with markers` (from WORKAROUND-PATTERNS.md, Known Limitations)
+- Example 3: `Using context: inherit means skill runs in main session` (from examples/workflow-example.md)
+- Example 4: `Separate context window` (from RESEARCH-claude-code.md, Agent Types)
+
+## Transformation Notes
+- **To Windsurf:** Replace with execution context explanation: "Executes in current Cascade session (no isolation available)"
+- **To Copilot:** Remove context references entirely; Copilot has no equivalent concept
+- Add notes explaining what context isolation would have provided
+
+---
+
+# Construct: permission-reference
+
+## Description
+References to tool restrictions, allowed/forbidden operations, and permission boundaries. Includes both enforced permissions (Claude Code) and advisory restrictions (other platforms).
+
+## Source Platform
+**claude-code** - Enforced via `allowed-tools` and permissions.allow/deny
+
+## Detection Pattern
+```regex
+(?i)(allowed[- ]?tools|forbidden\s+operations|tool\s+restrictions?|permission\s+restrictions?|not\s+allowed|allow(ed)?:\s*-|deny:\s*-|before\s+using\s+tools\s+outside|rely\s+on\s+AI\s+compliance|advisory\s+(only|restrictions?)|cannot\s+be\s+enforced)
+```
+
+## Examples
+- Example 1: `Tool Restrictions (Advisory) - NOTE: These restrictions rely on AI compliance and are NOT enforced by Windsurf` (from WORKAROUND-PATTERNS.md, Skill Emulation)
+- Example 2: `Forbidden Operations: - File editing - Non-git shell commands` (from WORKAROUND-PATTERNS.md)
+- Example 3: `allowed-tools: - Read - Grep - Bash(npm audit)` (from WORKAROUND-PATTERNS.md)
+- Example 4: `Before using tools outside this list, ask user for permission` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- **To Windsurf:** Add header "Tool Restrictions (Advisory)" with warning that restrictions are not enforced
+- **To Copilot:** Add section "Operational Constraints" with recommendation language
+- Always clarify enforcement level on each platform
+
+---
+
+# Construct: model-decision-trigger
+
+## Description
+References to AI-driven activation patterns where the model decides when to activate a workflow based on context and description matching. Includes "USE WHEN" patterns and trigger descriptions.
+
+## Source Platform
+**windsurf** - Native via `trigger: model_decision` and description-based matching
+
+## Detection Pattern
+```regex
+(?i)(USE\s+WHEN|trigger:\s*model_decision|model\s+decision|AI\s+determines|AI\s+decides|automatically\s+activates?|activates?\s+automatically|auto-?activation|activate\s+when\s+user\s+mentions|Cascade['s]?\s+(model\s+decision|determines))
+```
+
+## Examples
+- Example 1: `USE WHEN creating git commits. Helps write conventional commit messages.` (from WORKAROUND-PATTERNS.md)
+- Example 2: `trigger: model_decision - AI decides when to apply` (from RESEARCH-windsurf.md)
+- Example 3: `Windsurf's AI determines commit creation is relevant` (from WORKAROUND-PATTERNS.md)
+- Example 4: `This workflow activates automatically when: - User mentions "commit"` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- **To Claude Code:** Convert to rich description with trigger keywords; add "Invocation command: /skill-name" section
+- **To Copilot:** Add "When to use this prompt" section with explicit guidance
+- Always provide manual invocation fallback for platforms without model decision
+
+---
+
+# Construct: glob-pattern
+
+## Description
+Multi-file context references using glob patterns that specify which files should be loaded or considered during workflow execution. Includes both frontmatter patterns and inline references.
+
+## Source Platform
+**windsurf** - Native via `globs:` frontmatter for automatic multi-file context
+
+## Detection Pattern
+```regex
+(?i)(globs?:\s*\[|globs?:\s*-\s*["\']|matching\s+glob|glob\s+pattern|\*\*/\*\.(ts|tsx|js|jsx|py|md)|src/\*\*/|files?\s+matching\s+["\']?\*|applyTo:\s*\[)
+```
+
+## Examples
+- Example 1: `globs: - "src/components/**/*.tsx" - "src/components/**/*.ts"` (from WORKAROUND-PATTERNS.md)
+- Example 2: `Windsurf automatically loads all files matching glob patterns into context` (from WORKAROUND-PATTERNS.md)
+- Example 3: `Scan for test files matching *.test.ts or *.spec.ts` (from examples/skill-example.md)
+- Example 4: `applyTo: - "**/*.test.ts" - "**/*.spec.ts"` (from examples/skill-example.md)
+
+## Transformation Notes
+- **To Claude Code:** Add "Step 0: Multi-File Context Acquisition" section with Glob tool calls
+- **To Copilot:** Add `applyTo:` in frontmatter and note working set limits
+- Convert automatic context loading to explicit discovery steps
+
+---
+
+# Construct: persona-rule
+
+## Description
+References to custom agent personas, specialized behavioral profiles, or role-based instructions that modify how the AI operates during workflow execution.
+
+## Source Platform
+**windsurf** - Via `@rules:agent-{name}` activation in manual trigger rules
+
+## Detection Pattern
+```regex
+(?i)(@rules:agent-|agent\s+persona|persona\s+rule|security[-\s]specialist|specialized\s+agent|adopt\s+this\s+persona|behavioral\s+guidelines|specialized\s+.*\s+agent|agent[:\s]+[a-z-]+|custom\s+agent)
+```
+
+## Examples
+- Example 1: `@rules:agent-security-specialist` (from WORKAROUND-PATTERNS.md)
+- Example 2: `When @rules:agent-security-specialist is active, adopt this persona` (from WORKAROUND-PATTERNS.md)
+- Example 3: `agent: security-specialist` in skill frontmatter (from WORKAROUND-PATTERNS.md)
+- Example 4: `Activate with: @rules:agent-security-specialist before running this workflow` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- **To Claude Code:** Reference via `agent:` frontmatter field; agent definitions in `.claude/agents/`
+- **To Copilot:** Embed persona instructions directly in prompt body; no external agent files
+- Always include full persona definition inline for platforms without external agent support
+
+---
+
+# Construct: skill-chaining
+
+## Description
+References to invoking other skills, prompts, or workflows from within a workflow. Includes sequential execution patterns, "Part X of Y" decomposition, and cross-references to related skills.
+
+## Source Platform
+**github-copilot** - Pattern for working set limitation via sequential prompt chaining
+
+## Detection Pattern
+```regex
+(?i)(/prompt\s+[a-z-]+|Part\s+\d+\s+(of|→)\s+\d+|Proceed\s+to\s+Part\s+\d+|Next\s+Steps.*Part\s+\d+|→\s*Part\s+\d+|skill\s+chaining|invoke.*skill|chain.*skills?|/[a-z-]+\s*$|execute.*prompt)
+```
+
+## Examples
+- Example 1: `Proceed to Part 2: /prompt refactor-auth-api` (from examples/copilot-limited-context.md)
+- Example 2: `Part 1 of 4: Core Authentication Module` (from WORKAROUND-PATTERNS.md)
+- Example 3: `/prompt refactor-database-core` (from examples/copilot-limited-context.md)
+- Example 4: `Part 1 → Directs to Part 2` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- **To Claude Code:** Convert to skill invocations: `/skill-name` or reference within description
+- **To Windsurf:** Convert to workflow invocations: `/workflow-name` or use @rules references
+- Maintain clear sequencing instructions across all platforms
+
+---
+
+# Construct: context-gathering-protocol
+
+## Description
+Explicit instructions for gathering file context before beginning analysis or modification. Includes Step 0 protocols, context checklists, and multi-file discovery patterns.
+
+## Source Platform
+**claude-code** - Emulation pattern for Windsurf's automatic multi-file context
+
+## Detection Pattern
+```regex
+(?i)(Step\s+0|Context\s+Gathering\s+Protocol|Multi-?File\s+Context\s+Acquisition|Context\s+Checklist|gather.*context|context\s+gathering|before\s+beginning.*gather|comprehensive\s+context|Only\s+proceed.*context)
+```
+
+## Examples
+- Example 1: `### Step 0: Multi-File Context Acquisition` (from WORKAROUND-PATTERNS.md)
+- Example 2: `Context Checklist: - [ ] All API routes identified - [ ] Middleware files loaded` (from WORKAROUND-PATTERNS.md)
+- Example 3: `IMPORTANT: Before beginning refactoring analysis, gather comprehensive context` (from examples/workflow-example.md)
+- Example 4: `Only proceed to analysis once context gathering is complete` (from examples/workflow-example.md)
+
+## Transformation Notes
+- **To Windsurf:** Remove Step 0; context is automatic via `globs:` frontmatter
+- **To Copilot:** Keep Step 0 but limit file counts per working set (max 10)
+- Include checklist format for verification across all platforms
+
+---
+
+# Construct: activation-instruction
+
+## Description
+Guidance on when and how to invoke a skill, workflow, or prompt. Includes manual invocation commands, trigger conditions, and user action requirements.
+
+## Source Platform
+**All platforms** - Universal pattern with platform-specific syntax
+
+## Detection Pattern
+```regex
+(?i)(Manual\s+invocation|Invocation.*command|/[a-z-]+\s*$|When\s+to\s+invoke|invoke\s+this\s+skill|invoke\s+with|user\s+must.*invoke|explicitly\s+invoke|Activation\s+Instructions|Manual\s+Trigger)
+```
+
+## Examples
+- Example 1: `Manual invocation: /commit-helper` (from WORKAROUND-PATTERNS.md)
+- Example 2: `Invocation command: /optimize-api-performance` (from WORKAROUND-PATTERNS.md)
+- Example 3: `When to invoke this skill: Use when user mentions "optimize API performance"` (from WORKAROUND-PATTERNS.md)
+- Example 4: `User can also explicitly invoke: /commit-helper` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- **To Claude Code:** Use `/skill-name` format
+- **To Windsurf:** Use `/workflow-name` format
+- **To Copilot:** Use `/prompt name` or reference file directly
+
+---
+
+# Construct: working-set-limit
+
+## Description
+References to file count limitations, working set constraints, and strategies for handling operations that exceed platform limits.
+
+## Source Platform
+**github-copilot** - 10-file working set limit, 20-file context awareness limit
+
+## Detection Pattern
+```regex
+(?i)(working\s+set|10[-\s]file\s+limit|file\s+limit|working\s+set\s+limit|≤?\s*10\s+files?|batch.*files?|file\s+prioritization|exceeds?.*limit|within.*limit)
+```
+
+## Examples
+- Example 1: `GitHub Copilot's 10-file working set limit` (from examples/copilot-limited-context.md)
+- Example 2: `Working Set (8 files):` (from WORKAROUND-PATTERNS.md)
+- Example 3: `each ≤10 files` (from WORKAROUND-PATTERNS.md)
+- Example 4: `This exceeds the ideal 10-file limit` (from examples/copilot-limited-context.md)
+
+## Transformation Notes
+- **To Claude Code:** Remove limit references; no explicit working set constraint
+- **To Windsurf:** Remove limit references; Windsurf handles larger context automatically
+- Keep file counts for planning purposes but remove constraint language
+
+---
+
+# Construct: checkpoint-commit
+
+## Description
+Instructions for creating intermediate commits as checkpoints during multi-part operations. Enables rollback and verification between workflow phases.
+
+## Source Platform
+**github-copilot** - Pattern for multi-part workflow coordination
+
+## Detection Pattern
+```regex
+(?i)(checkpoint|create\s+commit|Checkpoint\s*:|commit\s+after|Step\s+\d+:\s*Checkpoint|git\s+commit.*refactor|rollback\s+plan|checkpoint\s+commit)
+```
+
+## Examples
+- Example 1: `Step 5: Checkpoint - Create commit: refactor(auth): part 1 - standardize core auth module` (from WORKAROUND-PATTERNS.md)
+- Example 2: `Checkpoint Commits - Part 1: [commit hash]` (from examples/copilot-limited-context.md)
+- Example 3: `Each batch creates checkpoint commit` (from WORKAROUND-PATTERNS.md)
+- Example 4: `Rollback Plan: If integration issues discovered...` (from examples/copilot-limited-context.md)
+
+## Transformation Notes
+- Universal pattern; keep checkpoint instructions across all platforms
+- Valuable for multi-step operations regardless of platform
+- Adjust commit message conventions per project standards
+
+---
+
+# Construct: progress-tracking
+
+## Description
+References to tracking workflow progress across multi-part operations, including progress files, completion checklists, and status indicators.
+
+## Source Platform
+**github-copilot** - Pattern for multi-part workflow coordination
+
+## Detection Pattern
+```regex
+(?i)(REFACTOR-PROGRESS\.md|Progress\s+Tracking|Completion\s+Checklist|\[\s*[xX ]?\s*\].*completed?|progress\s+file|track.*progress|current\s+part|Status:)
+```
+
+## Examples
+- Example 1: `Create REFACTOR-PROGRESS.md to track completion` (from WORKAROUND-PATTERNS.md)
+- Example 2: `Progress Tracking: - [ ] Part 1: Core module` (from examples/copilot-limited-context.md)
+- Example 3: `Completion Checklist: - [ ] All 28 files refactored` (from examples/copilot-limited-context.md)
+- Example 4: `Current part: [1/2/3/4]` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- Universal pattern; useful for complex operations on all platforms
+- Keep checklist format for verification
+- Consider platform-native alternatives (GitHub Issues, project management tools)
+
+---
+
+# Construct: workspace-command
+
+## Description
+References to the @workspace command for codebase-wide discovery and analysis, particularly in GitHub Copilot contexts.
+
+## Source Platform
+**github-copilot** - Native @workspace for codebase search
+
+## Detection Pattern
+```regex
+(?i)(@workspace|@workspace\s+analyze|@workspace\s+find|@workspace\s+show|workspace\s+search|use\s+@workspace)
+```
+
+## Examples
+- Example 1: `@workspace analyze database access patterns` (from examples/copilot-limited-context.md)
+- Example 2: `@workspace find all files that import from src/database/` (from WORKAROUND-PATTERNS.md)
+- Example 3: `Use @workspace when: - You need to SEARCH/ANALYZE many files` (from WORKAROUND-PATTERNS.md)
+- Example 4: `@workspace for discovery, decomposition for implementation` (from examples/copilot-limited-context.md)
+
+## Transformation Notes
+- **To Claude Code:** Convert to Grep/Glob tool usage with explicit patterns
+- **To Windsurf:** Use natural language search in Cascade or glob patterns
+- Explain that @workspace is for discovery, not modification
+
+---
+
+# Construct: test-command
+
+## Description
+References to running tests, including npm test commands, verification steps, and test result expectations.
+
+## Source Platform
+**All platforms** - Universal pattern for test execution
+
+## Detection Pattern
+```regex
+(?i)(npm\s+test|npm\s+run\s+test|run\s+tests?|test\s+suite|verify.*tests?|tests?\s+pass|pytest|jest|mocha|vitest)
+```
+
+## Examples
+- Example 1: `Run tests: npm test src/auth/` (from WORKAROUND-PATTERNS.md)
+- Example 2: `npm run test:integration` (from examples/copilot-limited-context.md)
+- Example 3: `Ensure all tests pass` (from examples/workflow-example.md)
+- Example 4: `npm test` (from examples/skill-example.md)
+
+## Transformation Notes
+- Universal pattern; keep test commands across all platforms
+- Adjust test runner syntax per project configuration
+- No platform-specific transformation needed
+
+---
+
+# Construct: advisory-warning
+
+## Description
+Explicit warnings about platform limitations, advisory-only restrictions, or features that cannot be enforced on the target platform.
+
+## Source Platform
+**windsurf** / **github-copilot** - Platforms lacking Claude Code's enforcement
+
+## Detection Pattern
+```regex
+(?i)(NOTE:.*not\s+enforced|advisory\s+only|rely\s+on\s+AI\s+compliance|cannot\s+be\s+enforced|IMPORTANT:.*restrictions|WARNING:.*limitations?|emulated|simulated|not\s+supported)
+```
+
+## Examples
+- Example 1: `NOTE: These restrictions rely on AI compliance and are NOT enforced by Windsurf` (from WORKAROUND-PATTERNS.md)
+- Example 2: `Advisory Restrictions - Document tool/permission restrictions (not enforced)` (from WORKAROUND-PATTERNS.md)
+- Example 3: `Subagent spawning not supported` (from transformation notes)
+- Example 4: `context: fork can only be simulated` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- Generate appropriate advisory warnings when transforming TO less-capable platforms
+- Remove advisory warnings when transforming TO Claude Code (native support)
+- Always preserve semantic intent while clarifying enforcement level
+
+---
+
+# Construct: version-comment
+
+## Description
+HTML-style version comments embedded in markdown content for tracking skill/workflow versions when frontmatter version field is not available.
+
+## Source Platform
+**windsurf** - Pattern for version tracking in adapted workflows
+
+## Detection Pattern
+```regex
+<!--\s*Version:\s*[\d.]+\s*-->|<!--\s*Part\s+\d+\s+of\s+\d+|<!--\s*Adapted\s+from
+```
+
+## Examples
+- Example 1: `<!-- Version: 1.0.0 -->` (from WORKAROUND-PATTERNS.md)
+- Example 2: `<!-- Part 1 of 4: Core Authentication Module -->` (from WORKAROUND-PATTERNS.md)
+- Example 3: `<!-- Adapted from Claude Code skill -->` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- **To Claude Code:** Extract to `version:` frontmatter field
+- **To Windsurf:** Keep as HTML comments (no version frontmatter field)
+- **To Copilot:** Keep as HTML comments for documentation
+
+---
+
+# Construct: execution-flow-section
+
+## Description
+Detailed step-by-step execution traces documenting how a skill/workflow should execute, including intermediate states and verification points.
+
+## Source Platform
+**All platforms** - Documentation pattern for complex workflows
+
+## Detection Pattern
+```regex
+(?i)(Execution\s+Flow|Step-by-Step\s+Execution|Manual\s+Traceability|Intermediate\s+State|Verification\s+Points)
+```
+
+## Examples
+- Example 1: `Execution Flow: How Windsurf Processes the Emulated Skill` (from WORKAROUND-PATTERNS.md)
+- Example 2: `Step-by-Step Execution Trace` (from examples/workflow-example.md)
+- Example 3: `Intermediate State After Step 0:` (from examples/workflow-example.md)
+- Example 4: `Verification Points: - Before: file exists - During: AI mentions following workflow` (from WORKAROUND-PATTERNS.md)
+
+## Transformation Notes
+- Universal documentation pattern; keep across all platforms
+- Update platform-specific references (Windsurf/Cascade, Claude Code, Copilot)
+- Valuable for debugging and verification regardless of platform
+
+---
+
+## Detection Implementation Notes
+
+### Priority Order
+When detecting constructs, process in this order to avoid false positives:
+1. Skip fenced code blocks (```...```)
+2. Skip inline code (`...`)
+3. Skip frontmatter section (---...---)
+4. Apply construct detection patterns
+
+### Overlap Handling
+Some constructs may overlap. Apply these precedence rules:
+1. `tool-call` takes precedence over generic word matches
+2. `model-decision-trigger` takes precedence for "USE WHEN" phrases
+3. `activation-instruction` takes precedence over generic slash commands
+
+### Code Block Detection
+```regex
+```[\s\S]*?```|`[^`]+`
+```
+Use this pattern to identify and skip code blocks before applying construct detection.
+
+---
+
+## Transformation Matrix
+
+| Construct | Claude Code | Windsurf | GitHub Copilot |
+|-----------|-------------|----------|----------------|
+| agent-spawn | Native (Task tool) | Advisory note (not supported) | Advisory note (not supported) |
+| tool-call | Native (specific tools) | Rephrase as actions | Generic recommendations |
+| context-switch | Native (fork/inherit) | Note (no isolation) | Remove references |
+| permission-reference | Native (enforced) | Advisory section | Operational constraints section |
+| model-decision-trigger | Rich description + manual | Native (trigger: model_decision) | When to use section |
+| glob-pattern | Step 0 context gathering | Native (globs:) | applyTo + working set notes |
+| persona-rule | agent: frontmatter | @rules: activation | Inline persona section |
+| skill-chaining | /skill-name | /workflow-name | /prompt name |
+| context-gathering-protocol | Keep (emulation pattern) | Remove (automatic) | Keep (limited files) |
+| activation-instruction | /skill-name | /workflow-name | /prompt name or file |
+| working-set-limit | Remove | Remove | Keep (platform constraint) |
+| checkpoint-commit | Keep | Keep | Keep |
+| progress-tracking | Keep | Keep | Keep |
+| workspace-command | Convert to Glob/Grep | Natural language | Native @workspace |
+| test-command | Keep | Keep | Keep |
+| advisory-warning | Remove (native support) | Keep | Keep |
+| version-comment | Extract to frontmatter | Keep as comment | Keep as comment |
+| execution-flow-section | Keep | Keep | Keep |
+
+---
+
+## Cross-References
+
+- **WORKAROUND-PATTERNS.md** - Source patterns for skill/workflow emulation
+- **RESEARCH-claude-code.md** - Claude Code native capabilities
+- **RESEARCH-windsurf.md** - Windsurf native capabilities
+- **examples/skill-example.md** - Cross-platform skill format
+- **examples/workflow-example.md** - Workflow emulation example
+- **examples/copilot-limited-context.md** - Working set limitation pattern
+- **STANDARD-SCHEMA.md** - Frontmatter field definitions (Phase 4)
+
+---
+
+## Summary
+
+**Total Constructs Documented:** 18
+
+**Required Constructs Coverage:**
+1. agent-spawn - Covered
+2. tool-call - Covered
+3. context-switch - Covered
+4. permission-reference - Covered
+5. model-decision-trigger - Covered
+6. glob-pattern - Covered
+7. persona-rule - Covered
+8. skill-chaining - Covered
+9. context-gathering-protocol - Covered
+10. activation-instruction - Covered
+
+**Additional Constructs Discovered:**
+11. working-set-limit - GitHub Copilot constraint references
+12. checkpoint-commit - Multi-part operation checkpoints
+13. progress-tracking - Workflow progress documentation
+14. workspace-command - @workspace codebase search
+15. test-command - Test execution references
+16. advisory-warning - Platform limitation warnings
+17. version-comment - HTML version tracking comments
+18. execution-flow-section - Step-by-step execution documentation
diff --git a/DEVELOPMENT.md b/DEVELOPMENT.md
index 1026098..45848cc 100644
--- a/DEVELOPMENT.md
+++ b/DEVELOPMENT.md
@@ -208,13 +208,44 @@ bun test
 # Specific file
 bun test path/to/test-file.test.ts
 
-# Watch mode
+# Watch mode (for bun)
 bun test --watch
 
+# Watch mode (npm scripts in packages/cli)
+cd packages/cli
+npm run test:watch
+
 # With coverage (if configured)
 bun test --coverage
 ```
 
+## Watch Mode Development
+
+For continuous development with automatic rebuilding and testing:
+
+```bash
+cd packages/cli
+
+# Combined watch: rebuilds code AND runs tests on changes
+npm run watch
+
+# TypeScript only: watch and rebuild on source changes
+npm run dev:watch
+
+# Tests only: watch and re-run tests on changes
+npm run test:watch
+```
+
+**Available watch scripts:**
+
+| Script | Purpose |
+|--------|---------|
+| `npm run watch` | Runs `dev:watch` + `test:watch` in parallel |
+| `npm run dev:watch` | TypeScript compilation + template sync |
+| `npm run test:watch` | Mocha in watch mode |
+| `npm run build:watch` | TypeScript compiler only |
+| `npm run templates:watch` | Template file sync only |
+
 ## Standard Development Workflow
 
 Follow this pattern for all development work:
diff --git a/GAP-ANALYSIS.md b/GAP-ANALYSIS.md
new file mode 100644
index 0000000..d05a685
--- /dev/null
+++ b/GAP-ANALYSIS.md
@@ -0,0 +1,1257 @@
+# Capability Gap Analysis and Workaround Patterns
+
+**Date:** 2026-01-12
+**Purpose:** Identify capability gaps between Claude Code and Windsurf, and propose emulation patterns
+
+---
+
+## Executive Summary
+
+Both Claude Code and Windsurf have unique capabilities that don't directly translate. This document analyzes those gaps and provides workaround patterns to emulate missing features across platforms.
+
+**Priority Ranking:**
+1. **HIGH** - Critical for functionality, severely limits portability
+2. **MEDIUM** - Important but workarounds exist
+3. **LOW** - Nice-to-have, minimal impact on core functionality
+
+---
+
+## Gaps: Missing in Windsurf
+
+### GAP-W1: Subagent Spawning
+**Priority:** 🔴 HIGH
+**Claude Code Feature:** Task tool spawns parallel subagents with isolated contexts
+**Windsurf Limitation:** No subagent support, single Cascade context only
+
+**Impact:**
+- Cannot delegate tasks to specialized agents
+- Cannot execute parallel research/work
+- All work must be sequential in single context
+- Context degradation from long-running sessions
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy 1: Sequential Execution with Context Markers
+---
+trigger: manual
+description: Emulate subagent work with context isolation markers
+---
+
+# Research Task Emulation
+
+## Phase 1: Research (Simulated Subagent 1)
+[CONTEXT: Acting as research agent with read-only focus]
+- Search codebase for authentication patterns
+- Document findings in RESEARCH.md
+[END CONTEXT]
+
+## Phase 2: Implementation (Simulated Subagent 2)
+[CONTEXT: Acting as implementation agent with write access]
+- Implement authentication based on RESEARCH.md
+- Create necessary files
+[END CONTEXT]
+
+## Phase 3: Verification (Simulated Subagent 3)
+[CONTEXT: Acting as test agent]
+- Run tests on authentication
+- Verify implementation
+[END CONTEXT]
+```
+
+```yaml
+# Strategy 2: Multiple Workflow Files (Pseudo-Parallel)
+# File: .windsurf/workflows/research-auth.md
+---
+description: Research authentication patterns
+---
+Search codebase and document findings in RESEARCH-auth.md
+
+# File: .windsurf/workflows/implement-auth.md
+---
+description: Implement authentication
+---
+Read RESEARCH-auth.md and implement based on findings
+
+# File: .windsurf/workflows/test-auth.md
+---
+description: Test authentication
+---
+Verify authentication implementation
+
+# User runs: /research-auth, then /implement-auth, then /test-auth
+```
+
+**Limitations:**
+- Not truly parallel (sequential only)
+- No isolated contexts (risk of context pollution)
+- Requires manual workflow orchestration
+- Cannot maintain separate conversation threads
+
+**See Also:** [WORKAROUND-PATTERNS.md - Pattern 1: Skill Emulation](WORKAROUND-PATTERNS.md#pattern-1-skill-emulation-for-windsurf) - Complete implementation guide with examples
+
+---
+
+### GAP-W2: Granular Permission Control
+**Priority:** 🟡 MEDIUM
+**Claude Code Feature:** Fine-grained allow/deny patterns for tools and paths
+**Windsurf Limitation:** Limited permission enforcement
+
+**Impact:**
+- Cannot enforce tool restrictions
+- Cannot block dangerous operations programmatically
+- Relies on AI respecting rules (not enforcement)
+- Security concerns for sensitive operations
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy 1: Explicit Rule Instructions with Warnings
+---
+trigger: always_on
+description: Security and permission guidelines
+---
+
+# Permission Rules
+
+## CRITICAL RESTRICTIONS (Follow strictly):
+
+### File Access
+- ✅ ALLOWED: Read any file in `src/`, `tests/`, `docs/`
+- ❌ FORBIDDEN: Read `.env`, `secrets/`, `credentials.json`
+- ❌ FORBIDDEN: Write to `config/production.json`
+- ❌ FORBIDDEN: Modify `package.json` without user approval
+
+### Command Execution
+- ✅ ALLOWED: `npm run lint`, `npm test`, `git status`
+- ❌ FORBIDDEN: `npm install` (ask user first)
+- ❌ FORBIDDEN: `git push` to main/master (ask user first)
+- ❌ FORBIDDEN: Any `rm -rf` commands
+
+**BEFORE violating these rules, STOP and ask user for explicit permission.**
+```
+
+```yaml
+# Strategy 2: Glob-Based Context Loading
+---
+trigger: glob
+globs: [".env", "secrets/**/*", "*credentials*"]
+description: Security warning for sensitive files
+---
+
+# SECURITY WARNING
+
+You are accessing a SENSITIVE FILE that may contain secrets.
+
+**RULES:**
+1. NEVER output the contents of this file
+2. NEVER write or modify this file
+3. If user asks to work with this file, confirm intent first
+4. Suggest using environment variable references instead
+
+This rule cannot be enforced - you must respect it.
+```
+
+**Limitations:**
+- Relies on AI compliance, not enforcement
+- No technical barrier to prevent violations
+- Rules can be ignored or overridden by AI
+- No audit trail of permission requests
+
+---
+
+### GAP-W3: Custom Agent Types
+**Priority:** 🟡 MEDIUM
+**Claude Code Feature:** Define custom subagents with specific tools and instructions
+**Windsurf Limitation:** No custom agent definitions
+
+**Impact:**
+- Cannot create specialized agent personas
+- Cannot restrict tool access per agent type
+- All work uses same Cascade personality
+- Cannot optimize for specific task types
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: Persona Rules with Context Switching
+# File: .windsurf/rules/agent-explorer.md
+---
+trigger: manual
+description: Read-only explorer agent persona
+---
+
+# Explorer Agent Persona
+
+When @rules:agent-explorer is active:
+
+**Role:** Read-only code explorer
+**Allowed Actions:**
+- Read files, search codebase
+- Analyze patterns and structure
+- Document findings
+
+**Forbidden Actions:**
+- Do not write or modify files
+- Do not execute commands
+- Do not suggest changes
+
+**Output Format:**
+- Create FINDINGS.md with analysis
+- Use bullet points for discoveries
+- Include file paths and line numbers
+```
+
+```yaml
+# File: .windsurf/rules/agent-implementer.md
+---
+trigger: manual
+description: Implementation agent persona
+---
+
+# Implementer Agent Persona
+
+When @rules:agent-implementer is active:
+
+**Role:** Code implementation specialist
+**Allowed Actions:**
+- Read findings from FINDINGS.md
+- Write and modify code files
+- Run tests to verify changes
+
+**Forbidden Actions:**
+- Do not conduct research (use @rules:agent-explorer)
+- Do not deploy or push (ask user first)
+
+**Pattern:**
+1. Read FINDINGS.md
+2. Implement changes
+3. Run tests
+4. Report results
+```
+
+**Usage:**
+```
+User: "@rules:agent-explorer analyze the authentication system"
+[Cascade analyzes and creates FINDINGS.md]
+
+User: "@rules:agent-implementer implement improvements from FINDINGS.md"
+[Cascade implements based on findings]
+```
+
+**Limitations:**
+- Manual activation required (not automatic)
+- No true isolation between personas
+- AI might blend personas if not careful
+- No tool restrictions enforced
+
+---
+
+### GAP-W4: Skill Customization Layer
+**Priority:** 🟢 LOW
+**Claude Code Feature:** SKILLCUSTOMIZATIONS/ for user-specific extensions
+**Windsurf Limitation:** No customization overlay system
+
+**Impact:**
+- Cannot extend base workflows without modifying them
+- Team workflows and personal preferences conflict
+- Difficult to maintain upstream updates
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: Personal Rules That Override Defaults
+# File: .windsurf/rules/personal-overrides.md (gitignored)
+---
+trigger: always_on
+description: Personal preferences and overrides
+---
+
+# Personal Overrides
+
+These rules override team defaults:
+
+## Testing Preferences
+- Use `npm run test:watch` instead of `npm test`
+- Skip integration tests during rapid development
+
+## Commit Style
+- Prefer detailed commit messages over brief ones
+- Include ticket numbers in format: [PROJ-123]
+
+## Code Style
+- Use single quotes (override team's double quotes)
+- Prefer arrow functions over function keyword
+```
+
+**Setup:**
+```bash
+# Add to .gitignore
+echo ".windsurf/rules/personal-overrides.md" >> .gitignore
+
+# Team shares base rules, individuals add personal overrides
+```
+
+**Limitations:**
+- Must manually maintain gitignore
+- No merge mechanism for base + personal
+- Can't selectively override specific rules
+- All-or-nothing rule application
+
+---
+
+### GAP-W5: Progressive Disclosure
+**Priority:** 🟢 LOW
+**Claude Code Feature:** Layered context loading (Level 1, 2, 3+)
+**Windsurf Limitation:** No progressive loading system
+
+**Impact:**
+- All workflow content loaded immediately
+- Cannot defer loading of detailed resources
+- 12,000 character limit makes this less critical
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: Reference External Documentation
+# File: .windsurf/workflows/complex-workflow.md
+---
+description: Complex workflow with detailed steps
+---
+
+# Complex Workflow
+
+## Quick Start
+1. Run initial setup
+2. Execute main tasks
+3. Verify completion
+
+## Detailed Instructions
+For detailed step-by-step instructions, see:
+- `docs/workflows/complex-workflow-details.md`
+- `docs/workflows/troubleshooting.md`
+
+## Reference Materials
+Load as needed:
+- API documentation: `docs/api/README.md`
+- Code examples: `examples/complex-workflow/`
+```
+
+**Limitations:**
+- Requires manual file reading
+- No automatic context loading
+- AI must explicitly read referenced files
+- Adds overhead to workflow execution
+
+---
+
+### GAP-W6: Lifecycle Hook System
+**Priority:** 🟡 MEDIUM
+**Claude Code Feature:** Comprehensive hooks (PreToolUse, PostToolUse, Stop, etc.)
+**Windsurf Limitation:** Limited event system
+
+**Impact:**
+- Cannot intercept tool execution
+- Cannot run cleanup on session end
+- Cannot validate inputs before execution
+- Limited automation opportunities
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: Explicit Workflow Steps with Validation
+# File: .windsurf/workflows/safe-commit.md
+---
+description: Git commit with pre-commit validation
+---
+
+# Safe Commit Workflow
+
+## Pre-Commit Validation (Manual Hook)
+Before committing:
+1. Run linter: `npm run lint`
+2. Run tests: `npm test`
+3. Check for secrets: grep -r "API_KEY" src/
+4. STOP if any validation fails
+
+## Commit
+If all validations pass:
+```bash
+git add .
+git commit -m "$1"
+```
+
+## Post-Commit Actions (Manual Hook)
+After commit:
+1. Show commit summary: `git log -1`
+2. Check branch status: `git status`
+3. Remind user to push if needed
+```
+
+```yaml
+# Strategy: Always-On Rule for Validation Reminders
+# File: .windsurf/rules/validation-reminders.md
+---
+trigger: always_on
+description: Remind about validation before operations
+---
+
+# Validation Reminders
+
+Before executing these operations, ALWAYS:
+
+**Before `git commit`:**
+- Run linter
+- Run tests
+- Check for sensitive data
+
+**Before `npm install`:**
+- Review package being installed
+- Check for known vulnerabilities
+- Confirm with user
+
+**After writing code:**
+- Run relevant tests
+- Check for TypeScript errors
+- Verify formatting
+```
+
+**Limitations:**
+- Manual compliance, not automatic
+- No technical enforcement
+- Easy to forget validation steps
+- No rollback mechanism
+
+---
+
+## Gaps: Missing in Claude Code
+
+### GAP-C1: AI-Driven Rule Activation (Model Decision)
+**Priority:** 🟡 MEDIUM
+**Windsurf Feature:** AI decides when to activate rules based on context
+**Claude Code Limitation:** Rules always active or manually invoked
+
+**Impact:**
+- Rules are either always-on or require explicit invocation
+- Cannot have context-aware rule activation
+- Clutters context with potentially irrelevant rules
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: Multiple Specific Skills with Clear Descriptions
+# File: ~/.claude/skills/python-style/SKILL.md
+---
+name: python-style
+description: USE WHEN working with Python files. Provides Python style guidelines and best practices.
+---
+
+# Python Style Guide
+
+[Python-specific instructions]
+```
+
+```yaml
+# File: ~/.claude/skills/javascript-style/SKILL.md
+---
+name: javascript-style
+description: USE WHEN working with JavaScript or TypeScript files. Provides JS/TS style guidelines.
+---
+
+# JavaScript Style Guide
+
+[JavaScript-specific instructions]
+```
+
+**How it works:**
+- Claude's auto-invoke matches description to context
+- `USE WHEN` pattern helps Claude decide relevance
+- More specific descriptions = better auto-activation
+
+**Limitations:**
+- Less sophisticated than true AI decision
+- Based on description matching, not deep context analysis
+- May activate when not needed or miss activation
+- Relies on skill description quality
+
+---
+
+### GAP-C2: Cascade Memories (Pattern Learning)
+**Priority:** 🟡 MEDIUM
+**Windsurf Feature:** Learns patterns across sessions
+**Claude Code Limitation:** No persistent memory/learning
+
+**Impact:**
+- Cannot learn user preferences over time
+- Repeats same questions across sessions
+- No pattern recognition across projects
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: Explicit Preference Documentation
+# File: CLAUDE.local.md (gitignored personal preferences)
+
+# My Personal Preferences
+
+## Code Style
+- I prefer arrow functions over function keyword
+- I use single quotes for strings
+- I prefer detailed commit messages
+
+## Development Workflow
+- I always run tests before committing
+- I prefer feature branches over main
+- I like to see diffs before approving changes
+
+## Recent Project Patterns
+*(Update this manually as you discover patterns)*
+
+### Authentication Pattern (2026-01-12)
+- Using JWT tokens stored in httpOnly cookies
+- Refresh tokens in Redis with 7-day expiration
+- Access tokens expire in 15 minutes
+
+### Database Pattern (2026-01-10)
+- Using Prisma ORM with PostgreSQL
+- Migrations in `prisma/migrations/`
+- Seed data in `prisma/seed.ts`
+```
+
+```yaml
+# Strategy: Session State Files
+# File: .claude/state/project-context.json
+
+{
+  "lastWorkingArea": "authentication-module",
+  "recentDecisions": [
+    {
+      "date": "2026-01-12",
+      "decision": "Use bcrypt for password hashing",
+      "rationale": "More secure than basic SHA-256"
+    }
+  ],
+  "preferredPatterns": {
+    "testing": "Jest with React Testing Library",
+    "styling": "Tailwind CSS",
+    "stateManagement": "Zustand"
+  }
+}
+```
+
+**Usage in Skill:**
+```yaml
+---
+name: context-loader
+description: Load project context and user preferences at session start
+---
+
+# Context Loader
+
+Read the following files to understand context:
+1. `CLAUDE.local.md` - User preferences
+2. `.claude/state/project-context.json` - Project state
+3. `STATE.md` - Current project status
+
+Apply these preferences and patterns throughout the session.
+```
+
+**Limitations:**
+- Manual updates required
+- No automatic pattern detection
+- Can become stale if not maintained
+- No cross-project learning
+
+---
+
+### GAP-C3: Multiple Simultaneous Conversations
+**Priority:** 🟢 LOW
+**Windsurf Feature:** Multiple Cascade conversations in parallel
+**Claude Code Limitation:** Single session per project
+
+**Impact:**
+- Cannot work on multiple features simultaneously
+- Cannot compare approaches in parallel
+- Must finish one conversation before starting another
+
+**Workaround Pattern:**
+
+```bash
+# Strategy: Multiple Terminal Windows/Sessions
+# Terminal 1: Working on Feature A
+cd ~/project
+claude code
+
+# Terminal 2: Working on Feature B (different directory context)
+cd ~/project-feature-b
+claude code
+
+# Or use named sessions (if supported)
+claude code --session feature-a
+claude code --session feature-b
+```
+
+```yaml
+# Strategy: Session State Management
+# File: .claude/skills/session-manager/SKILL.md
+---
+name: session-manager
+description: Manage multiple work streams by saving/loading session state
+---
+
+# Session Manager
+
+## Save Session State
+When switching contexts:
+1. Document current work in `SESSION-[feature-name].md`
+2. Commit current changes
+3. Note next steps in file
+
+## Load Session State
+When resuming:
+1. Read `SESSION-[feature-name].md`
+2. Review current changes since last session
+3. Continue from noted next steps
+```
+
+**Limitations:**
+- Requires manual session management
+- Not truly parallel (must switch between sessions)
+- Context switching overhead
+- State management burden on user
+
+---
+
+### GAP-C4: Native IDE Integration
+**Priority:** 🟢 LOW
+**Windsurf Feature:** Built-in IDE with integrated AI
+**Claude Code Limitation:** CLI-first, relies on external editor
+
+**Impact:**
+- Must switch between terminal and editor
+- Less seamless inline assistance
+- More manual file navigation
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: Optimize CLI Workflow
+# File: ~/.claude/skills/editor-integration/SKILL.md
+---
+name: editor-integration
+description: Optimize workflows for external editor usage
+---
+
+# Editor Integration Patterns
+
+## When making changes:
+1. Use Edit tool to show exact changes
+2. Provide file path with line numbers
+3. User can jump to location in editor
+
+## For large refactors:
+1. Create `REFACTOR-PLAN.md` with all changes
+2. List files and specific line numbers
+3. User can work through plan in editor
+
+## Output format:
+Always include: `file.ts:123` format for clickable links
+```
+
+**Limitations:**
+- Not as seamless as native IDE
+- Requires context switching
+- Cannot see editor state directly
+- Manual synchronization needed
+
+---
+
+## Gaps: Missing in GitHub Copilot
+
+### GAP-GH1: Working Set and Context Limitations
+**Priority:** 🔴 HIGH
+**Claude Code/Windsurf Feature:** Unlimited working sets and files
+**GitHub Copilot Limitation:** 10 file max working set, 6,000 char context window, 20 file max context
+
+**Impact:**
+- Severely limits large-scale refactoring
+- Cannot work effectively on larger projects
+- Quality degrades quickly on medium-sized features
+- Community considering alternatives due to restrictions
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: Sequential Batch Processing
+# Break large refactors into multiple smaller working sets
+
+## Batch 1 (Files 1-10):
+# Phase 1: Core authentication files
+- src/auth/login.ts
+- src/auth/register.ts
+- src/auth/session.ts
+- src/auth/middleware.ts
+- src/auth/types.ts
+- src/auth/utils.ts
+- src/auth/validators.ts
+- src/auth/errors.ts
+- tests/auth/login.test.ts
+- tests/auth/register.test.ts
+
+## Batch 2 (Files 11-20):
+# Phase 2: Integration points
+- src/api/routes/auth.ts
+- src/api/controllers/user.ts
+# ... continue with next 10 files
+```
+
+```markdown
+# Strategy: Incremental Refactoring with Checkpoints
+
+## Workflow:
+1. Identify refactoring scope
+2. Break into 10-file chunks
+3. Refactor Batch 1, commit
+4. Refactor Batch 2, commit
+5. Continue until complete
+6. Final integration pass
+
+## Benefits:
+- Works within Copilot limits
+- Git history shows clear progression
+- Can rollback individual batches
+- Easier code review
+```
+
+**Limitations:**
+- Time-consuming manual batching
+- Risk of inconsistencies across batches
+- Cannot see full picture in single view
+- Breaks flow state
+
+**See Also:** [WORKAROUND-PATTERNS.md - Pattern 3: Working Set Limitation Pattern](WORKAROUND-PATTERNS.md#pattern-3-working-set-limitation-pattern-for-github-copilot) - Complete implementation guide with skill decomposition, coordinator pattern, file prioritization heuristics, decision tree for split vs @workspace, and working example in [examples/copilot-limited-context.md](examples/copilot-limited-context.md)
+
+---
+
+### GAP-GH2: Lifecycle Hooks
+**Priority:** 🟡 MEDIUM
+**Claude Code Feature:** 10+ customizable lifecycle hooks (PreToolUse, PostToolUse, etc.)
+**GitHub Copilot Limitation:** No configurable lifecycle hooks
+
+**Impact:**
+- Cannot automate pre/post-execution workflows
+- Cannot validate before tool use
+- Cannot provide feedback after tool use
+- Limited automation opportunities
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: Explicit Workflow Steps in Custom Instructions
+# File: .github/copilot-instructions.md
+
+# Workflow Validation Standards
+
+## Before Making Changes:
+Always perform these steps BEFORE editing files:
+1. Run linter to check current state
+2. Run tests to establish baseline
+3. Review related files for dependencies
+
+## After Making Changes:
+Always perform these steps AFTER editing files:
+1. Run linter to check for issues
+2. Run tests to verify no regressions
+3. Show summary of changes made
+
+## Before Git Operations:
+BEFORE running `git commit`:
+1. Run full test suite
+2. Check for sensitive data (API keys, passwords)
+3. Verify commit message follows conventions
+```
+
+```yaml
+# Strategy: Custom Prompt for Validation
+# File: .github/prompts/safe-refactor.prompt.md
+
+# Safe Refactoring Protocol
+
+Follow this protocol for all refactoring:
+
+**Pre-Refactor Checklist:**
+- [ ] Tests pass
+- [ ] Linter clean
+- [ ] No TypeScript errors
+
+**Refactoring:**
+[Make changes]
+
+**Post-Refactor Validation:**
+- [ ] Tests still pass
+- [ ] Linter still clean
+- [ ] No new TypeScript errors
+- [ ] Manual smoke test completed
+
+**Rollback Plan:**
+If validation fails: `git checkout -- .`
+```
+
+**Limitations:**
+- Manual compliance required
+- No automatic enforcement
+- Easy to skip steps
+- No technical barrier to prevent violations
+
+---
+
+### GAP-GH3: Large File Handling
+**Priority:** 🟡 MEDIUM
+**Claude Code Feature:** No file size limits
+**GitHub Copilot Limitation:** Quality degrades >782 lines, significant problems >5,000 lines
+
+**Impact:**
+- Cannot effectively refactor large files
+- Poor suggestions on complex files
+- May cut files in half
+- Forces artificial file splitting
+
+**Workaround Pattern:**
+
+```yaml
+# Strategy: File Decomposition
+# Before refactoring large file, decompose it
+
+## Step 1: Analyze Large File
+Identify logical boundaries in large file:
+- Class/module definitions
+- Related function groups
+- Data structures and types
+
+## Step 2: Extract Modules
+Create separate files for each logical unit:
+- user-service.ts (core logic)
+- user-types.ts (type definitions)
+- user-validators.ts (validation functions)
+- user-utils.ts (helper functions)
+
+## Step 3: Update Imports
+Refactor imports to use new structure
+
+## Step 4: Refactor Smaller Files
+Now each file is <500 lines and Copilot works well
+```
+
+```yaml
+# Strategy: Window-Based Editing
+# For files that must stay large
+
+## Approach:
+1. Open only the section you're editing
+2. Use Copilot on that section
+3. Close and save
+4. Open next section
+5. Repeat
+
+## Keep Context Small:
+- Work on one function at a time
+- Minimize visible code
+- Use "fold" features to hide irrelevant sections
+```
+
+**Limitations:**
+- Artificial file splitting may harm architecture
+- Window-based editing is tedious
+- Loses full-file context
+- Not suitable for all refactorings
+
+---
+
+### GAP-GH4: Multi-Repository Support
+**Priority:** 🟢 LOW
+**Claude Code Feature:** Can work across multiple repositories
+**GitHub Copilot Limitation:** Agent can only modify single repository, opens exactly 1 PR per task
+
+**Impact:**
+- Cannot coordinate changes across multiple repos
+- Microservice refactorings require multiple tasks
+- Shared library updates need separate runs
+
+**Workaround Pattern:**
+
+```bash
+# Strategy: Sequential Multi-Repo Execution
+
+## Workflow:
+1. Create task list for all affected repos
+2. Run Copilot Agent on Repo 1, create PR
+3. Run Copilot Agent on Repo 2, create PR
+4. Run Copilot Agent on Repo 3, create PR
+5. Merge PRs in dependency order
+
+## Coordination:
+- Document cross-repo dependencies in each PR
+- Link PRs together in descriptions
+- Merge in correct order (dependencies first)
+```
+
+```markdown
+# Strategy: Monorepo Migration (if feasible)
+
+If multi-repo coordination is frequent pain point:
+1. Consider migrating to monorepo
+2. Single repository = single Copilot run
+3. Atomic cross-package changes
+4. Better for tightly-coupled services
+
+Trade-offs:
++ Single PR for cross-service changes
++ Easier refactoring
+- Larger repository
+- May not fit all architectures
+```
+
+**Limitations:**
+- Monorepo not always feasible
+- Sequential execution is slow
+- Risk of inconsistencies if PRs merge out of order
+- Manual coordination required
+
+---
+
+## Workaround Pattern Library
+
+### Pattern 1: Emulating Claude Skills in Windsurf
+
+**Goal:** Make Claude Code skills work in Windsurf
+
+**Approach:**
+```yaml
+# Original Claude Skill: ~/.claude/skills/commit/SKILL.md
+---
+name: commit
+description: Create conventional git commits
+allowed-tools: Bash(git *)
+---
+
+# Commit Skill
+[Instructions for creating commits]
+```
+
+**Windsurf Translation:**
+```yaml
+# .windsurf/workflows/commit.md
+---
+description: Create conventional git commits
+labels: git, automation
+trigger: manual
+---
+
+# Commit Workflow
+[Same instructions from Claude skill]
+
+# Invoke with: /commit
+```
+
+**Key Changes:**
+1. Move to `.windsurf/workflows/`
+2. Filename becomes command name
+3. Remove `allowed-tools` (not enforced)
+4. Add `trigger` and `labels`
+5. Keep instructions identical
+
+---
+
+### Pattern 2: Emulating Windsurf Workflows in Claude Code
+
+**Goal:** Make Windsurf workflows work in Claude Code
+
+**Approach:**
+```yaml
+# Original Windsurf Workflow: .windsurf/workflows/deploy.md
+---
+trigger: manual
+description: Deploy to production
+labels: deployment
+---
+
+# Deploy
+[Deployment instructions]
+```
+
+**Claude Translation:**
+```yaml
+# .claude/skills/deploy/SKILL.md
+---
+name: deploy
+description: Deploy to production
+allowed-tools: Bash
+---
+
+# Deploy Skill
+[Same instructions from Windsurf workflow]
+```
+
+**Alternative (simpler):**
+```yaml
+# .claude/commands/deploy.md
+---
+description: Deploy to production
+allowed-tools: Bash
+---
+
+[Same instructions from Windsurf workflow]
+```
+
+**Key Changes:**
+1. Choose between skill (complex) or command (simple)
+2. Add skill structure if using skills
+3. Add `allowed-tools` for safety
+4. Remove Windsurf-specific fields
+5. Keep instructions identical
+
+---
+
+### Pattern 3: Emulating Windsurf Always-On Rules in Claude
+
+**Goal:** Make Windsurf always-on rules work in Claude Code
+
+**Approach:**
+```yaml
+# Original Windsurf Rule: .windsurf/rules/code-style.md
+---
+trigger: always_on
+description: Code style guidelines
+---
+
+# Code Style
+- Use single quotes
+- Prefer const over let
+```
+
+**Claude Translation:**
+```markdown
+# CLAUDE.md (add to project root)
+
+# Code Style
+- Use single quotes
+- Prefer const over let
+```
+
+**Key Changes:**
+1. Combine all always-on rules into CLAUDE.md
+2. Remove front matter (optional in CLAUDE.md)
+3. Keep instructions identical
+4. CLAUDE.md is always loaded (like always_on)
+
+---
+
+### Pattern 4: Emulating Windsurf Glob Triggers in Claude
+
+**Goal:** Activate rules based on file patterns
+
+**Approach:**
+```yaml
+# Original Windsurf Rule: .windsurf/rules/python-rules.md
+---
+trigger: glob
+globs: ["*.py", "**/*.py"]
+description: Python-specific rules
+---
+
+# Python Rules
+[Python instructions]
+```
+
+**Claude Translation:**
+```yaml
+# .claude/skills/python-rules/SKILL.md
+---
+name: python-rules
+description: USE WHEN working with Python files (*.py). Python-specific coding rules and standards.
+---
+
+# Python Rules
+[Same Python instructions]
+```
+
+**Key Changes:**
+1. Use "USE WHEN" with file pattern in description
+2. Claude's auto-invoke will activate for Python work
+3. Less precise than glob, but functional
+4. Relies on context matching
+
+---
+
+### Pattern 5: Cross-Platform CLAUDE.md/Rules Strategy
+
+**Goal:** Single source of truth for project instructions
+
+**Approach:**
+```markdown
+# CLAUDE.md (works in both!)
+
+# Project Instructions
+
+## Code Style
+- Use TypeScript strict mode
+- Prefer functional programming
+- Use Tailwind for styling
+
+## Testing
+- Jest for unit tests
+- Playwright for E2E
+- 80% coverage minimum
+
+## Git Workflow
+- Conventional commits
+- Feature branches
+- Squash merge to main
+```
+
+**Windsurf Supplement:**
+```yaml
+# .windsurf/rules/claude-md-loader.md
+---
+trigger: always_on
+description: Load CLAUDE.md as base rules
+---
+
+# Project Rules
+
+Follow all instructions in the root CLAUDE.md file.
+See @CLAUDE.md for complete project guidelines.
+```
+
+**Benefits:**
+- Single file for basic project rules
+- Works in both platforms
+- Version controlled
+- Team can share
+
+---
+
+### Pattern 6: Shared Workflow Format
+
+**Goal:** Write once, run everywhere
+
+**Standard Template:**
+```yaml
+# Header comment: Works in Claude Code as skill or Windsurf as workflow
+# ---
+# Claude Code: Place in .claude/skills/SKILL-NAME/SKILL.md with name: field
+# Windsurf: Place in .windsurf/workflows/WORKFLOW-NAME.md
+# ---
+name: standard-workflow              # Claude only
+description: Standard workflow that works on both platforms
+allowed-tools: Read,Write,Bash       # Claude only (ignored by Windsurf)
+trigger: manual                      # Windsurf only (ignored by Claude)
+labels: cross-platform, standard     # Windsurf only (ignored by Claude)
+---
+
+# Standard Workflow
+
+This workflow works on both Claude Code and Windsurf.
+
+[Platform-agnostic instructions]
+
+## Platform-Specific Notes
+
+**Claude Code:** Uses allowed-tools for permission control
+**Windsurf:** Invoke with /workflow-name
+```
+
+**Benefits:**
+- Portable across platforms
+- Extra metadata ignored by each platform
+- Clear documentation of platform differences
+- Single source for logic
+
+---
+
+## Priority Gap Summary
+
+### High Priority (Must Address)
+1. **GAP-W1: Subagent Spawning** (Windsurf) - Sequential workflow emulation
+2. **GAP-GH1: Working Set Limitations** (GitHub Copilot) - Sequential batch processing
+3. *No high-priority gaps in Claude Code*
+
+### Medium Priority (Important)
+**Windsurf:**
+1. **GAP-W2: Granular Permissions** - Explicit rule instructions
+2. **GAP-W3: Custom Agent Types** - Persona rules
+3. **GAP-W6: Lifecycle Hooks** - Manual validation steps
+
+**GitHub Copilot:**
+4. **GAP-GH2: Lifecycle Hooks** - Explicit workflow steps in instructions
+5. **GAP-GH3: Large File Handling** - File decomposition or window-based editing
+
+**Claude Code:**
+6. **GAP-C1: AI-Driven Activation** - Better descriptions
+7. **GAP-C2: Pattern Learning** - Manual preference docs
+
+### Low Priority (Nice-to-Have)
+1. **GAP-W4: Customization Layer** (Windsurf) - Personal override rules
+2. **GAP-W5: Progressive Disclosure** (Windsurf) - Reference external docs
+3. **GAP-C3: Multiple Conversations** (Claude Code) - Session management
+4. **GAP-C4: Native IDE** (Claude Code) - Optimized CLI workflow
+5. **GAP-GH4: Multi-Repository Support** (GitHub Copilot) - Sequential multi-repo execution
+
+---
+
+## Platform Gap Overview
+
+| Platform | High Priority Gaps | Medium Priority Gaps | Low Priority Gaps |
+|----------|-------------------|---------------------|------------------|
+| **Claude Code** | 0 | 2 | 2 |
+| **Windsurf** | 1 | 3 | 2 |
+| **GitHub Copilot** | 1 | 2 | 1 |
+
+**Analysis:**
+- **Claude Code** has the fewest and least severe gaps (most complete feature set)
+- **Windsurf** has the most medium-priority gaps (missing core features like subagents, permissions, hooks)
+- **GitHub Copilot** has one critical gap (working set limits) that significantly impacts usability
+
+---
+
+## Next Steps for Phase 2
+
+Based on this gap analysis covering **three platforms** (Claude Code, Windsurf, GitHub Copilot), Phase 2 (Standard Template Design) should focus on:
+
+1. **Choose Standard Format:**
+   - **Option A:** Claude Code as base (most complete, preserves maximum features)
+   - **Option B:** Intersection standard (only features all three platforms support)
+   - **Option C:** Superset standard (include all features with platform tags)
+   - **Recommendation:** Option C (Superset) allows maximum expressiveness with clear platform compatibility markers
+
+2. **Define Required Fields:**
+   - Minimal common fields all three platforms support
+   - Optional fields for platform-specific features (tagged with platform)
+   - Clear documentation showing feature compatibility matrix
+
+3. **Workaround Documentation:**
+   - Document emulation patterns for each gap
+   - Provide conversion examples for all three platforms
+   - Test patterns on real projects
+
+4. **File Structure:**
+   - Standard directory layout compatible with all platforms
+   - Naming conventions (avoid platform-specific restrictions)
+   - Metadata schema supporting all three frontmatter formats
+
+5. **Platform Tags:**
+   - Define tagging system for platform-specific features
+   - Example: `platforms: [claude-code, windsurf]` or `copilot-only: true`
+   - Enable tools to filter/adapt based on target platform
+
+---
+
+## Sources
+
+- RESEARCH-claude-code.md
+- RESEARCH-windsurf.md
+- RESEARCH-github-copilot.md
+- CAPABILITY-MATRIX.md
+- TERMINOLOGY-MAPPING.md
+- Real-world testing and analysis
+- Community feedback and issue trackers
diff --git a/PLAN-phase-4.md b/PLAN-phase-4.md
new file mode 100644
index 0000000..ca8ba26
--- /dev/null
+++ b/PLAN-phase-4.md
@@ -0,0 +1,213 @@
+# Execution Plan - Phase 4
+
+## Overview
+
+**Phase:** Programmatic Mapping System
+**Created:** 2026-01-12
+**Status:** Complete
+
+## Context
+
+Phase 4 builds the automated translation system that converts templates between AI assistant formats. After documenting capabilities (Phase 1), defining the standard schema (Phase 2), and creating emulation patterns (Phase 3), we now need a programmatic tool that can deterministically transform templates from the standard format to platform-specific formats (Claude Code, Windsurf, GitHub Copilot).
+
+This phase creates the foundation for automated workflow portability by implementing:
+- Parser for the standard .ai-templates/ format
+- Generator for Claude Code .claude/skills/ format
+- Generator for Windsurf .windsurfrules/ format
+- CLI tool for executing conversions
+
+The mapping engine will use the transformation rules from PLATFORM-ADAPTERS.md and apply the emulation patterns from WORKAROUND-PATTERNS.md to produce working platform-specific files.
+
+## Tasks
+
+### Task 1: Design Mapping Engine Architecture
+
+**Status:** Completed
+
+**Objective:** Define the technical architecture and data structures for the template conversion system
+
+**Implementation:**
+```xml
+<task>
+  <action>
+    1. Create packages/cli/src/lib/template-mapper/ directory
+    2. Design core interfaces in packages/cli/src/lib/template-mapper/types.ts:
+       - TemplateMetadata: Parsed YAML frontmatter + markdown content
+       - PlatformAdapter: Interface with transform() and validate() methods
+       - MappingEngine: Orchestrator that coordinates parsing and generation
+       - ConversionOptions: User-configurable options (target platform, strict mode, warnings)
+    3. Document architecture in ARCHITECTURE-mapping-engine.md:
+       - Component diagram showing parser → engine → adapters → generators
+       - Data flow: Standard format → TemplateMetadata → PlatformAdapter → Platform files
+       - Error handling strategy (validation failures, missing fields, incompatible features)
+       - Extension points for adding new platforms
+    4. Define transformation pipeline:
+       - Parse: YAML frontmatter + markdown → TemplateMetadata
+       - Validate: Check schema compliance, compatibility markers
+       - Transform: Apply platform adapter rules from PLATFORM-ADAPTERS.md
+       - Emulate: Apply patterns from WORKAROUND-PATTERNS.md for missing features
+       - Generate: Write platform-specific files with correct structure
+  </action>
+  <verification>
+    - Architecture document includes component diagram and data flow
+    - types.ts defines all core interfaces with TypeScript types
+    - Transformation pipeline clearly documented with 5 stages
+    - Extension points identified for future platforms (GitHub Copilot generator)
+  </verification>
+  <rollback>
+    - git checkout HEAD -- packages/cli/src/lib/template-mapper/
+    - rm ARCHITECTURE-mapping-engine.md
+  </rollback>
+</task>
+```
+
+**Acceptance Criteria:**
+- [x] ARCHITECTURE-mapping-engine.md created with component diagram and data flow
+- [x] types.ts defines TemplateMetadata, PlatformAdapter, MappingEngine, ConversionOptions
+- [x] Transformation pipeline documented with parse → validate → transform → emulate → generate
+- [x] Extension points documented for adding GitHub Copilot generator in future
+
+---
+
+### Task 2: Implement Parser and Claude Code Generator
+
+**Status:** Completed
+
+**Objective:** Build the standard format parser and Claude Code platform adapter with full transformation logic
+
+**Implementation:**
+```xml
+<task>
+  <action>
+    1. Implement parser in packages/cli/src/lib/template-mapper/parser.ts:
+       - parseTemplate(filePath: string): TemplateMetadata
+       - Use gray-matter library to parse YAML frontmatter
+       - Validate frontmatter against STANDARD-SCHEMA.md specification
+       - Extract markdown content sections (workflows, examples, notes)
+       - Handle parse errors gracefully with clear error messages
+    2. Implement Claude Code adapter in packages/cli/src/lib/template-mapper/adapters/claude-code.ts:
+       - Implement PlatformAdapter interface with transform() method
+       - Map YAML frontmatter fields to Claude Code SKILL.md format per PLATFORM-ADAPTERS.md Section 3.1
+       - Generate markdown structure: frontmatter → description → workflows → examples
+       - Handle lifecycle hooks transformation (hookMappings)
+       - Apply agent spawning preservation (no emulation needed - native support)
+       - Write output to .claude/skills/{name}/SKILL.md
+    3. Add unit tests in packages/cli/test/lib/template-mapper/parser.test.ts:
+       - Test valid standard template parsing
+       - Test invalid YAML handling (malformed frontmatter)
+       - Test missing required fields (name, description)
+       - Test markdown content extraction
+    4. Add unit tests in packages/cli/test/lib/template-mapper/adapters/claude-code.test.ts:
+       - Test field mapping (name, description, triggers, workflows)
+       - Test hook transformation (userPromptSubmitHook → user-prompt-submit)
+       - Test file structure generation (.claude/skills/{name}/SKILL.md)
+       - Test agent spawning preservation
+  </action>
+  <verification>
+    - npm test passes all parser tests (valid input, invalid YAML, missing fields)
+    - npm test passes all Claude Code adapter tests (field mapping, hooks, structure)
+    - Can parse examples/skill-example.md successfully
+    - Can generate valid .claude/skills/test-runner/SKILL.md from skill-example.md
+    - Generated Claude Code file matches expected frontmatter structure
+  </verification>
+  <rollback>
+    - git checkout HEAD -- packages/cli/src/lib/template-mapper/parser.ts
+    - git checkout HEAD -- packages/cli/src/lib/template-mapper/adapters/claude-code.ts
+    - git checkout HEAD -- packages/cli/test/lib/template-mapper/
+    - npm test to verify rollback didn't break existing tests
+  </rollback>
+</task>
+```
+
+**Acceptance Criteria:**
+- [x] parser.ts implements parseTemplate() with YAML frontmatter + markdown extraction
+- [x] claude-code.ts implements full transformation per PLATFORM-ADAPTERS.md Section 1.1
+- [x] Unit tests cover valid input, error cases, field mapping, transformation (37 tests passing)
+- [x] settings.json generated when permissions field is present
+- [x] Generated output validated against Claude Code SKILL.md format
+
+---
+
+### Task 3: Implement Windsurf Generator and CLI Tool
+
+**Status:** Completed
+
+**Objective:** Build the Windsurf platform adapter with emulation patterns and create CLI interface for conversions
+
+**Implementation:**
+```xml
+<task>
+  <action>
+    1. Implement Windsurf adapter in packages/cli/src/lib/template-mapper/adapters/windsurf.ts:
+       - Implement PlatformAdapter interface with transform() method
+       - Map YAML frontmatter to Windsurf workflow format per PLATFORM-ADAPTERS.md Section 3.2
+       - Generate .windsurfrules/{name}.md with workflow structure
+       - Apply skill emulation pattern from WORKAROUND-PATTERNS.md Pattern 1:
+         * When input has subagent spawning: Add warning comment + generate rules/skill-loader.md
+         * Transform agent spawning calls to inline instructions
+       - Handle multi-file context (native support - no emulation needed)
+       - Generate rules/workflow-activator.md for automatic loading
+    2. Create CLI command in packages/cli/src/commands/convert/index.ts:
+       - Command: aiwcli convert <source> --to <platform>
+       - Supported platforms: claude-code, windsurf
+       - Options: --output <dir>, --strict (fail on incompatibilities)
+       - Use MappingEngine to orchestrate parser → adapter → file write
+       - Display conversion summary (files generated, warnings, compatibility notes)
+    3. Add unit tests in packages/cli/test/lib/template-mapper/adapters/windsurf.test.ts:
+       - Test field mapping (name → workflow name, description, triggers → activation)
+       - Test skill emulation pattern application (agent spawning → inline + warning)
+       - Test rules/skill-loader.md generation when needed
+       - Test multi-file context preservation
+    4. Add integration tests in packages/cli/test/integration/convert-command.test.ts:
+       - Test converting skill-example.md to Claude Code format
+       - Test converting skill-example.md to Windsurf format with emulation
+       - Test converting workflow-example.md to Claude Code format (reverse conversion)
+       - Test error handling (invalid input, unsupported platform)
+  </action>
+  <verification>
+    - npm test passes all Windsurf adapter tests (field mapping, emulation, structure)
+    - npm test passes all integration tests (convert command, error handling)
+    - aiwcli convert examples/skill-example.md --to windsurf generates valid workflow
+    - Generated Windsurf files include skill-loader.md when agent spawning detected
+    - aiwcli convert examples/workflow-example.md --to claude-code generates valid skill
+    - CLI displays clear warnings when applying emulation patterns
+  </verification>
+  <rollback>
+    - git checkout HEAD -- packages/cli/src/lib/template-mapper/adapters/windsurf.ts
+    - git checkout HEAD -- packages/cli/src/commands/convert/
+    - git checkout HEAD -- packages/cli/test/lib/template-mapper/adapters/windsurf.test.ts
+    - git checkout HEAD -- packages/cli/test/integration/convert-command.test.ts
+    - npm test to verify rollback didn't break existing tests
+  </rollback>
+</task>
+```
+
+**Acceptance Criteria:**
+- [x] windsurf.ts implements full transformation per PLATFORM-ADAPTERS.md Section 2
+- [x] Skill emulation patterns applied (allowed-tools → advisory, context:fork → markers, agent → persona rule)
+- [x] CLI command `aiw convert` implemented with --to and --output options
+- [x] Unit tests cover field mapping, emulation, multi-file context (56 tests passing)
+- [x] Generated Windsurf files validated against .windsurf/workflows/ format
+
+---
+
+## Verification
+
+**Phase Complete When:**
+- [x] All tasks completed
+- [x] All acceptance criteria met
+- [x] Architecture document (ARCHITECTURE-mapping-engine.md) created and reviewed
+- [x] Parser successfully parses standard format with YAML frontmatter
+- [x] Claude Code generator produces valid .claude/skills/ files
+- [x] Windsurf generator produces valid .windsurf/workflows/ files with emulation patterns
+- [x] CLI tool functional: `aiw convert <source> --to <platform>`
+- [x] All unit tests passing (56 tests)
+- [ ] Round-trip conversion tested: standard → Claude Code → verify format
+- [ ] Round-trip conversion tested: standard → Windsurf → verify format + emulation
+- [ ] Examples converted successfully (skill-example.md, workflow-example.md)
+- [ ] No regressions introduced to existing aiwcli commands
+- [ ] Changes committed atomically (3 commits: architecture, parser+claude, windsurf+cli)
+
+---
+
+**Maximum 3 tasks per plan to maintain fresh context**
diff --git a/PLAN-phase-5.md b/PLAN-phase-5.md
new file mode 100644
index 0000000..25654ec
--- /dev/null
+++ b/PLAN-phase-5.md
@@ -0,0 +1,394 @@
+# Execution Plan - Phase 5
+
+## Overview
+
+**Phase:** Semantic Content Transformation
+**Created:** 2026-01-12
+**Status:** Completed
+
+## Context
+
+Phase 4 built the template mapper that transforms **metadata** (YAML frontmatter) between platforms. However, the **content** (markdown body) passes through unchanged. This creates a problem: platform-specific constructs in content (e.g., "spawn agent X", "use the Task tool to delegate") become nonsensical on platforms that don't support them.
+
+Phase 5 addresses this by:
+1. Defining a schema for semantic constructs that appear in workflow content
+2. Building a parser that identifies these constructs
+3. Creating per-platform transformers that rewrite content appropriately
+
+**User Guidance:** Use task agents to conserve context. Design work with Opus agents proposing schemas, then review agents evaluating, using iterative refinement loops until reviews find no issues.
+
+### Iterative Refinement Loop Definition
+
+An iterative refinement loop (propose-review-iterate cycle) works as follows:
+
+1. **PROPOSE:** Proposer agent creates the artifact
+2. **REVIEW:** Reviewer agent evaluates with confidence score (1-10) and issue list
+   - **Blocking issue:** Any issue that would cause the artifact to be unusable for its purpose
+   - **Non-blocking issue:** Improvements that don't prevent basic functionality
+3. **ITERATE:** If confidence < 8 OR blocking issues exist, return to step 1 with feedback
+4. **TERMINATE:** Accept and proceed when confidence >= 8 with no blocking issues
+5. **FALLBACK:** Maximum 5 iterations. If threshold not met after 5 cycles, escalate to user.
+
+## Tasks
+
+### Task 1: Design Content Schema via Agent Iteration
+
+**Objective:** Create CONTENT-SCHEMA.md defining all semantic constructs that need transformation, using agent-based iterative refinement.
+
+**Implementation:**
+```xml
+<task>
+  <action>
+    Use agent-based iterative refinement loop to design the content schema:
+
+    1. PROPOSE PHASE (Opus agent via Task tool):
+       Spawn an Opus agent to propose CONTENT-SCHEMA.md containing:
+       - List of semantic constructs (agent spawning, tool calls, context switches, etc.)
+       - Detection patterns (regex/heuristics) for each construct
+       - Source platform identification (which platform uses this construct)
+       - Example instances from real workflows
+
+       Agent should analyze:
+       - WORKAROUND-PATTERNS.md for existing construct examples
+       - examples/skill-example.md (skill format, tool restrictions, activation patterns)
+       - examples/workflow-example.md (workflow emulation, Step 0 context gathering)
+       - examples/copilot-limited-context.md (skill decomposition, chaining patterns)
+       - RESEARCH-claude-code.md, RESEARCH-windsurf.md for platform-specific syntax
+
+       CONTENT-SCHEMA.md should follow this structure for each construct:
+       ```markdown
+       # Construct: {name}
+       ## Description: {what it represents}
+       ## Source Platform: {claude-code|windsurf|copilot}
+       ## Detection Pattern: {regex or heuristic}
+       ## Examples:
+       - Example 1: `{raw text}`
+       - Example 2: `{raw text}`
+       ```
+
+    2. REVIEW PHASE (Sonnet agent via Task tool):
+       Spawn a Sonnet review agent to evaluate the schema:
+       - Check for completeness (all constructs from WORKAROUND-PATTERNS.md covered?)
+       - Check for ambiguity (can detection patterns false-positive?)
+       - Check for missing edge cases
+       - Score confidence 1-10, list specific issues as BLOCKING or NON-BLOCKING
+
+    3. ITERATE until review confidence >= 8 with no blocking issues (max 5 iterations)
+
+    4. Write final CONTENT-SCHEMA.md to project root
+  </action>
+  <verification>
+    - CONTENT-SCHEMA.md exists with comprehensive construct coverage
+    - All constructs from WORKAROUND-PATTERNS.md are covered (minimum: agent-spawn, tool-call,
+      context-switch, permission-reference, model-decision-trigger, glob-pattern, persona-rule,
+      skill-chaining, context-gathering-protocol, activation-instruction)
+    - Each construct has: name, description, detection pattern, source platform
+    - Each construct has at least 2 example instances
+    - Review agent scores >= 8 confidence
+    - No blocking issues remain from final review
+  </verification>
+  <rollback>
+    - Delete CONTENT-SCHEMA.md
+    - git checkout HEAD -- CONTENT-SCHEMA.md (if committed)
+  </rollback>
+</task>
+```
+
+**Acceptance Criteria:**
+- [ ] CONTENT-SCHEMA.md created with comprehensive construct definitions
+- [ ] All semantic constructs from WORKAROUND-PATTERNS.md are documented
+- [ ] Detection patterns are specific enough to avoid false positives
+- [ ] Review agent confirms schema completeness with confidence >= 8
+- [ ] Example instances demonstrate each construct clearly
+
+---
+
+### Task 2: Implement Content Parser with Detection Engine
+
+**Objective:** Build content parser that extracts semantic constructs from markdown workflow content using the schema from Task 1.
+
+**Implementation:**
+```xml
+<task>
+  <action>
+    1. Add types to packages/cli/src/lib/template-mapper/types.ts (following project pattern):
+
+       ```typescript
+       /**
+        * Semantic construct identified in workflow content
+        */
+       export interface SemanticConstruct {
+         type: string;        // e.g., 'agent-spawn', 'tool-call', 'context-switch'
+         platform: Platform;  // source platform that uses this syntax
+         source: 'frontmatter' | 'body';  // where construct was found
+         location: {          // where in content
+           start: number;
+           end: number;
+           line: number;
+         };
+         rawText: string;     // original matched text
+         parsed: Record<string, unknown>; // extracted data
+       }
+
+       /**
+        * Result of parsing content for semantic constructs
+        */
+       export interface ContentAnalysis {
+         constructs: SemanticConstruct[];
+         rawContent: string;
+       }
+       ```
+
+    2. Create packages/cli/src/lib/template-mapper/content-parser.ts:
+
+       Import types from types.ts (following project pattern):
+       ```typescript
+       import type { Platform, SemanticConstruct, ContentAnalysis } from './types.js'
+       ```
+
+    3. Implement detection functions for ALL construct types from CONTENT-SCHEMA.md:
+       - detectAgentSpawning(): finds "spawn agent", "Task tool", subagent references
+       - detectToolCalls(): finds "use X tool", "call Y tool"
+       - detectContextSwitches(): finds "fork context", "inherit context"
+       - detectPermissionReferences(): finds tool restrictions, allowed-tools references
+       - detectModelDecisionTriggers(): finds "USE WHEN", "trigger: model_decision"
+       - detectGlobPatterns(): finds multi-file context references
+       - detectPersonaRules(): finds "@rules:agent-", persona activation
+       - detectSkillChaining(): finds "/prompt", skill references, "Part 1 -> Part 2"
+       - detectContextGatheringProtocols(): finds "Step 0", context checklist markers
+       - detectActivationInstructions(): finds "Invocation:", manual invoke guidance
+       (Detection functions must cover 100% of constructs from CONTENT-SCHEMA.md)
+
+    4. Create main parseContent(content: string): ContentAnalysis function
+       - Run all detectors
+       - Merge results with location tracking
+       - Handle overlapping matches:
+         - Prefer more specific (longer) matches over generic ones
+         - If same specificity, prefer earlier start position
+         - Nested constructs: outer construct contains inner in parsed.children
+       - Skip constructs found inside markdown code blocks (```...```)
+
+    5. Export from template-mapper/index.ts:
+       ```typescript
+       export { parseContent } from './content-parser.js'
+       export type { SemanticConstruct, ContentAnalysis } from './types.js'
+       ```
+
+    6. Write unit tests in packages/cli/test/lib/template-mapper/content-parser.test.ts:
+       - Test each construct type detection
+       - Test edge cases:
+         - Nested constructs
+         - No matches (plain markdown)
+         - Constructs inside code blocks (should skip)
+         - Multiple overlapping constructs
+         - Multi-line construct patterns
+         - Malformed/partial constructs
+  </action>
+  <verification>
+    - content-parser.ts exists with all detection functions
+    - Types added to types.ts following project centralization pattern
+    - Unit tests pass: npx mocha "test/lib/template-mapper/content-parser.test.ts"
+    - Parser correctly identifies constructs from example workflows
+    - No false positives on plain markdown or code blocks
+  </verification>
+  <rollback>
+    - Delete packages/cli/src/lib/template-mapper/content-parser.ts
+    - Delete packages/cli/test/lib/template-mapper/content-parser.test.ts
+    - Revert type additions in types.ts
+    - Remove exports from index.ts
+  </rollback>
+</task>
+```
+
+**Acceptance Criteria:**
+- [ ] Types (SemanticConstruct, ContentAnalysis) added to types.ts
+- [ ] content-parser.ts implements all detection functions from CONTENT-SCHEMA.md
+- [ ] parseContent() function correctly identifies constructs with location info
+- [ ] All unit tests pass (target: 20+ tests covering all construct types and edge cases)
+- [ ] Tests verify each construct type from the schema
+
+---
+
+### Task 3: Implement Content Transformers and CLI Integration
+
+**Objective:** Create per-platform content transformers and integrate semantic transformation into the `aiw convert` CLI.
+
+**Implementation:**
+```xml
+<task>
+  <action>
+    1. Add transformer types to packages/cli/src/lib/template-mapper/types.ts:
+
+       ```typescript
+       import type { Platform, ContentAnalysis, TransformationWarning } from './types.js'
+
+       /**
+        * Content transformer interface for platform-specific content rewriting
+        */
+       export interface ContentTransformer {
+         platform: Platform;
+         transform(analysis: ContentAnalysis): TransformedContent;
+       }
+
+       /**
+        * Result of content transformation
+        */
+       export interface TransformedContent {
+         content: string;
+         warnings: TransformationWarning[];
+       }
+       ```
+
+    2. Create packages/cli/src/lib/template-mapper/content-transformers.ts:
+
+       Implement platform-specific transformers:
+
+       a) Claude Code Transformer (minimal changes):
+          - Pass through most constructs (Claude Code is the reference platform)
+          - Convert Windsurf-specific syntax if present
+          - Warn on Windsurf-only constructs (model_decision, globs)
+
+       b) Windsurf Transformer:
+          - Inline agent prompts instead of spawn references:
+            "spawn agent X" -> Inline agent X's prompt directly in the workflow
+          - Convert "Task tool" references to sequential workflow steps
+          - Add advisory notes where constructs are emulated:
+            ```markdown
+            ## Tool Restrictions (Advisory)
+            > **NOTE:** These restrictions rely on AI compliance and are NOT enforced by Windsurf.
+            ```
+          - Handle GAP-W1: Windsurf cannot spawn parallel subagents like Claude Code's Task tool.
+            Transform "spawn agent X" to inlined instructions or sequential workflow steps.
+          - Include: "IMPORTANT: Before using tools outside this list, ask user for permission"
+
+       c) GitHub Copilot Transformer:
+          - Decompose large context references for 10-file limit
+          - Convert agent spawns to manual handoff suggestions:
+            "spawn agent X" -> "## Manual Handoff\nCreate separate chat session for: {task}"
+          - Generate skill chaining structure for large operations:
+            - Create coordinator prompt when content references >10 files
+            - Add "Next Steps" sections linking to sub-skills
+            - Generate progress tracking template (PROGRESS.md pattern)
+          - Add working set management guidance:
+            - Multi-file context refs -> Batch instructions: "Process files in groups of 10"
+            - Document as "@workspace constraints"
+
+    3. Write unit tests in packages/cli/test/lib/template-mapper/content-transformers.test.ts:
+       - Test WindsurfTransformer.transform() inlines agent spawning constructs
+       - Test CopilotTransformer.transform() decomposes large context references
+       - Test ClaudeCodeTransformer.transform() passes through correctly
+       - Test warning generation for unsupported constructs
+       - Test advisory section generation for Windsurf
+
+    4. Update platform adapters to use content transformers:
+       - Modify ClaudeCodeAdapter.transform():
+         ```typescript
+         // After parsing content, apply content transformation
+         const contentResult = claudeContentTransformer.transform(parsedContent)
+         const transformedContent = contentResult.content
+         warnings.push(...contentResult.warnings)
+         ```
+       - Modify WindsurfAdapter.transform() similarly
+       - Ensure warnings from content transformation are included in result
+
+    5. Extend ParsedTemplate type in types.ts:
+       ```typescript
+       export interface ParsedTemplate {
+         metadata: TemplateMetadata
+         content: string
+         sourcePath?: string
+         // Phase 5 addition:
+         contentAnalysis?: ContentAnalysis
+       }
+       ```
+
+    6. Write integration tests in packages/cli/test/integration/content-transform.test.ts:
+       - Test full conversion with content containing semantic constructs
+       - Verify output content is correctly transformed per platform
+       - Test round-trip verification:
+         - Semantic constructs survive round-trip (structural integrity)
+         - Warnings correctly identify emulation artifacts
+         - Note: Lossless round-trip is NOT expected due to platform capability gaps
+       - Test error handling:
+         - Content with unrecognized constructs
+         - Transformer exceptions
+         - Partial transformation failures
+
+    7. Test CLI end-to-end:
+       - aiw convert examples/workflow-example.md --to windsurf
+       - Verify content is transformed, not just metadata
+  </action>
+  <verification>
+    - content-transformers.ts exists with all platform transformers
+    - Types added to types.ts (ContentTransformer, TransformedContent)
+    - Unit tests for transformers pass
+    - Each adapter's transform() method applies content transformation
+    - aiw convert command transforms content correctly
+    - Integration tests pass covering semantic constructs
+    - Warnings generated for emulated/unsupported constructs
+  </verification>
+  <rollback>
+    - Delete packages/cli/src/lib/template-mapper/content-transformers.ts
+    - Delete packages/cli/test/lib/template-mapper/content-transformers.test.ts
+    - Delete packages/cli/test/integration/content-transform.test.ts
+    - Revert changes to claude-code.ts, windsurf.ts adapters
+    - Revert ParsedTemplate type extension in types.ts
+    - git checkout HEAD -- packages/cli/src/lib/template-mapper/
+  </rollback>
+</task>
+```
+
+**Acceptance Criteria:**
+- [ ] ContentTransformer interface defined in types.ts with platform-specific implementations
+- [ ] Windsurf transformer inlines agent prompts and adds advisory warnings
+- [ ] Copilot transformer handles context decomposition with skill chaining support
+- [ ] Unit tests for content-transformers.ts pass (target: 15+ tests)
+- [ ] CLI `aiw convert` transforms content, not just metadata
+- [ ] Warnings generated for emulated/unsupported content constructs
+- [ ] Integration tests verify end-to-end transformation
+
+---
+
+## Dependencies Between Tasks
+
+```
+Task 1 (Schema) ──► Task 2 (Parser) ──► Task 3 (Transformers)
+                    needs schema       needs parser
+```
+
+**Execution Order:**
+1. Task 1 must complete first to define CONTENT-SCHEMA.md
+2. Task 2 uses CONTENT-SCHEMA.md to implement detection functions
+3. Task 3 uses parser output to implement transformers
+
+---
+
+## Deliverables Summary
+
+| File | Purpose |
+|------|---------|
+| CONTENT-SCHEMA.md | Semantic construct definitions with detection patterns |
+| types.ts (additions) | SemanticConstruct, ContentAnalysis, ContentTransformer, TransformedContent types |
+| content-parser.ts | Parser to identify constructs in workflow content |
+| content-transformers.ts | Per-platform transformers for content rewriting |
+| content-parser.test.ts | Unit tests for parser |
+| content-transformers.test.ts | Unit tests for transformers |
+| content-transform.test.ts | Integration tests for end-to-end transformation |
+
+---
+
+## Verification
+
+**Phase Complete When:**
+- [ ] All tasks completed
+- [ ] All acceptance criteria met
+- [ ] No regressions introduced (existing tests still pass)
+- [ ] Changes committed atomically (one commit per task)
+- [ ] CONTENT-SCHEMA.md documents all semantic constructs from WORKAROUND-PATTERNS.md
+- [ ] Content parser correctly identifies platform-specific constructs
+- [ ] Content transformers rewrite content for each target platform
+- [ ] `aiw convert` CLI produces semantically correct output
+
+---
+
+**Maximum 3 tasks per plan to maintain fresh context**
diff --git a/PLATFORM-ADAPTERS.md b/PLATFORM-ADAPTERS.md
new file mode 100644
index 0000000..68b6a5a
--- /dev/null
+++ b/PLATFORM-ADAPTERS.md
@@ -0,0 +1,2117 @@
+# Platform Adapters: Transformation Rules
+
+**Version:** 1.0.0
+**Date:** 2026-01-12
+**Purpose:** Define deterministic transformation rules for converting superset templates to platform-native formats
+
+---
+
+## Overview
+
+This document specifies the **platform adapters** that transform templates written in the Standard Schema (superset format) into native formats for Claude Code, Windsurf, and GitHub Copilot. Each adapter handles:
+
+1. **Field Mapping** - Converting superset fields to platform-native equivalents
+2. **Emulation Patterns** - Workarounds for features not natively supported
+3. **Output Structure** - Platform-specific file locations and formats
+4. **Validation** - Platform-specific constraints and limits
+5. **Warning Generation** - Alerts for unsupported or degraded features
+
+---
+
+## Table of Contents
+
+1. [Claude Code Adapter](#1-claude-code-adapter)
+2. [Windsurf Adapter](#2-windsurf-adapter)
+3. [GitHub Copilot Adapter](#3-github-copilot-adapter)
+4. [Transformation Rules](#4-transformation-rules)
+5. [Complete Transformation Example](#5-complete-transformation-example)
+
+---
+
+## 1. Claude Code Adapter
+
+Claude Code is the **most feature-complete platform**, so the adapter primarily strips unused fields and restructures output for Claude Code's directory conventions.
+
+**See Also:** [WORKAROUND-PATTERNS.md Pattern 2](WORKAROUND-PATTERNS.md#pattern-2-workflow-emulation-for-claude-code) - Detailed workflow emulation pattern for converting Windsurf workflows with AI-driven activation to Claude Code skills
+
+### 1.1 Field Mapping
+
+| Superset Field | Claude Code Field | Transformation |
+|----------------|-------------------|----------------|
+| `name` | `name` | Direct copy (required) |
+| `description` | `description` | Direct copy |
+| `version` | `version` | Direct copy |
+| `allowed-tools` | `allowed-tools` | Direct copy as array |
+| `model` | `model` | Direct copy |
+| `context` | `context` | Direct copy (`inherit` or `fork`) |
+| `agent` | `agent` | Direct copy (reference to agent file) |
+| `permissions.allow` | `permissions.allow` | Direct copy as array |
+| `permissions.deny` | `permissions.deny` | Direct copy as array |
+| `trigger` | *(dropped)* | Windsurf-only field |
+| `globs` | *(dropped)* | Windsurf-only field |
+| `labels` | *(dropped)* | Windsurf-only field |
+| `alwaysApply` | *(dropped)* | Windsurf-only field |
+| `author` | *(dropped)* | Windsurf-only field |
+| `applyTo` | *(dropped)* | GitHub Copilot-only field |
+| `excludeAgent` | *(dropped)* | GitHub Copilot-only field |
+| `mode` | *(dropped)* | GitHub Copilot-only field |
+| `platforms` | *(dropped)* | Meta-field (processed by adapter) |
+| `compatibility` | *(dropped)* | Meta-field (documentation only) |
+| `emulation` | *(dropped)* | Meta-field (used by other adapters) |
+
+### 1.2 Dropped Fields (Windsurf/Copilot-Only)
+
+The following fields are **ignored** when generating Claude Code output:
+
+**Windsurf Fields:**
+- `trigger` - Activation modes not applicable (Claude uses auto-invoke via description)
+- `globs` - File patterns handled via `permissions` in Claude Code
+- `labels` - No categorization system in Claude Code
+- `alwaysApply` - Equivalent to placing content in CLAUDE.md
+- `author` - No attribution field in Claude Code
+
+**GitHub Copilot Fields:**
+- `applyTo` - Use `permissions` patterns instead
+- `excludeAgent` - No agent exclusion in Claude Code
+- `mode` - All Claude Code skills are implicitly "agent" mode
+
+### 1.3 Output Structure
+
+```
+.claude/
++-- skills/
+|   +-- {name}/
+|       +-- SKILL.md              # Main skill file with frontmatter
+|       +-- assets/               # Optional supporting files
+|       +-- CHUNKS/               # Optional chunked content
+|
++-- agents/
+|   +-- {agent-name}.md           # Custom agent definitions (if referenced)
+|
++-- settings.json                 # Permission grants (generated)
+```
+
+#### SKILL.md Output Format
+
+```yaml
+---
+name: {name}
+description: {description}
+version: {version}
+allowed-tools: {allowed-tools}
+model: {model}
+context: {context}
+agent: {agent}
+---
+
+{markdown_body}
+```
+
+### 1.4 Settings Generation
+
+When `permissions` are specified, generate or update `.claude/settings.json`:
+
+```json
+{
+  "permissions": {
+    "allow": [
+      "{permissions.allow[0]}",
+      "{permissions.allow[1]}"
+    ],
+    "deny": [
+      "{permissions.deny[0]}",
+      "{permissions.deny[1]}"
+    ]
+  }
+}
+```
+
+**Merging Rules:**
+
+**IMPORTANT:** Permissions in skill frontmatter are **PROJECT-SCOPED**, not skill-scoped. They are merged into the global `.claude/settings.json` and apply to the entire project, not just when the skill is active.
+
+**Merging Algorithm:**
+
+1. **Start with existing permissions:**
+   - If `.claude/settings.json` exists, load current `permissions.allow` and `permissions.deny` arrays
+   - If it doesn't exist, start with empty arrays: `{"permissions": {"allow": [], "deny": []}}`
+
+2. **Merge `allow` patterns:**
+   - Append all `permissions.allow` entries from skill frontmatter to existing `allow` array
+   - Remove duplicate patterns (exact string match)
+   - Result: `allow = deduplicate(existing_allow + skill_allow)`
+
+3. **Merge `deny` patterns:**
+   - Append all `permissions.deny` entries from skill frontmatter to existing `deny` array
+   - Remove duplicate patterns (exact string match)
+   - Result: `deny = deduplicate(existing_deny + skill_deny)`
+
+4. **No removal/replacement:**
+   - Skills ONLY ADD permissions, they never remove existing ones
+   - To remove permissions, manually edit `.claude/settings.json`
+
+**Conflict Resolution:**
+- At runtime, `deny` patterns take precedence over `allow` patterns
+- If a pattern matches both `allow` and `deny`, access is **denied**
+- Example: `allow: ["Read(**)"]` + `deny: ["Read(.env)"]` = can read all files except .env
+
+**Example Merge Scenario:**
+
+**Initial State** (`.claude/settings.json`):
+```json
+{
+  "permissions": {
+    "allow": ["Read(**/*.ts)"],
+    "deny": []
+  }
+}
+```
+
+**Skill A Added** (`permissions.allow: ["Write(src/**)"]`):
+```json
+{
+  "permissions": {
+    "allow": ["Read(**/*.ts)", "Write(src/**)"],
+    "deny": []
+  }
+}
+```
+
+**Skill B Added** (`permissions.deny: ["Write(src/critical/**)"]`):
+```json
+{
+  "permissions": {
+    "allow": ["Read(**/*.ts)", "Write(src/**)"],
+    "deny": ["Write(src/critical/**)"]
+  }
+}
+```
+
+**Result:** Can write to `src/**` EXCEPT `src/critical/**` (deny wins).
+
+**Common Pitfalls:**
+
+1. **Permission Accumulation:**
+   - Adding `permissions` to multiple skills will accumulate ALL permissions in project settings.json
+   - This can unintentionally grant broad access; review settings.json periodically
+
+2. **No Skill-Scoped Permissions:**
+   - Permissions apply PROJECT-WIDE, not just when the skill is active
+   - A restrictive skill cannot override more permissive project settings
+   - Consider creating separate projects for different security contexts
+
+3. **Manual Cleanup Required:**
+   - Removing a skill does NOT remove its permissions from settings.json
+   - Must manually edit settings.json to revoke accumulated permissions
+
+4. **Deny-Allow Interactions:**
+   - `allow: ["Bash(*)"]` + `deny: ["Bash(rm *)"]` = allows all bash EXCEPT rm commands
+   - Overly broad `allow` patterns may need specific `deny` patterns to restrict
+
+### 1.5 Example Transformation
+
+**Input (Superset Format):**
+
+```yaml
+---
+name: security-review
+description: USE WHEN reviewing code for security vulnerabilities
+version: "1.0.0"
+allowed-tools:
+  - Read
+  - Grep
+  - Glob
+  - Bash(npm audit)
+model: opus
+context: fork
+permissions:
+  allow:
+    - Read(**/*.ts)
+    - Read(**/*.js)
+  deny:
+    - Read(.env)
+    - Read(secrets/**)
+# Windsurf fields (ignored)
+trigger: model_decision
+globs: ["**/*.ts", "**/*.js"]
+labels: [security, review]
+# Copilot fields (ignored)
+applyTo: ["**/*.ts", "**/*.js"]
+mode: agent
+# Meta fields (processed)
+platforms: [claude-code, windsurf, github-copilot]
+---
+
+# Security Review
+
+Perform security analysis of the codebase...
+```
+
+**Output (Claude Code):**
+
+**File:** `.claude/skills/security-review/SKILL.md`
+
+```yaml
+---
+name: security-review
+description: USE WHEN reviewing code for security vulnerabilities
+version: "1.0.0"
+allowed-tools:
+  - Read
+  - Grep
+  - Glob
+  - Bash(npm audit)
+model: opus
+context: fork
+---
+
+# Security Review
+
+Perform security analysis of the codebase...
+```
+
+**File:** `.claude/settings.json` (merged)
+
+```json
+{
+  "permissions": {
+    "allow": [
+      "Read(**/*.ts)",
+      "Read(**/*.js)"
+    ],
+    "deny": [
+      "Read(.env)",
+      "Read(secrets/**)"
+    ]
+  }
+}
+```
+
+---
+
+## 2. Windsurf Adapter
+
+Windsurf has **fewer native features** than Claude Code, so this adapter uses **emulation patterns** extensively.
+
+### 2.1 Field Mapping
+
+| Superset Field | Windsurf Field | Transformation |
+|----------------|----------------|----------------|
+| `name` | *(filename)* | Filename becomes identifier |
+| `description` | `description` | Direct copy |
+| `version` | *(dropped or comment)* | No native field; add as comment |
+| `allowed-tools` | *(emulated)* | Convert to explicit instructions |
+| `model` | *(model selection)* | Platform setting |
+| `context` | *(emulated)* | Sequential workflow markers |
+| `agent` | *(emulated)* | Persona rules |
+| `permissions.allow` | *(emulated)* | Explicit rule instructions |
+| `permissions.deny` | *(emulated)* | Explicit rule warnings |
+| `trigger` | `trigger` | Direct copy |
+| `globs` | `globs` | Direct copy (required for `trigger: glob`) |
+| `labels` | `labels` | Direct copy as array |
+| `alwaysApply` | `alwaysApply` | Direct copy as boolean |
+| `author` | `author` | Direct copy |
+| `applyTo` | `globs` | Convert to glob patterns (if `trigger: glob`) |
+| `excludeAgent` | *(dropped)* | Not supported |
+| `mode` | *(dropped)* | Not applicable |
+| `platforms` | *(dropped)* | Meta-field |
+| `compatibility` | *(dropped)* | Meta-field |
+| `emulation` | *(applied)* | Patterns injected into body |
+
+### 2.2 Emulation Patterns
+
+**See Also:** [WORKAROUND-PATTERNS.md](WORKAROUND-PATTERNS.md) - Detailed skill emulation pattern with complete examples
+
+#### 2.2.1 allowed-tools to Explicit Instructions
+
+**Pattern:** Convert tool restrictions to explicit AI instructions (not enforced)
+
+**Input:**
+```yaml
+allowed-tools:
+  - Read
+  - Grep
+  - Bash(git *)
+```
+
+**Emulated Output (injected at top of body):**
+
+```markdown
+## Tool Restrictions (Advisory)
+
+> **NOTE:** These restrictions rely on AI compliance and are NOT enforced by the platform.
+
+**Allowed Operations:**
+- Read files
+- Search file contents (grep)
+- Git commands only (`git *`)
+
+**Forbidden Operations:**
+- Writing or editing files
+- Non-git shell commands
+- File creation
+
+**IMPORTANT:** Before using any tool not listed above, STOP and ask for user confirmation.
+```
+
+#### 2.2.2 context: fork to Sequential Workflow Markers
+
+**Pattern:** Emulate subagent isolation with explicit context boundaries
+
+**Input:**
+```yaml
+context: fork
+```
+
+**Emulated Output:**
+
+```markdown
+## Execution Context
+
+This workflow simulates isolated subagent execution.
+
+### Context Isolation Protocol
+
+When executing this workflow:
+
+1. **BEGIN ISOLATED CONTEXT** - Treat this as a fresh session
+2. Do NOT reference prior conversation history
+3. Do NOT make assumptions from previous context
+4. Complete ALL steps within this workflow before responding to other requests
+5. **END ISOLATED CONTEXT** - Resume normal session after completion
+
+---
+
+[CONTEXT: Isolated Execution - Act as if this is a fresh conversation]
+
+{original workflow content}
+
+[END CONTEXT: Return to normal session state]
+```
+
+#### 2.2.3 agent: to Persona Rules
+
+**Pattern:** Convert custom agent references to manual persona activation
+
+**Input:**
+```yaml
+agent: security-reviewer
+```
+
+**Emulated Output:**
+
+Creates a companion rule file `.windsurf/rules/agent-{agent-name}.md`:
+
+```yaml
+---
+trigger: manual
+description: Activate security-reviewer persona with @rules:agent-security-reviewer
+---
+
+# Security Reviewer Persona
+
+When @rules:agent-security-reviewer is active, adopt this persona:
+
+## Role
+You are a specialized security review agent.
+
+## Behavioral Guidelines
+{content from referenced agent file}
+
+## Activation
+User invokes with: `@rules:agent-security-reviewer`
+
+## Deactivation
+Returns to default Cascade behavior when user starts new topic.
+
+> **NOTE:** Tool restrictions cannot be enforced in Windsurf. Rely on AI compliance.
+```
+
+**Workflow Reference:**
+```markdown
+## Agent Persona
+
+This workflow uses the **security-reviewer** agent.
+Activate with: `@rules:agent-security-reviewer` before running this workflow.
+```
+
+#### 2.2.4 permissions to Glob Trigger Rules with Warnings
+
+**Pattern:** Convert permission patterns to advisory rules
+
+**Input:**
+```yaml
+permissions:
+  allow:
+    - Read(**/*.ts)
+    - Write(src/**/*.ts)
+  deny:
+    - Read(.env)
+    - Write(config/production.json)
+```
+
+**Emulated Output (companion rule file):**
+
+Creates `.windsurf/rules/permissions-{skill-name}.md`:
+
+```yaml
+---
+trigger: glob
+globs: [".env", "config/production.json", "secrets/**/*"]
+description: Security warning for restricted files
+---
+
+# SECURITY WARNING - Restricted File Access
+
+You are accessing a file that has ACCESS RESTRICTIONS in this project.
+
+## Restricted Patterns
+
+**FORBIDDEN - Do NOT access these files:**
+- `.env` - Environment secrets
+- `config/production.json` - Production configuration
+- `secrets/**/*` - All files in secrets directory
+
+## Required Actions
+
+1. **STOP** - Do not read or modify this file
+2. **WARN** - Alert the user about the attempted access
+3. **ASK** - Request explicit permission if access is truly needed
+
+> **WARNING:** These restrictions are NOT technically enforced.
+> Violating them may expose secrets or corrupt production configurations.
+```
+
+**Main Workflow Addition:**
+```markdown
+## Access Permissions (Advisory)
+
+This workflow has the following access restrictions:
+
+**Allowed:**
+- Read TypeScript files (`**/*.ts`)
+- Write to source directory (`src/**/*.ts`)
+
+**Forbidden:**
+- Environment files (`.env`)
+- Production config (`config/production.json`)
+
+See `@rules:permissions-{skill-name}` for enforcement details.
+```
+
+### 2.3 Dropped Fields
+
+**Claude Code-Only Fields:**
+- `allowed-tools` - Converted to advisory instructions
+- `model` - May be available in Windsurf settings
+- `context` - Emulated with markers (no true isolation)
+- `agent` - Emulated via persona rules
+- `permissions` - Converted to advisory rules
+
+**Emulation Notes:**
+| Dropped Field | Emulation Strategy | Limitations |
+|---------------|-------------------|-------------|
+| `allowed-tools` | Explicit instructions | Not enforced |
+| `context: fork` | Sequential markers | No true isolation |
+| `agent` | Persona rules | Manual activation |
+| `permissions` | Glob trigger warnings | Advisory only |
+| `hooks` | Workflow step instructions | No automatic execution |
+
+#### Lifecycle Hooks Emulation
+
+**Problem:** Windsurf does not have lifecycle hooks like Claude Code's PreToolUse, PostToolUse, Stop events.
+
+**Emulation Strategy:**
+
+When `hooks` field is present in superset template, convert hook logic to explicit workflow steps:
+
+**Input (Superset with hooks):**
+```yaml
+hooks:
+  PreToolUse:
+    - matcher: "Write|Edit"
+      hooks:
+        - type: command
+          command: "npm run lint"
+  Stop:
+    - hooks:
+        - type: command
+          command: "npm test"
+```
+
+**Output (Windsurf workflow with manual steps):**
+```markdown
+# {Skill Name}
+
+## Pre-Execution Checks
+
+**IMPORTANT:** Before making any file changes, run:
+```bash
+npm run lint
+```
+
+## Main Workflow
+
+{Main skill content}
+
+## Post-Execution Validation
+
+**IMPORTANT:** After completing work, run:
+```bash
+npm test
+```
+
+Ensure all tests pass before considering the task complete.
+```
+
+**Limitations:**
+- Not automatically enforced
+- Relies on AI following instructions
+- No hooks for tool-level events
+- User must manually verify execution
+
+### 2.4 Output Structure
+
+```
+.windsurf/
++-- workflows/
+|   +-- {name}.md                 # Main workflow file
+|
++-- rules/
+|   +-- agent-{agent-name}.md     # Emulated agent persona (if agent: used)
+|   +-- permissions-{name}.md     # Emulated permissions (if permissions: used)
+```
+
+### 2.5 Character Limit Handling
+
+**Limit:** 12,000 characters per file
+
+**Strategy:**
+
+1. **Check Length:** After transformation, measure total character count
+2. **If Under Limit:** Output as single file
+3. **If Over Limit:** Split into chunks
+
+**Chunking Process:**
+
+```
+.windsurf/
++-- workflows/
+    +-- {name}.md                 # Main entry (under limit)
+    +-- {name}-part-2.md          # Continuation
+    +-- {name}-part-3.md          # Additional parts as needed
+```
+
+**Main File (chunked):**
+```yaml
+---
+description: {description} (Part 1 of N)
+trigger: manual
+labels: {labels}
+---
+
+# {Name} - Part 1
+
+{First ~10,000 characters of content}
+
+---
+
+## Continuation
+
+This workflow continues in additional parts:
+- Part 2: `/workflow {name}-part-2`
+- Part 3: `/workflow {name}-part-3`
+
+Run parts sequentially for complete workflow execution.
+```
+
+**Splitting Algorithm:**
+1. Split at markdown heading boundaries (`##` or `###`)
+2. Keep logical sections together
+3. Each chunk must be self-contained enough to execute
+4. Add navigation links between chunks
+
+### 2.6 Example Transformation
+
+**Input (Superset Format):**
+
+```yaml
+---
+name: deploy-production
+description: Deploy application to production environment
+version: "2.0.0"
+allowed-tools:
+  - Bash(npm run build)
+  - Bash(docker *)
+  - Bash(kubectl *)
+context: fork
+agent: deployment-specialist
+permissions:
+  allow:
+    - Read(src/**)
+    - Read(config/**)
+  deny:
+    - Write(.env.production)
+trigger: manual
+labels: [deployment, production, automation]
+platforms: [claude-code, windsurf]
+---
+
+# Production Deployment
+
+## Prerequisites
+- Ensure all tests pass
+- Verify staging deployment successful
+
+## Deployment Steps
+1. Build production bundle
+2. Build Docker image
+3. Push to registry
+4. Deploy to Kubernetes
+
+## Verification
+- Check pod status
+- Verify health endpoints
+```
+
+**Output (Windsurf):**
+
+**File:** `.windsurf/workflows/deploy-production.md`
+
+```yaml
+---
+description: Deploy application to production environment
+trigger: manual
+labels:
+  - deployment
+  - production
+  - automation
+---
+
+# Production Deployment
+
+<!-- Version: 2.0.0 -->
+
+## Agent Persona
+
+This workflow uses the **deployment-specialist** agent.
+Activate with: `@rules:agent-deployment-specialist` before running this workflow.
+
+## Tool Restrictions (Advisory)
+
+> **NOTE:** These restrictions rely on AI compliance and are NOT enforced.
+
+**Allowed Operations:**
+- Build commands (`npm run build`)
+- Docker commands (`docker *`)
+- Kubernetes commands (`kubectl *`)
+
+**Forbidden Operations:**
+- Direct file editing
+- Non-deployment shell commands
+
+## Access Permissions (Advisory)
+
+**Allowed:**
+- Read source files (`src/**`)
+- Read configuration (`config/**`)
+
+**Forbidden:**
+- Write to production environment file (`.env.production`)
+
+---
+
+## Execution Context
+
+[CONTEXT: Isolated Execution - Treat as fresh session]
+
+## Prerequisites
+- Ensure all tests pass
+- Verify staging deployment successful
+
+## Deployment Steps
+1. Build production bundle
+2. Build Docker image
+3. Push to registry
+4. Deploy to Kubernetes
+
+## Verification
+- Check pod status
+- Verify health endpoints
+
+[END CONTEXT: Return to normal session]
+```
+
+**File:** `.windsurf/rules/agent-deployment-specialist.md`
+
+```yaml
+---
+trigger: manual
+description: Activate deployment-specialist persona with @rules:agent-deployment-specialist
+---
+
+# Deployment Specialist Persona
+
+When @rules:agent-deployment-specialist is active:
+
+## Role
+You are a specialized deployment automation agent focused on safe, reliable production deployments.
+
+## Behavioral Guidelines
+- Always verify prerequisites before deployment
+- Use rolling deployments to minimize downtime
+- Monitor deployment progress and rollback on failures
+- Never deploy without proper testing
+
+## Activation
+User invokes with: `@rules:agent-deployment-specialist`
+
+> **NOTE:** Tool restrictions cannot be enforced. Rely on AI compliance.
+```
+
+**File:** `.windsurf/rules/permissions-deploy-production.md`
+
+```yaml
+---
+trigger: glob
+globs: [".env.production"]
+description: Security warning for production environment file
+---
+
+# SECURITY WARNING - Production Environment File
+
+You are accessing `.env.production` which has WRITE RESTRICTIONS.
+
+## Required Actions
+
+1. **STOP** - Do not modify this file
+2. **WARN** - Alert the user
+3. **ASK** - Request explicit permission if modification is truly needed
+
+> **WARNING:** Modifying production environment without proper review may cause outages.
+```
+
+---
+
+## 3. GitHub Copilot Adapter
+
+GitHub Copilot has the **most restrictive constraints** (working set limits, context limits), so this adapter focuses on optimization and warnings.
+
+**See Also:** [WORKAROUND-PATTERNS.md Pattern 3](WORKAROUND-PATTERNS.md#pattern-3-working-set-limitation-pattern-for-github-copilot) - Detailed working set limitation pattern with skill decomposition, batch processing, file prioritization, and decision tree for when to split vs use @workspace
+
+### 3.1 Field Mapping
+
+| Superset Field | Copilot Field | Transformation |
+|----------------|---------------|----------------|
+| `name` | *(filename)* | Filename becomes identifier |
+| `description` | `description` | Direct copy |
+| `version` | *(comment)* | Add as comment in body |
+| `allowed-tools` | *(emulated)* | Convert to explicit instructions |
+| `model` | `model` | Pro+ only; add compatibility note |
+| `context` | *(emulated)* | Sequential batch notes |
+| `agent` | *(inline)* | Inline persona in prompt body |
+| `permissions.allow` | *(emulated)* | Convert to instructions |
+| `permissions.deny` | *(emulated)* | Convert to warnings |
+| `trigger` | *(emulated)* | Manual invocation pattern |
+| `globs` | `applyTo` | Convert to applyTo patterns |
+| `labels` | *(dropped)* | Not supported |
+| `alwaysApply` | *(dropped)* | Use copilot-instructions.md instead |
+| `author` | *(comment)* | Add as comment |
+| `applyTo` | `applyTo` | Direct copy (normalize string to array) |
+| `excludeAgent` | `excludeAgent` | Direct copy (normalize string to array) |
+| `mode` | `mode` | Direct copy (`agent`, `ask`, `edit`) |
+| `platforms` | *(dropped)* | Meta-field |
+| `compatibility` | *(dropped)* | Meta-field |
+| `emulation` | *(applied)* | Patterns injected into body |
+
+### 3.2 Emulation Patterns
+
+#### 3.2.1 allowed-tools to Explicit Instructions
+
+**Pattern:** Similar to Windsurf, convert to advisory instructions
+
+**Input:**
+```yaml
+allowed-tools:
+  - Read
+  - Write(src/**)
+  - Bash(npm test)
+```
+
+**Emulated Output:**
+
+```markdown
+## Operational Constraints
+
+**This prompt has the following tool restrictions:**
+
+Allowed:
+- Read any file
+- Write to source directory only (`src/**`)
+- Run tests (`npm test`)
+
+Not Allowed:
+- Write outside source directory
+- Run arbitrary shell commands
+- Delete files
+
+Please adhere to these constraints throughout execution.
+```
+
+#### 3.2.2 context: fork to Sequential Batch Notes
+
+**Pattern:** Document batch execution for large tasks
+
+**Input:**
+```yaml
+context: fork
+```
+
+**Emulated Output:**
+
+```markdown
+## Batch Execution Protocol
+
+This prompt may require multiple execution batches due to working set limits.
+
+### Execution Guidelines
+
+1. **Batch Size:** Process maximum 10 files per batch
+2. **Checkpoints:** Create checkpoint commits between batches
+3. **Context Preservation:** Document progress in `PROGRESS.md`
+4. **Resumption:** Use `PROGRESS.md` to resume if interrupted
+
+### Batch Template
+
+For each batch:
+1. Identify next 10 files to process
+2. Make changes
+3. Commit with message: `batch N: description`
+4. Update `PROGRESS.md`
+5. Continue to next batch
+```
+
+#### 3.2.3 Windsurf Triggers to applyTo Patterns
+
+**Pattern:** Convert Windsurf glob triggers to Copilot applyTo
+
+**Input:**
+```yaml
+trigger: glob
+globs:
+  - "**/*.py"
+  - "tests/**/*.py"
+```
+
+**Emulated Output:**
+
+```yaml
+applyTo:
+  - "**/*.py"
+  - "tests/**/*.py"
+```
+
+#### 3.2.4 agent: to Inline Persona
+
+**Pattern:** Inline agent personality into prompt body (no separate files)
+
+**Input:**
+```yaml
+agent: code-reviewer
+```
+
+**Emulated Output:**
+
+```markdown
+## Agent Persona: Code Reviewer
+
+For this task, adopt the following persona:
+
+**Role:** Expert code reviewer focused on quality and maintainability
+
+**Approach:**
+- Examine code for bugs, security issues, and anti-patterns
+- Provide specific, actionable feedback
+- Reference line numbers and file paths
+- Suggest concrete improvements
+
+**Tone:**
+- Constructive and professional
+- Educational where appropriate
+- Prioritize issues by severity
+
+---
+
+{Original prompt content follows}
+```
+
+### 3.3 Dropped Fields
+
+**Windsurf-Only Fields:**
+- `trigger` - Use manual invocation or convert to `applyTo`
+- `labels` - Not supported
+- `alwaysApply` - Use copilot-instructions.md for always-on content
+- `author` - Add as comment if needed
+
+**Emulation Notes:**
+| Dropped Field | Emulation Strategy | Limitations |
+|---------------|-------------------|-------------|
+| `trigger` | Manual or applyTo | No AI-driven activation |
+| `labels` | *(none)* | No categorization |
+| `alwaysApply` | Use instructions file | Different mechanism |
+| `allowed-tools` | Explicit instructions | Not enforced |
+| `context: fork` | Batch notes | No true isolation |
+| `hooks` | Workflow step instructions | No automatic execution |
+
+#### 3.3.1 Lifecycle Hooks Emulation
+
+**Problem:** GitHub Copilot does not have lifecycle hooks like Claude Code's PreToolUse, PostToolUse, Stop events.
+
+**Emulation Strategy:**
+
+When `hooks` field is present in superset template, convert hook logic to explicit prompt instructions:
+
+**Input (Superset with hooks):**
+```yaml
+hooks:
+  PreToolUse:
+    - matcher: "Write|Edit"
+      hooks:
+        - type: command
+          command: "npm run lint"
+  Stop:
+    - hooks:
+        - type: command
+          command: "git diff --check"
+```
+
+**Output (GitHub Copilot prompt with manual steps):**
+```markdown
+# {Skill Name}
+
+{Main content}
+
+## Pre-Change Validation
+
+Before modifying any files, execute:
+```bash
+npm run lint
+```
+
+Address any linting errors before proceeding.
+
+## Post-Completion Checklist
+
+After completing all changes, verify:
+
+1. Run: `git diff --check`
+2. Ensure no whitespace errors
+3. Confirm all modifications are intentional
+
+```
+
+**Limitations:**
+- Not automatically enforced
+- Relies on user/AI following instructions
+- No event-driven execution
+- Manual verification required
+
+### 3.4 Output Structure
+
+```
+.github/
++-- prompts/
+|   +-- {name}.prompt.md          # Main prompt file
+|
++-- instructions/
+|   +-- {name}.instructions.md    # Path-specific instructions (if applyTo used)
+|
++-- copilot-instructions.md       # Always-on instructions (if alwaysApply: true)
+```
+
+### 3.5 Working Set Limit Warnings
+
+**Limits:**
+- Maximum 10 files in working set
+- Maximum 20 files in context
+- ~6,000 character context window
+- Quality degrades >782 lines per file
+
+**Warning Injection:**
+
+When template references more than 10 files or complex operations:
+
+```markdown
+## Working Set Advisory
+
+> **WARNING:** GitHub Copilot has a 10-file working set limit.
+
+This prompt may reference more files than Copilot can handle simultaneously.
+
+**Recommended Approach:**
+
+1. Process files in batches of 10 or fewer
+2. Use explicit file lists rather than broad patterns
+3. Complete one batch before starting the next
+
+**File Batching Example:**
+```
+Batch 1: src/auth/*.ts (5 files)
+Batch 2: src/api/*.ts (5 files)
+Batch 3: tests/auth/*.test.ts (5 files)
+```
+
+See [GitHub Copilot Limits](https://docs.github.com/copilot) for details.
+```
+
+**Context Window Warning:**
+
+When body exceeds ~4,000 characters:
+
+```markdown
+> **NOTE:** This prompt approaches Copilot's ~6,000 character context limit.
+> Consider breaking into smaller focused prompts for better results.
+```
+
+### 3.6 Example Transformation
+
+**Input (Superset Format):**
+
+```yaml
+---
+name: typescript-refactor
+description: Refactor TypeScript codebase for better modularity
+version: "1.0.0"
+allowed-tools:
+  - Read
+  - Write
+  - Edit
+context: fork
+agent: refactoring-specialist
+trigger: manual
+globs:
+  - "**/*.ts"
+  - "**/*.tsx"
+applyTo:
+  - "**/*.ts"
+  - "**/*.tsx"
+mode: agent
+platforms: [claude-code, windsurf, github-copilot]
+---
+
+# TypeScript Refactoring
+
+## Goals
+- Improve code modularity
+- Extract reusable components
+- Reduce code duplication
+
+## Steps
+1. Analyze current structure
+2. Identify extraction candidates
+3. Create new modules
+4. Update imports
+5. Verify tests pass
+```
+
+**Output (GitHub Copilot):**
+
+**File:** `.github/prompts/typescript-refactor.prompt.md`
+
+```yaml
+---
+description: Refactor TypeScript codebase for better modularity
+applyTo:
+  - "**/*.ts"
+  - "**/*.tsx"
+mode: agent
+---
+
+# TypeScript Refactoring
+
+<!-- Version: 1.0.0 -->
+<!-- Author: Generated from cross-platform template -->
+
+## Agent Persona: Refactoring Specialist
+
+For this task, adopt the following persona:
+
+**Role:** Expert code refactoring specialist focused on modularity and clean architecture
+
+**Approach:**
+- Analyze code structure before making changes
+- Make incremental, testable changes
+- Preserve existing functionality
+- Document significant architectural decisions
+
+---
+
+## Operational Constraints
+
+**This prompt has the following tool restrictions:**
+
+Allowed:
+- Read any TypeScript file
+- Write/Edit TypeScript files
+
+Please adhere to these constraints throughout execution.
+
+---
+
+## Working Set Advisory
+
+> **WARNING:** GitHub Copilot has a 10-file working set limit.
+
+For large refactoring tasks:
+1. Process files in batches of 10 or fewer
+2. Complete one module extraction before starting the next
+3. Commit between batches
+
+---
+
+## Batch Execution Protocol
+
+This refactoring may require multiple execution batches.
+
+### Execution Guidelines
+
+1. **Batch Size:** Process maximum 10 files per batch
+2. **Checkpoints:** Create checkpoint commits between batches
+3. **Resumption:** Document progress for interrupted sessions
+
+---
+
+## Goals
+- Improve code modularity
+- Extract reusable components
+- Reduce code duplication
+
+## Steps
+1. Analyze current structure
+2. Identify extraction candidates
+3. Create new modules
+4. Update imports
+5. Verify tests pass
+```
+
+**File:** `.github/instructions/typescript.instructions.md`
+
+```yaml
+---
+applyTo:
+  - "**/*.ts"
+  - "**/*.tsx"
+---
+
+# TypeScript Development Instructions
+
+When working with TypeScript files, apply refactoring best practices:
+
+- Improve code modularity
+- Extract reusable components
+- Reduce code duplication
+```
+
+---
+
+## 4. Transformation Rules
+
+### 4.1 Field Precedence
+
+When multiple values could apply, use this precedence order:
+
+1. **Platform-specific override** (highest priority)
+2. **Superset standard field**
+3. **Emulated/converted value**
+4. **Default value** (lowest priority)
+
+**Example:**
+```yaml
+# Superset template
+model: sonnet                    # Standard field
+# If windsurf.model exists in platform config, it overrides
+```
+
+### 4.2 Conditional Inclusion
+
+Use the `platforms` field to determine which platforms receive output:
+
+```yaml
+platforms:
+  - claude-code
+  - windsurf
+  # github-copilot NOT listed = no output generated for Copilot
+```
+
+**Algorithm:**
+```
+for each target_platform in [claude-code, windsurf, github-copilot]:
+    if platforms is not defined OR target_platform in platforms:
+        generate_output(template, target_platform)
+    else:
+        skip_platform(target_platform)
+```
+
+### 4.3 Warning Generation
+
+Generate warnings for:
+
+1. **Unsupported Features:** When a feature doesn't exist on target platform
+2. **Degraded Features:** When emulation is imperfect
+3. **Limit Violations:** When content exceeds platform limits
+4. **Security Concerns:** When permission emulation is advisory-only
+
+**Warning Format:**
+
+```markdown
+> **WARNING [{CATEGORY}]:** {message}
+>
+> {details}
+```
+
+**Warning Categories:**
+- `UNSUPPORTED` - Feature doesn't exist
+- `EMULATED` - Feature is approximated
+- `LIMIT` - Platform constraint exceeded
+- `SECURITY` - Advisory-only restriction
+- `DEGRADED` - Reduced functionality
+
+### 4.4 Compatibility Notes Injection
+
+When `compatibility` field exists, inject relevant notes:
+
+```yaml
+compatibility:
+  windsurf:
+    status: partial
+    notes: "Subagent spawning emulated via sequential workflows"
+```
+
+**Injected (Windsurf output):**
+
+```markdown
+## Platform Compatibility Note
+
+> **NOTE [COMPATIBILITY]:** This template has partial support on Windsurf.
+> Subagent spawning emulated via sequential workflows.
+```
+
+### 4.5 Transformation Pipeline
+
+```
+                    +-------------------+
+                    |  Superset Template |
+                    +-------------------+
+                             |
+                             v
+                    +-------------------+
+                    |  Parse Frontmatter |
+                    +-------------------+
+                             |
+                             v
+                    +-------------------+
+                    | Check `platforms` |
+                    +-------------------+
+                             |
+              +--------------+--------------+
+              |              |              |
+              v              v              v
+     +----------------+ +----------------+ +----------------+
+     | Claude Adapter | | Windsurf Adapter| | Copilot Adapter|
+     +----------------+ +----------------+ +----------------+
+              |              |              |
+              v              v              v
+     +----------------+ +----------------+ +----------------+
+     | Map Fields     | | Map Fields     | | Map Fields     |
+     | Drop Unused    | | Apply Emulation| | Apply Emulation|
+     +----------------+ +----------------+ +----------------+
+              |              |              |
+              v              v              v
+     +----------------+ +----------------+ +----------------+
+     | Generate       | | Check Limits   | | Check Limits   |
+     | settings.json  | | Chunk if >12K  | | Add Warnings   |
+     +----------------+ +----------------+ +----------------+
+              |              |              |
+              v              v              v
+     +----------------+ +----------------+ +----------------+
+     | Output:        | | Output:        | | Output:        |
+     | .claude/skills/| | .windsurf/     | | .github/prompts|
+     +----------------+ +----------------+ +----------------+
+```
+
+---
+
+## 5. Complete Transformation Example
+
+This section demonstrates transforming a complex template to all three platforms.
+
+### 5.1 Input: Superset Template
+
+**File:** `.ai-templates/skills/full-stack-review/SKILL.md`
+
+```yaml
+---
+# ============================================
+# CORE FIELDS (Universal)
+# ============================================
+name: full-stack-review
+description: >
+  USE WHEN performing comprehensive code review. Reviews frontend React
+  components, backend Node.js APIs, and database interactions for security,
+  performance, and maintainability issues.
+version: "2.1.0"
+
+# ============================================
+# CLAUDE CODE FIELDS
+# ============================================
+allowed-tools:
+  - Read
+  - Grep
+  - Glob
+  - Bash(npm audit)
+  - Bash(npm run lint)
+  - Bash(npm test)
+model: opus
+context: fork
+agent: senior-reviewer
+permissions:
+  allow:
+    - Read(**/*.ts)
+    - Read(**/*.tsx)
+    - Read(**/*.js)
+    - Read(package.json)
+    - Read(package-lock.json)
+  deny:
+    - Read(.env)
+    - Read(.env.*)
+    - Read(secrets/**)
+    - Write(**)
+
+# ============================================
+# WINDSURF FIELDS
+# ============================================
+trigger: model_decision
+globs:
+  - "**/*.ts"
+  - "**/*.tsx"
+  - "**/*.js"
+labels:
+  - code-review
+  - security
+  - full-stack
+alwaysApply: false
+author: "Engineering Team <eng@example.com>"
+
+# ============================================
+# GITHUB COPILOT FIELDS
+# ============================================
+applyTo:
+  - "**/*.ts"
+  - "**/*.tsx"
+  - "**/*.js"
+excludeAgent:
+  - coding-agent
+mode: agent
+
+# ============================================
+# CROSS-PLATFORM FIELDS
+# ============================================
+platforms:
+  - claude-code
+  - windsurf
+  - github-copilot
+
+compatibility:
+  claude-code:
+    status: full
+    notes: "Full feature support with subagent isolation"
+  windsurf:
+    status: partial
+    notes: "No subagent isolation; permissions are advisory only"
+  github-copilot:
+    status: partial
+    notes: "Limited to 10 files per review batch"
+
+emulation:
+  subagents:
+    pattern: sequential-workflow
+    fallback: "Execute review phases sequentially"
+    limitations:
+      - "No parallel execution"
+      - "Context pollution risk"
+  permissions:
+    pattern: explicit-rules
+    fallback: "Document restrictions as instructions"
+    limitations:
+      - "Not enforced by platform"
+---
+
+# Full Stack Code Review
+
+Perform a comprehensive review of the full-stack application.
+
+## Review Phases
+
+### Phase 1: Security Analysis
+- Check for injection vulnerabilities
+- Review authentication flows
+- Audit authorization logic
+- Scan for exposed secrets
+
+### Phase 2: Frontend Review
+- React component best practices
+- State management patterns
+- Performance optimizations
+- Accessibility compliance
+
+### Phase 3: Backend Review
+- API design patterns
+- Error handling
+- Database query efficiency
+- Input validation
+
+### Phase 4: Dependency Audit
+- Run `npm audit` for vulnerabilities
+- Check for outdated packages
+- Review license compliance
+
+## Output Format
+
+Create `REVIEW-REPORT.md` with:
+- Executive summary
+- Critical issues (must fix)
+- Warnings (should fix)
+- Suggestions (nice to have)
+- Metrics and scores
+```
+
+### 5.2 Output: Claude Code
+
+**File:** `.claude/skills/full-stack-review/SKILL.md`
+
+```yaml
+---
+name: full-stack-review
+description: >
+  USE WHEN performing comprehensive code review. Reviews frontend React
+  components, backend Node.js APIs, and database interactions for security,
+  performance, and maintainability issues.
+version: "2.1.0"
+allowed-tools:
+  - Read
+  - Grep
+  - Glob
+  - Bash(npm audit)
+  - Bash(npm run lint)
+  - Bash(npm test)
+model: opus
+context: fork
+agent: senior-reviewer
+---
+
+# Full Stack Code Review
+
+Perform a comprehensive review of the full-stack application.
+
+## Review Phases
+
+### Phase 1: Security Analysis
+- Check for injection vulnerabilities
+- Review authentication flows
+- Audit authorization logic
+- Scan for exposed secrets
+
+### Phase 2: Frontend Review
+- React component best practices
+- State management patterns
+- Performance optimizations
+- Accessibility compliance
+
+### Phase 3: Backend Review
+- API design patterns
+- Error handling
+- Database query efficiency
+- Input validation
+
+### Phase 4: Dependency Audit
+- Run `npm audit` for vulnerabilities
+- Check for outdated packages
+- Review license compliance
+
+## Output Format
+
+Create `REVIEW-REPORT.md` with:
+- Executive summary
+- Critical issues (must fix)
+- Warnings (should fix)
+- Suggestions (nice to have)
+- Metrics and scores
+```
+
+**File:** `.claude/settings.json` (merged)
+
+```json
+{
+  "permissions": {
+    "allow": [
+      "Read(**/*.ts)",
+      "Read(**/*.tsx)",
+      "Read(**/*.js)",
+      "Read(package.json)",
+      "Read(package-lock.json)"
+    ],
+    "deny": [
+      "Read(.env)",
+      "Read(.env.*)",
+      "Read(secrets/**)",
+      "Write(**)"
+    ]
+  }
+}
+```
+
+**File:** `.claude/agents/senior-reviewer.md`
+
+```yaml
+---
+name: senior-reviewer
+description: Senior code reviewer with security focus
+allowed-tools:
+  - Read
+  - Grep
+  - Glob
+---
+
+# Senior Reviewer Agent
+
+You are a senior code reviewer with expertise in:
+- Security vulnerability detection
+- Performance optimization
+- Clean code principles
+- Full-stack architecture
+
+## Review Approach
+- Be thorough but constructive
+- Prioritize issues by severity
+- Provide specific remediation steps
+- Include code examples when helpful
+```
+
+---
+
+### 5.3 Output: Windsurf
+
+**File:** `.windsurf/workflows/full-stack-review.md`
+
+```yaml
+---
+description: >
+  USE WHEN performing comprehensive code review. Reviews frontend React
+  components, backend Node.js APIs, and database interactions for security,
+  performance, and maintainability issues.
+trigger: model_decision
+globs:
+  - "**/*.ts"
+  - "**/*.tsx"
+  - "**/*.js"
+labels:
+  - code-review
+  - security
+  - full-stack
+author: "Engineering Team <eng@example.com>"
+---
+
+# Full Stack Code Review
+
+<!-- Version: 2.1.0 -->
+
+## Platform Compatibility Note
+
+> **NOTE [COMPATIBILITY]:** This template has partial support on Windsurf.
+> No subagent isolation; permissions are advisory only.
+
+---
+
+## Agent Persona
+
+This workflow uses the **senior-reviewer** agent.
+Activate with: `@rules:agent-senior-reviewer` before running this workflow.
+
+---
+
+## Tool Restrictions (Advisory)
+
+> **WARNING [SECURITY]:** These restrictions rely on AI compliance and are NOT enforced.
+
+**Allowed Operations:**
+- Read files
+- Search file contents (grep/glob)
+- Run `npm audit`
+- Run `npm run lint`
+- Run `npm test`
+
+**Forbidden Operations:**
+- Writing or editing ANY files
+- Non-audit shell commands
+
+**IMPORTANT:** Before using any tool not listed above, STOP and ask for user confirmation.
+
+---
+
+## Access Permissions (Advisory)
+
+**Allowed:**
+- Read TypeScript files (`**/*.ts`, `**/*.tsx`)
+- Read JavaScript files (`**/*.js`)
+- Read package files (`package.json`, `package-lock.json`)
+
+**Forbidden:**
+- Environment files (`.env`, `.env.*`)
+- Secrets directory (`secrets/**`)
+- Write to ANY files (`**`)
+
+See `@rules:permissions-full-stack-review` for enforcement details.
+
+---
+
+## Execution Context
+
+[CONTEXT: Isolated Execution - Treat as fresh session]
+
+This workflow simulates isolated subagent execution. Complete ALL phases within this workflow before responding to other requests.
+
+---
+
+## Review Phases
+
+### Phase 1: Security Analysis
+[CONTEXT: Acting as security specialist]
+- Check for injection vulnerabilities
+- Review authentication flows
+- Audit authorization logic
+- Scan for exposed secrets
+[END CONTEXT]
+
+### Phase 2: Frontend Review
+[CONTEXT: Acting as frontend specialist]
+- React component best practices
+- State management patterns
+- Performance optimizations
+- Accessibility compliance
+[END CONTEXT]
+
+### Phase 3: Backend Review
+[CONTEXT: Acting as backend specialist]
+- API design patterns
+- Error handling
+- Database query efficiency
+- Input validation
+[END CONTEXT]
+
+### Phase 4: Dependency Audit
+[CONTEXT: Acting as security auditor]
+- Run `npm audit` for vulnerabilities
+- Check for outdated packages
+- Review license compliance
+[END CONTEXT]
+
+---
+
+[END CONTEXT: Return to normal session]
+
+## Output Format
+
+Create `REVIEW-REPORT.md` with:
+- Executive summary
+- Critical issues (must fix)
+- Warnings (should fix)
+- Suggestions (nice to have)
+- Metrics and scores
+```
+
+**File:** `.windsurf/rules/agent-senior-reviewer.md`
+
+```yaml
+---
+trigger: manual
+description: Activate senior-reviewer persona with @rules:agent-senior-reviewer
+---
+
+# Senior Reviewer Persona
+
+When @rules:agent-senior-reviewer is active, adopt this persona:
+
+## Role
+You are a senior code reviewer with expertise in security vulnerability detection, performance optimization, clean code principles, and full-stack architecture.
+
+## Behavioral Guidelines
+- Be thorough but constructive
+- Prioritize issues by severity
+- Provide specific remediation steps
+- Include code examples when helpful
+
+## Focus Areas
+- Security vulnerabilities
+- Performance bottlenecks
+- Code maintainability
+- Best practice violations
+
+## Activation
+User invokes with: `@rules:agent-senior-reviewer`
+
+## Deactivation
+Returns to default Cascade behavior when user starts new topic.
+
+> **NOTE:** Tool restrictions cannot be enforced in Windsurf. Rely on AI compliance.
+```
+
+**File:** `.windsurf/rules/permissions-full-stack-review.md`
+
+```yaml
+---
+trigger: glob
+globs:
+  - ".env"
+  - ".env.*"
+  - "secrets/**/*"
+description: Security warning for restricted files during code review
+---
+
+# SECURITY WARNING - Restricted File Access
+
+You are accessing a file that has ACCESS RESTRICTIONS during code review.
+
+## Restricted Patterns
+
+**FORBIDDEN - Do NOT access these files:**
+- `.env` - Environment secrets
+- `.env.*` - Environment variants
+- `secrets/**/*` - All files in secrets directory
+
+## Required Actions
+
+1. **STOP** - Do not read this file
+2. **WARN** - Alert the user about the attempted access
+3. **SKIP** - Continue review without accessing restricted files
+
+> **WARNING:** These restrictions are NOT technically enforced.
+> Accessing these files may expose secrets in review output.
+```
+
+---
+
+### 5.4 Output: GitHub Copilot
+
+**File:** `.github/prompts/full-stack-review.prompt.md`
+
+```yaml
+---
+description: >
+  USE WHEN performing comprehensive code review. Reviews frontend React
+  components, backend Node.js APIs, and database interactions for security,
+  performance, and maintainability issues.
+applyTo:
+  - "**/*.ts"
+  - "**/*.tsx"
+  - "**/*.js"
+excludeAgent:
+  - coding-agent
+mode: agent
+---
+
+# Full Stack Code Review
+
+<!-- Version: 2.1.0 -->
+<!-- Author: Engineering Team <eng@example.com> -->
+
+## Platform Compatibility Note
+
+> **NOTE [COMPATIBILITY]:** This template has partial support on GitHub Copilot.
+> Limited to 10 files per review batch.
+
+---
+
+## Agent Persona: Senior Reviewer
+
+For this task, adopt the following persona:
+
+**Role:** Senior code reviewer with expertise in security vulnerability detection, performance optimization, clean code principles, and full-stack architecture.
+
+**Approach:**
+- Be thorough but constructive
+- Prioritize issues by severity
+- Provide specific remediation steps
+- Include code examples when helpful
+
+**Focus Areas:**
+- Security vulnerabilities
+- Performance bottlenecks
+- Code maintainability
+- Best practice violations
+
+---
+
+## Operational Constraints
+
+> **WARNING [SECURITY]:** These restrictions are advisory and rely on AI compliance.
+
+**Allowed Operations:**
+- Read TypeScript files (`**/*.ts`, `**/*.tsx`)
+- Read JavaScript files (`**/*.js`)
+- Read package files (`package.json`, `package-lock.json`)
+- Run `npm audit`
+- Run `npm run lint`
+- Run `npm test`
+
+**Forbidden Operations:**
+- Reading environment files (`.env`, `.env.*`)
+- Reading secrets directory (`secrets/**`)
+- Writing or editing ANY files
+
+---
+
+## Working Set Advisory
+
+> **WARNING [LIMIT]:** GitHub Copilot has a 10-file working set limit.
+
+This code review may reference more files than Copilot can handle simultaneously.
+
+**Recommended Batch Approach:**
+
+1. **Batch 1: Security-Critical Files** (max 10 files)
+   - Authentication modules
+   - Authorization logic
+   - Input validation
+
+2. **Batch 2: Frontend Components** (max 10 files)
+   - React components
+   - State management
+   - UI utilities
+
+3. **Batch 3: Backend APIs** (max 10 files)
+   - API routes
+   - Controllers
+   - Database queries
+
+4. **Batch 4: Remaining Files**
+   - Utilities
+   - Configuration
+   - Tests
+
+---
+
+## Batch Execution Protocol
+
+> **WARNING [EMULATED]:** Subagent isolation emulated via sequential batches.
+
+### Execution Guidelines
+
+1. **Batch Size:** Process maximum 10 files per phase
+2. **Checkpoints:** Document findings after each phase
+3. **Context Preservation:** Maintain running list of issues
+4. **Completion:** Consolidate into final report
+
+---
+
+## Review Phases
+
+### Phase 1: Security Analysis
+- Check for injection vulnerabilities
+- Review authentication flows
+- Audit authorization logic
+- Scan for exposed secrets
+
+### Phase 2: Frontend Review
+- React component best practices
+- State management patterns
+- Performance optimizations
+- Accessibility compliance
+
+### Phase 3: Backend Review
+- API design patterns
+- Error handling
+- Database query efficiency
+- Input validation
+
+### Phase 4: Dependency Audit
+- Run `npm audit` for vulnerabilities
+- Check for outdated packages
+- Review license compliance
+
+---
+
+## Output Format
+
+Create `REVIEW-REPORT.md` with:
+- Executive summary
+- Critical issues (must fix)
+- Warnings (should fix)
+- Suggestions (nice to have)
+- Metrics and scores
+```
+
+**File:** `.github/instructions/code-review.instructions.md`
+
+```yaml
+---
+applyTo:
+  - "**/*.ts"
+  - "**/*.tsx"
+  - "**/*.js"
+---
+
+# Code Review Standards
+
+When reviewing code in this project:
+
+## Security Checks
+- Always check for injection vulnerabilities
+- Verify authentication and authorization logic
+- Scan for exposed secrets or credentials
+
+## Quality Checks
+- Follow React component best practices
+- Ensure proper error handling
+- Validate all inputs
+
+## Restrictions
+- Do NOT access `.env` or secrets files
+- Do NOT modify files during review
+```
+
+---
+
+## Summary
+
+This document provides complete, deterministic transformation rules for converting superset templates to all three platforms:
+
+| Platform | Transformation Complexity | Key Challenges |
+|----------|--------------------------|----------------|
+| **Claude Code** | Low | Mostly field dropping |
+| **Windsurf** | Medium | Extensive emulation needed |
+| **GitHub Copilot** | Medium-High | Limit warnings and batching |
+
+**Key Patterns:**
+1. Claude Code receives the most features natively
+2. Windsurf requires persona rules and advisory restrictions
+3. GitHub Copilot requires batching guidance and limit warnings
+
+**All adapters follow:**
+- Deterministic field mapping
+- Consistent warning format
+- Clear emulation documentation
+- Platform-specific output locations
+
+---
+
+## 6. Security Considerations
+
+### 6.1 Permission Enforcement Limitations
+
+**CRITICAL:** Permission emulation varies significantly across platforms. Understanding these differences is essential for security-critical operations.
+
+| Platform | Permission Enforcement | Risk Level |
+|----------|----------------------|------------|
+| **Claude Code** | **Enforced** - `allowed-tools` and `permissions` are runtime-enforced by the system | ✅ Low |
+| **Windsurf** | **Advisory Only** - Emulated via markdown instructions; AI may ignore restrictions | ⚠️ High |
+| **GitHub Copilot** | **Advisory Only** - Emulated via markdown instructions; AI may ignore restrictions | ⚠️ High |
+
+**What This Means:**
+
+- **Claude Code:** If a skill specifies `allowed-tools: [Read]`, the system will **prevent** Write/Bash/other tool usage. Permissions are hard-enforced.
+
+- **Windsurf:** If emulation adds "## Tool Restrictions (Advisory)", the AI is **instructed** to follow them, but there is **no system enforcement**. The AI can still use restricted tools if prompted or if it determines it's necessary.
+
+- **GitHub Copilot:** Same as Windsurf - advisory only, no system enforcement.
+
+### 6.2 Security Recommendations
+
+**For Security-Critical Operations:**
+
+1. **Use Claude Code for enforced restrictions**
+   - If a skill handles sensitive data (credentials, secrets, production systems)
+   - If tool restrictions are required for safety (prevent `Bash(rm -rf *)`, etc.)
+   - If permission boundaries must be guaranteed
+
+2. **Treat Windsurf/Copilot permissions as guidance**
+   - Do NOT rely on emulated permissions for security
+   - Assume AI can access any tool/file unless you configure IDE-level restrictions
+   - Review AI actions carefully when working with sensitive data
+
+3. **Defense in Depth**
+   - Use `.gitignore` to prevent accidental commits of sensitive files
+   - Use file system permissions to restrict access at OS level
+   - Configure IDE/workspace permissions where available
+   - Employ code review for all AI-generated changes to sensitive areas
+
+**Warning Injection:**
+
+Platform adapters automatically inject security warnings for Windsurf and GitHub Copilot when `permissions` or `allowed-tools` are specified:
+
+```markdown
+## Security Notice
+
+⚠️ **ADVISORY ONLY:** These restrictions are not enforced by Windsurf.
+The AI is instructed to follow them, but system enforcement is not available.
+For security-critical operations, use Claude Code which provides runtime enforcement.
+```
+
+### 6.3 Project Settings Impact (Claude Code)
+
+**IMPORTANT:** When using the Claude Code adapter, permissions from skill frontmatter are merged into **project-level** `.claude/settings.json`, not scoped to individual skills.
+
+**Security Implications:**
+
+- Installing a skill with `permissions.allow: ["Bash(npm install)"]` grants this permission **globally** to the project
+- Multiple skills accumulate permissions in `settings.json`
+- Malicious or poorly-designed skills can grant unintended broad access
+- Review `.claude/settings.json` periodically to audit accumulated permissions
+
+**Best Practices:**
+
+1. **Minimize skill permissions** - Only grant what's strictly necessary
+2. **Audit settings.json** - Review project permissions after installing new skills
+3. **Use skill `allowed-tools` instead** - Where possible, restrict tools rather than file patterns
+4. **Manual cleanup** - Remove obsolete permissions from `settings.json` when uninstalling skills
+
+**Example Risk Scenario:**
+
+```yaml
+# Skill A adds:
+permissions:
+  allow: ["Read(src/**)"]
+
+# Skill B adds:
+permissions:
+  allow: ["Write(src/**)"]
+
+# Result in settings.json:
+{
+  "permissions": {
+    "allow": [
+      "Read(src/**)",
+      "Write(src/**)"  # Now ALL project sessions can write to src/
+    ]
+  }
+}
+```
+
+Even if you only run Skill A, Skill B's permissions persist and apply globally.
+
+### 6.4 Recommended Practices
+
+1. **Review skill source** before installing - Check frontmatter for broad permissions
+2. **Test in isolated environment** - Try new skills in throwaway projects first
+3. **Use version control** - Commit before running untrusted skills
+4. **Prefer narrow scopes** - `allowed-tools: [Read]` is safer than `permissions.allow: ["Read(**)"]`
+5. **Document assumptions** - Comment security expectations in `settings.json`
+
+---
+
+## Sources
+
+- STANDARD-SCHEMA.md
+- STANDARD-STRUCTURE.md
+- GAP-ANALYSIS.md
+- TERMINOLOGY-MAPPING.md
+- Official documentation from Claude Code, Windsurf, and GitHub Copilot
diff --git a/ROADMAP.md b/ROADMAP.md
new file mode 100644
index 0000000..ff100b0
--- /dev/null
+++ b/ROADMAP.md
@@ -0,0 +1,233 @@
+# Template for Cross AI Assistant Compatibility - Roadmap
+
+## Current Position
+
+**Phase:** Phase 5
+**Status:** 📋 Ready to Plan
+
+## Phase Sequence
+
+### Phase 1: Research and Discovery
+- **Status:** ✅ Completed (2026-01-12)
+- **Description:** Map capabilities, terminologies, and limitations across target AI assistants (Claude Code, Windsurf, and GitHub Copilot)
+- **Tasks:**
+  - [x] Document all Claude Code capabilities (skills, commands, agents, file structure)
+  - [x] Document all Windsurf capabilities (workflows, rules, cascades, file structure)
+  - [x] Document all GitHub Copilot capabilities (prompts, agents, MCP integration, file structure)
+  - [x] Create capability comparison matrix showing what exists where
+  - [x] Document terminology mapping (workflow=skill=prompt, etc.)
+  - [x] Identify capability gaps and emulation opportunities
+  - [x] Research any existing cross-platform formats or standards
+- **Verification Criteria:**
+  - [x] Complete capability matrix covering all three tools
+  - [x] Terminology translation table created
+  - [x] Capability gaps documented with potential workarounds
+  - [x] Research findings documented
+- **Deliverables:**
+  - RESEARCH-claude-code.md (analyzing Upgrades skill as reference)
+  - RESEARCH-windsurf.md
+  - RESEARCH-github-copilot.md (covering both Copilot and Codex)
+  - CAPABILITY-MATRIX.md (3-platform comparison)
+  - TERMINOLOGY-MAPPING.md (cross-platform mappings)
+  - GAP-ANALYSIS.md (10 gaps with workarounds)
+
+### Phase 2: Standard Template Design
+- **Status:** ✅ Completed (2026-01-12)
+- **Description:** Choose standard format and define template structure that works across AI assistants
+- **Tasks:**
+  - [x] Evaluate Claude Code format as potential standard
+  - [x] Evaluate creating custom vendor-neutral format
+  - [x] Make decision on standard approach (with rationale)
+  - [x] Define file structure conventions
+  - [x] Define metadata schema (front matter, headers, etc.)
+  - [x] Document template specification
+- **Verification Criteria:**
+  - [x] Standard format chosen and documented
+  - [x] Template specification complete
+  - [x] File structure defined
+  - [x] Metadata schema documented
+  - [x] Decision rationale captured
+- **Deliverables:**
+  - STANDARD-SCHEMA.md (complete superset YAML frontmatter specification)
+  - STANDARD-STRUCTURE.md (directory layout and platform mappings)
+  - PLATFORM-ADAPTERS.md (transformation rules for all 3 platforms)
+  - VERIFICATION-phase-2.md (verification report with all fixes)
+
+### Phase 3: Workaround Pattern Library
+- **Status:** ✅ Completed (2026-01-12)
+- **Description:** Document and test patterns for emulating missing capabilities across platforms
+- **Tasks:**
+  - [x] Design emulation pattern for Claude skills in Windsurf (using rules + front matter)
+  - [x] Design emulation pattern for Windsurf workflows in Claude Code
+  - [x] Test each emulation pattern in actual tools
+  - [x] Document workaround patterns with examples
+  - [x] Create pattern template library
+- **Verification Criteria:**
+  - [x] At least 3 emulation patterns documented
+  - [x] Each pattern tested and validated
+  - [x] Pattern library created with examples
+  - [x] Known limitations documented
+- **Deliverables:**
+  - WORKAROUND-PATTERNS.md (3 complete emulation patterns)
+  - examples/skill-example.md
+  - examples/workflow-example.md
+  - examples/copilot-limited-context.md
+  - VERIFICATION-phase-3.md
+
+### Phase 4: Programmatic Mapping System
+- **Status:** ✅ Completed (2026-01-12)
+- **Description:** Build automated translation system to convert templates between AI assistant formats
+- **Tasks:**
+  - [x] Design mapping engine architecture
+  - [x] Implement parser for standard template format
+  - [x] Implement generator for Claude Code format
+  - [x] Implement generator for Windsurf format
+  - [x] Create CLI tool or script for conversions
+  - [x] Test round-trip conversions
+- **Verification Criteria:**
+  - [x] Can parse standard format correctly
+  - [x] Can generate Claude Code format
+  - [x] Can generate Windsurf format
+  - [x] Round-trip conversion preserves intent
+  - [x] CLI tool is functional
+- **Deliverables:**
+  - ARCHITECTURE-mapping-engine.md
+  - packages/cli/src/lib/template-mapper/ (parser, adapters, types)
+  - `aiw convert` CLI command
+  - VERIFICATION-phase-4.md
+
+### Phase 5: Semantic Content Transformation
+- **Status:** 📋 Not Started
+- **Description:** Build semantic parsing and transformation layer that identifies platform-specific constructs in workflow content and transforms them for target platforms
+- **Tasks:**
+  - [ ] Define content schema documenting semantic constructs (agent spawning, tool calls, context switches) with detection patterns
+  - [ ] Implement content parser that extracts semantic constructs from markdown workflow content
+  - [ ] Implement per-platform content transformers (inline agents for Windsurf, decompose for Copilot)
+  - [ ] Integrate semantic transformation into existing `aiw convert` CLI
+  - [ ] Test transformations with real workflow examples
+- **Verification Criteria:**
+  - [ ] Content schema documented with detection patterns for all major constructs
+  - [ ] Parser correctly identifies agent spawning, tool calls, and context patterns
+  - [ ] Windsurf transformer inlines agent prompts instead of spawning references
+  - [ ] Copilot transformer handles decomposition for context limits
+  - [ ] Integration with existing `aiw convert` CLI command
+  - [ ] Unit tests covering parsing and transformation
+- **Rationale for Insertion:**
+  - Phase 4 transforms metadata (frontmatter) but passes content through unchanged
+  - Platform-specific constructs in content (e.g., "spawn agent X") become nonsensical on platforms that don't support them
+  - Semantic content transformation enables true cross-platform portability
+
+### Phase 6: Reference Implementation
+- **Status:** 📋 Not Started
+- **Description:** Create example templates demonstrating the system working across both platforms
+- **Tasks:**
+  - [ ] Create 2-3 reference templates in standard format
+  - [ ] Convert to Claude Code format and test
+  - [ ] Convert to Windsurf format and test
+  - [ ] Document any issues or limitations discovered
+  - [ ] Refine mapping system based on findings
+- **Verification Criteria:**
+  - [ ] Reference templates work in Claude Code
+  - [ ] Reference templates work in Windsurf
+  - [ ] Issues documented and addressed
+  - [ ] Templates demonstrate key features
+
+### Phase 7: Documentation and Polish
+- **Status:** 📋 Not Started
+- **Description:** Create comprehensive documentation for using the template system
+- **Tasks:**
+  - [ ] Write user guide for template format
+  - [ ] Write conversion tool documentation
+  - [ ] Document best practices and patterns
+  - [ ] Create troubleshooting guide
+  - [ ] Add examples and tutorials
+- **Verification Criteria:**
+  - [ ] Complete user guide exists
+  - [ ] Conversion tool documented
+  - [ ] Best practices guide created
+  - [ ] Examples cover common use cases
+
+---
+
+## Completed Phases
+
+### Phase 4: Programmatic Mapping System ✅
+**Completed:** 2026-01-12
+**Duration:** 1 day
+**Key Deliverables:**
+- ARCHITECTURE-mapping-engine.md with component diagram and 5-stage pipeline
+- Template parser with YAML frontmatter + markdown extraction
+- Claude Code adapter with full field mapping and settings.json generation
+- Windsurf adapter with emulation patterns (advisory sections, persona rules)
+- CLI command: `aiw convert <source> --to <platform>`
+- 56 unit tests passing
+
+**Key Decisions:**
+- 5-stage transformation pipeline: Parse → Validate → Transform → Emulate → Generate
+- Platform adapters handle all transformation logic
+- Warnings generated for emulated/unsupported features
+- Multi-file output support (main workflow + supplementary rules)
+
+### Phase 3: Workaround Pattern Library ✅
+**Completed:** 2026-01-12
+**Duration:** 1 day
+**Key Deliverables:**
+- WORKAROUND-PATTERNS.md with 3 complete emulation patterns (1,844 lines)
+- Pattern 1: Skill Emulation for Windsurf (workflows + rules)
+- Pattern 2: Workflow Emulation for Claude Code (skills)
+- Pattern 3: Working Set Limitation for GitHub Copilot (10-file decomposition)
+- 3 example files demonstrating each pattern
+
+**Key Decisions:**
+- Manual traceability approach for debugging
+- Advisory-based emulation (not enforced)
+- Clear documentation of what emulation cannot achieve
+
+### Phase 2: Standard Template Design ✅
+**Completed:** 2026-01-12
+**Duration:** 1 day
+**Key Deliverables:**
+- Complete superset YAML frontmatter specification (STANDARD-SCHEMA.md) with all fields from all 3 platforms
+- Standard directory layout with platform mappings (STANDARD-STRUCTURE.md) for .ai-templates/
+- Deterministic platform adapter transformation rules (PLATFORM-ADAPTERS.md) with emulation patterns
+- Comprehensive verification report (VERIFICATION-phase-2.md) confirming all acceptance criteria met
+
+**Key Decisions:**
+- **Superset + Platform Adapter approach:** Preserves ALL features from ALL platforms in standard format
+- **Platform adapters handle downgrading:** Emulation patterns for features not natively supported
+- **Clear compatibility markers:** Users can see what works where with compatibility field
+- **Three platform adapters:** Claude Code (most complete), Windsurf (needs emulation), GitHub Copilot (working set limits)
+
+**Architecture:**
+- Superset standard captures capabilities from Claude Code, Windsurf, and GitHub Copilot
+- Platform adapters transform standard → native format with field mapping, emulation, and warnings
+- 6 of 10 GAP-ANALYSIS workaround patterns incorporated (4 remaining for Phase 3+)
+
+### Phase 1: Research and Discovery ✅
+**Completed:** 2026-01-12
+**Duration:** 1 day
+**Key Deliverables:**
+- Comprehensive Claude Code architecture documentation (RESEARCH-claude-code.md) - analyzed Upgrades skill as reference
+- Comprehensive Windsurf architecture documentation (RESEARCH-windsurf.md)
+- Comprehensive GitHub Copilot & Codex documentation (RESEARCH-github-copilot.md)
+- Detailed 3-platform capability comparison matrix (CAPABILITY-MATRIX.md)
+- Cross-platform terminology translation table (TERMINOLOGY-MAPPING.md)
+- Gap analysis with 10 workaround patterns (GAP-ANALYSIS.md)
+
+**Key Findings:**
+- **Claude Code strength:** Subagent spawning, granular permissions, 10+ lifecycle hooks, unlimited file sizes, multi-repo support
+- **Windsurf strength:** Multi-file context (best-in-class), AI-driven activation (Model Decision), pattern learning (Memories), Flow mode collaboration
+- **GitHub Copilot strength:** Best inline completions, extensive IDE support, deep MCP integration, mature enterprise features, $10 entry point
+- **Critical gaps identified:**
+  - Windsurf: Cannot spawn subagents (HIGH)
+  - GitHub Copilot: 10-file working set limit (HIGH)
+  - 10 high/medium priority gaps total with emulation strategies
+- **Cross-platform patterns:**
+  - CLAUDE.md / Always-On Rule / copilot-instructions.md works across all three
+  - Shared workflow format possible with platform tags
+  - MCP protocol compatible across all three platforms
+- **Recommendation:** Superset standard format to accommodate all three platforms with clear compatibility markers
+
+---
+
+**Last Updated:** 2026-01-12
diff --git a/STANDARD-STRUCTURE.md b/STANDARD-STRUCTURE.md
new file mode 100644
index 0000000..b311211
--- /dev/null
+++ b/STANDARD-STRUCTURE.md
@@ -0,0 +1,635 @@
+# Standard Directory Structure and Platform Mappings
+
+**Date:** 2026-01-12
+**Purpose:** Define the canonical directory structure for cross-platform AI assistant templates with mappings to Claude Code, Windsurf, and GitHub Copilot native formats.
+
+---
+
+## Executive Summary
+
+This document defines the **standard directory layout** for portable AI assistant templates that work across Claude Code, Windsurf IDE, and GitHub Copilot. The structure follows the **Superset + Platform Adapter** approach: capturing ALL features from ALL platforms in a unified format, with platform adapters handling translation to each platform's native structure.
+
+---
+
+## Standard Directory Layout
+
+```
+.ai-templates/                    # Standard root (platform-agnostic)
+|
++-- skills/                       # Automation templates (workflows/prompts)
+|   +-- skill-name/               # Each skill in its own directory
+|   |   +-- SKILL.md              # Main template file (required)
+|   |   +-- assets/               # Supporting files (optional)
+|   |   |   +-- scripts/          # Helper scripts
+|   |   |   +-- templates/        # Code templates
+|   |   |   +-- examples/         # Example files
+|   |   +-- CHUNKS/               # Chunked content for large templates
+|   |       +-- chunk-1.md        # First chunk (if template exceeds limits)
+|   |       +-- chunk-2.md        # Additional chunks as needed
+|   |
+|   +-- another-skill/
+|       +-- SKILL.md
+|
+|   # Note: Skills can represent both Claude Code skills and Windsurf workflows.
+|   # See WORKAROUND-PATTERNS.md Pattern 2 for workflow emulation patterns.
+|
++-- instructions/                 # Project-level instructions
+|   +-- PROJECT.md                # Main instructions (always loaded)
+|   +-- LOCAL.md                  # Local overrides (gitignored)
+|   +-- paths/                    # Path-specific instructions
+|       +-- src-typescript.md     # Rules for src/**/*.ts
+|       +-- src-api.md            # Rules for src/api/**/*
+|       +-- tests.md              # Rules for tests/**/*
+|
++-- agents/                       # Custom agent definitions
+|   +-- explorer.md               # Read-only explorer agent
+|   +-- implementer.md            # Code implementation agent
+|   +-- reviewer.md               # Code review agent
+|
++-- config/                       # Platform adapter configurations
+|   +-- claude-code.json          # Claude Code specific settings
+|   +-- windsurf.json             # Windsurf specific settings
+|   +-- github-copilot.json       # GitHub Copilot specific settings
+|   +-- platform-features.json    # Feature compatibility matrix
+|
++-- hooks/                        # Lifecycle event handlers
+|   +-- pre-commit.md             # Before git commit
+|   +-- session-start.md          # On session start
+|   +-- post-tool-use.md          # After tool execution
+|
++-- state/                        # Runtime state (gitignored)
+    +-- session-context.json      # Current session state
+    +-- learned-patterns.json     # Emulated memory/patterns
+```
+
+---
+
+## Platform Mapping Table
+
+### Primary Locations
+
+| Standard Location | Claude Code | Windsurf | GitHub Copilot |
+|-------------------|-------------|----------|----------------|
+| `.ai-templates/` | `.claude/` | `.windsurf/` | `.github/` |
+| `.ai-templates/skills/` | `.claude/skills/` | `.windsurf/workflows/` | `.github/prompts/` |
+| `.ai-templates/skills/name/SKILL.md` | `.claude/skills/name/SKILL.md` | `.windsurf/workflows/name.md` | `.github/prompts/name.prompt.md` or `.github/skills/name/SKILL.md` |
+| *Workflow emulation* | See [Pattern 2](WORKAROUND-PATTERNS.md#pattern-2-workflow-emulation-for-claude-code) | N/A (native workflows) | N/A |
+| `.ai-templates/commands/` | `.claude/commands/` | N/A (use workflows) | N/A (not supported) |
+| `.ai-templates/instructions/PROJECT.md` | `CLAUDE.md` (root) | `.windsurf/rules/*.md` (always_on) | `.github/copilot-instructions.md` |
+| `.ai-templates/instructions/MODEL.md` | N/A (not supported) | N/A (not supported) | `CLAUDE.md`, `GEMINI.md`, `AGENTS.md` (model-specific) |
+| `.ai-templates/instructions/LOCAL.md` | `CLAUDE.local.md` (root) | `~/.codeium/windsurf/memories/global_rules.md` | Workspace settings |
+| `.ai-templates/instructions/paths/` | N/A (use permissions) | `.windsurf/rules/` (glob trigger) | `.github/instructions/` |
+| `.ai-templates/agents/` | `.claude/agents/` | N/A (not supported) | Inline in prompts |
+| `.ai-templates/config/` | `.claude/settings.json` | N/A (limited config) | IDE/Workspace settings |
+| `.ai-templates/hooks/` | `.claude/settings.json` (hooks: {}) | **No equivalent** (triggers are different concept) | N/A (not supported) |
+| `.ai-templates/state/` | `.claude/state/` (gitignored) | N/A (uses Memories) | N/A (not supported) |
+
+### Path-Specific Instructions
+
+| Standard Pattern | Claude Code | Windsurf | GitHub Copilot |
+|------------------|-------------|----------|----------------|
+| `paths/src-typescript.md` | Permissions: `Read(src/**/*.ts)` | Glob rule: `globs: ["src/**/*.ts"]` | `applyTo: "src/**/*.ts"` |
+| `paths/src-api.md` | Permissions: `Read(src/api/**)` | Glob rule: `globs: ["src/api/**"]` | `applyTo: "src/api/**"` |
+| `paths/tests.md` | Permissions: `Read(tests/**)` | Glob rule: `globs: ["tests/**"]` | `applyTo: "tests/**"` |
+
+### Agent Definitions
+
+| Standard Location | Claude Code | Windsurf | GitHub Copilot |
+|-------------------|-------------|----------|----------------|
+| `agents/explorer.md` | `.claude/agents/explorer.md` | Emulate via persona rule | Inline in prompt files |
+| `agents/implementer.md` | `.claude/agents/implementer.md` | Emulate via persona rule | Inline in prompt files |
+| `agents/reviewer.md` | `.claude/agents/reviewer.md` | Emulate via persona rule | Inline in prompt files |
+
+### User-Level / Global Directories
+
+These directories exist at the user level (not project level) and apply across all projects:
+
+| Purpose | Claude Code | Windsurf | GitHub Copilot |
+|---------|-------------|----------|----------------|
+| **Global skills/workflows** | `~/.claude/skills/` | N/A (not supported) | `~/.copilot/skills/` |
+| **Global commands** | `~/.claude/commands/` | N/A (use workflows) | N/A (not supported) |
+| **Global instructions** | N/A (use project `CLAUDE.md`) | `~/.codeium/windsurf/memories/global_rules.md` | N/A (use workspace settings) |
+| **Memories/Learning** | N/A (manual state management) | `~/.codeium/windsurf/memories/` | N/A (not supported) |
+| **AI-generated memories** | N/A (manual state management) | `~/.codeium/windsurf/cascade/` | N/A (not supported) |
+| **User settings** | `~/.claude/settings.json` | `~/.codeium/windsurf/config/` | IDE settings.json |
+| **MCP configuration** | `.mcp.json` (plugin root) | Limited MCP support | MCP server configs (IDE settings) |
+
+**Notes:**
+- **Claude Code global skills** at `~/.claude/skills/` are available across all projects without needing to be in project `.claude/` directory
+- **Windsurf Memories system** at `~/.codeium/windsurf/memories/` learns from interactions and applies patterns automatically
+- **Windsurf global_rules.md** applies to all projects for this user, equivalent to LOCAL.md in standard format
+
+---
+
+## Naming Conventions
+
+### Directory and File Names
+
+1. **Use kebab-case** for all file and directory names
+   - Good: `code-review`, `pre-commit`, `src-typescript.md`
+   - Bad: `codeReview`, `preCommit`, `srcTypescript.md`
+
+2. **Main file naming:**
+   - Skills: Always `SKILL.md` (uppercase)
+   - Instructions: Always `PROJECT.md` and `LOCAL.md` (uppercase)
+   - Path rules: `{path-pattern}.md` (lowercase kebab-case)
+   - Agents: `{agent-name}.md` (lowercase kebab-case)
+
+3. **Reserved names:**
+   - `SKILL.md` - Main skill definition
+   - `PROJECT.md` - Main project instructions
+   - `LOCAL.md` - Local overrides (gitignored)
+   - `CHUNKS/` - Directory for chunked content
+
+### Skill Directory Structure
+
+```
+skills/
++-- commit/                       # Skill name as directory
+|   +-- SKILL.md                  # Required: main definition
+|   +-- assets/                   # Optional: supporting files
+|
++-- deploy-production/            # Kebab-case for multi-word names
+    +-- SKILL.md
+```
+
+### Path-Specific Instruction Naming
+
+Pattern: Replace path separators and wildcards with descriptive names.
+
+| File Path Pattern | Instruction File Name |
+|-------------------|----------------------|
+| `src/**/*.ts` | `src-typescript.md` |
+| `src/api/**/*` | `src-api.md` |
+| `src/components/**/*.tsx` | `src-components-tsx.md` |
+| `tests/**/*` | `tests.md` |
+| `docs/**/*.md` | `docs-markdown.md` |
+| `*.config.js` | `config-js.md` |
+
+---
+
+## Size Limits and Constraints
+
+### Platform-Specific Limits
+
+| Constraint | Claude Code | Windsurf | GitHub Copilot |
+|------------|-------------|----------|----------------|
+| **Skill/Workflow file size** | Unlimited | **12,000 characters** | Unlimited |
+| **Rule/Instruction file size** | Unlimited | **12,000 characters** | Unlimited |
+| **Single file line limit** | Unlimited | ~300-500 lines (performance) | ~6,000 lines (quality degrades) |
+| **Context window** | Large | Large | **6,000 chars/batch; 60 lines/file; 20 files max** |
+| **Max files in context** | Unlimited | Unlimited | **20 files** |
+| **Working set** | Unlimited | Unlimited | **10 files** (Edits mode) |
+
+### Chunking Strategy for Large Templates
+
+When a template exceeds platform limits, use the chunking system:
+
+```
+skills/large-skill/
++-- SKILL.md                      # Main entry point (under limit)
++-- CHUNKS/                       # Overflow content
+    +-- chunk-1-setup.md          # Setup instructions
+    +-- chunk-2-implementation.md # Implementation details
+    +-- chunk-3-testing.md        # Testing procedures
+```
+
+**SKILL.md Header for Chunked Skills:**
+
+```yaml
+---
+name: large-skill
+description: Complex skill requiring multiple chunks
+chunks:
+  - CHUNKS/chunk-1-setup.md
+  - CHUNKS/chunk-2-implementation.md
+  - CHUNKS/chunk-3-testing.md
+---
+
+# Large Skill
+
+This skill is chunked for platform compatibility.
+
+## Quick Start
+[Brief overview under 6,000 characters for Copilot compatibility]
+
+## Detailed Instructions
+For complete instructions, load chunks as needed:
+- Setup: See `CHUNKS/chunk-1-setup.md`
+- Implementation: See `CHUNKS/chunk-2-implementation.md`
+- Testing: See `CHUNKS/chunk-3-testing.md`
+```
+
+### Size Recommendations
+
+| Content Type | Recommended Size | Reason |
+|--------------|------------------|--------|
+| Main SKILL.md | < 6,000 chars | GitHub Copilot context limit |
+| Windsurf workflows | < 12,000 chars | Hard platform limit |
+| Path-specific rules | < 3,000 chars | Keep focused and fast |
+| Agent definitions | < 4,000 chars | Reasonable persona scope |
+| Quick start section | < 2,000 chars | Initial context load |
+
+---
+
+## Complete Mapping Examples
+
+### Example 1: Standard Skill to All Platforms
+
+**Standard Location:** `.ai-templates/skills/commit/SKILL.md`
+
+```yaml
+---
+name: commit
+description: Create conventional git commits with proper formatting
+allowed-tools: [Bash]
+platforms: [claude-code, windsurf, github-copilot]
+---
+
+# Commit Skill
+
+Create a properly formatted conventional commit.
+
+## Steps
+1. Check git status
+2. Stage changes
+3. Create commit with conventional format
+```
+
+**Claude Code:** `.claude/skills/commit/SKILL.md`
+```yaml
+---
+name: commit
+description: Create conventional git commits with proper formatting
+allowed-tools: [Bash]
+---
+
+# Commit Skill
+[Same content]
+```
+
+**Windsurf:** `.windsurf/workflows/commit.md`
+```yaml
+---
+description: Create conventional git commits with proper formatting
+trigger: manual
+labels: [git, automation]
+---
+
+# Commit Workflow
+[Same content, invoke with /commit]
+```
+
+**GitHub Copilot:** `.github/prompts/commit.prompt.md`
+```yaml
+---
+description: Create conventional git commits with proper formatting
+mode: agent
+---
+
+# Commit Prompt
+[Same content, invoke with /commit or #prompt:commit]
+```
+
+---
+
+### Example 2: Project Instructions to All Platforms
+
+**Standard Location:** `.ai-templates/instructions/PROJECT.md`
+
+```markdown
+# Project Instructions
+
+## Code Style
+- Use TypeScript strict mode
+- Prefer functional programming patterns
+- Use Tailwind CSS for styling
+
+## Testing
+- Jest for unit tests
+- 80% coverage minimum
+
+## Git Workflow
+- Conventional commits required
+- Feature branches only
+```
+
+**Claude Code:** `CLAUDE.md` (project root)
+```markdown
+[Same content - no changes needed]
+```
+
+**Windsurf:** `.windsurf/rules/project-instructions.md`
+```yaml
+---
+trigger: always_on
+description: Project coding standards
+---
+
+[Same content with frontmatter]
+```
+
+**GitHub Copilot:** `.github/copilot-instructions.md`
+```markdown
+[Same content - no changes needed]
+```
+
+---
+
+### Example 3: Path-Specific Rules to All Platforms
+
+**Standard Location:** `.ai-templates/instructions/paths/src-api.md`
+
+```yaml
+---
+path-pattern: src/api/**/*
+description: API route development standards
+---
+
+# API Development Standards
+
+- Use Express.js patterns
+- Validate all inputs with Zod
+- Return consistent error formats
+- Include OpenAPI documentation
+```
+
+**Claude Code:** Added to `.claude/settings.json`
+```json
+{
+  "permissions": {
+    "allow": ["Read(src/api/**/*)", "Write(src/api/**/*.ts)"]
+  }
+}
+```
+Plus skill with description matching for auto-invoke.
+
+**Windsurf:** `.windsurf/rules/src-api.md`
+```yaml
+---
+trigger: glob
+globs: ["src/api/**/*"]
+description: API route development standards
+---
+
+[Same content]
+```
+
+**GitHub Copilot:** `.github/instructions/src-api.instructions.md`
+```yaml
+---
+applyTo: "src/api/**/*"
+---
+
+[Same content]
+```
+
+---
+
+### Example 4: Agent Definition to All Platforms
+
+**Standard Location:** `.ai-templates/agents/explorer.md`
+
+```yaml
+---
+name: explorer
+description: Read-only codebase exploration agent
+allowed-tools: [Read, Glob, Grep]
+forbidden-tools: [Write, Edit, Bash]
+---
+
+# Explorer Agent
+
+You are a read-only exploration agent. Your role is to:
+- Search and analyze the codebase
+- Document findings in FINDINGS.md
+- Never modify files
+
+## Allowed Actions
+- Read any file
+- Search with glob and grep
+- Create documentation files
+
+## Forbidden Actions
+- Do not write or edit code files
+- Do not execute commands
+- Do not suggest changes (only document)
+```
+
+**Claude Code:** `.claude/agents/explorer.md`
+```yaml
+---
+name: explorer
+description: Read-only codebase exploration agent
+allowed-tools: [Read, Glob, Grep]
+---
+
+[Same content]
+```
+
+**Windsurf:** `.windsurf/rules/agent-explorer.md` (emulated via persona rule)
+```yaml
+---
+trigger: manual
+description: Read-only explorer agent persona - activate with @rules:agent-explorer
+---
+
+# Explorer Agent Persona
+
+When @rules:agent-explorer is active, adopt this persona:
+
+[Same behavioral content]
+
+Note: Tool restrictions cannot be enforced, rely on AI compliance.
+```
+
+**GitHub Copilot:** Inline in prompt files
+```yaml
+# .github/prompts/explore-codebase.prompt.md
+---
+description: Explore codebase in read-only mode
+mode: agent
+tools:
+  - filesystem (read-only)
+---
+
+You are acting as an explorer agent.
+
+[Same behavioral content inline]
+```
+
+---
+
+## Reverse Mapping: Platform-Native to Standard
+
+### From Claude Code to Standard
+
+| Claude Code Location | Standard Location |
+|---------------------|-------------------|
+| `.claude/` | `.ai-templates/` |
+| `.claude/skills/name/SKILL.md` | `.ai-templates/skills/name/SKILL.md` |
+| `CLAUDE.md` | `.ai-templates/instructions/PROJECT.md` |
+| `CLAUDE.local.md` | `.ai-templates/instructions/LOCAL.md` |
+| `.claude/agents/name.md` | `.ai-templates/agents/name.md` |
+| `.claude/settings.json` | `.ai-templates/config/claude-code.json` |
+| `.claude/commands/` | `.ai-templates/skills/` (convert to skills) |
+
+### From Windsurf to Standard
+
+| Windsurf Location | Standard Location |
+|-------------------|-------------------|
+| `.windsurf/` | `.ai-templates/` |
+| `.windsurf/workflows/name.md` | `.ai-templates/skills/name/SKILL.md` |
+| `.windsurf/rules/*.md` (always_on) | `.ai-templates/instructions/PROJECT.md` |
+| `.windsurf/rules/*.md` (glob) | `.ai-templates/instructions/paths/*.md` |
+| `.windsurf/rules/*.md` (manual persona) | `.ai-templates/agents/*.md` |
+| `global_rules.md` | `.ai-templates/instructions/LOCAL.md` |
+
+### From GitHub Copilot to Standard
+
+| GitHub Copilot Location | Standard Location |
+|------------------------|-------------------|
+| `.github/` | `.ai-templates/` |
+| `.github/prompts/name.prompt.md` | `.ai-templates/skills/name/SKILL.md` |
+| `.github/copilot-instructions.md` | `.ai-templates/instructions/PROJECT.md` |
+| `.github/instructions/*.instructions.md` | `.ai-templates/instructions/paths/*.md` |
+| `.github/chatmodes/*.chatmode.md` | `.ai-templates/agents/*.md` (convert) |
+| Workspace settings | `.ai-templates/config/github-copilot.json` |
+
+---
+
+## Config File Schemas
+
+### claude-code.json
+
+```json
+{
+  "$schema": "https://aiwcli.dev/schemas/claude-code.json",
+  "version": "1.0.0",
+  "permissions": {
+    "allow": [
+      "Read(**/*.ts)",
+      "Write(src/**/*.ts)",
+      "Bash(npm test)",
+      "Bash(npm run lint)"
+    ],
+    "deny": [
+      "Read(.env)",
+      "Write(package.json)"
+    ]
+  },
+  "hooks": {
+    "PreToolUse": [
+      {
+        "matcher": "Bash(git push*)",
+        "action": "require-confirmation"
+      }
+    ]
+  },
+  "model": "claude-sonnet-4-20250514"
+}
+```
+
+### windsurf.json
+
+```json
+{
+  "$schema": "https://aiwcli.dev/schemas/windsurf.json",
+  "version": "1.0.0",
+  "notes": {
+    "max-file-size": "12000 characters",
+    "chunking-required": true
+  },
+  "rule-mapping": {
+    "always-on-rules": ["project-instructions"],
+    "glob-rules": ["src-api", "src-components"],
+    "manual-rules": ["agent-explorer", "agent-implementer"]
+  }
+}
+```
+
+### github-copilot.json
+
+```json
+{
+  "$schema": "https://aiwcli.dev/schemas/github-copilot.json",
+  "version": "1.0.0",
+  "constraints": {
+    "max-context-chars": 6000,
+    "max-files-in-context": 20,
+    "max-working-set": 10
+  },
+  "prompt-mapping": {
+    "skills-as-prompts": true,
+    "agents-inline": true
+  },
+  "mcp-servers": {
+    "github": {
+      "enabled": true,
+      "auth": "oauth"
+    }
+  }
+}
+```
+
+### platform-features.json
+
+```json
+{
+  "$schema": "https://aiwcli.dev/schemas/platform-features.json",
+  "version": "1.0.0",
+  "features": {
+    "subagent-spawning": {
+      "claude-code": true,
+      "windsurf": false,
+      "github-copilot": true
+    },
+    "lifecycle-hooks": {
+      "claude-code": ["SessionStart", "PreToolUse", "PostToolUse", "Stop", "SubagentStop"],
+      "windsurf": [],
+      "github-copilot": [],
+      "note": "Windsurf uses trigger-based rules (always_on, model_decision, glob) instead of lifecycle hooks"
+    },
+    "file-pattern-rules": {
+      "claude-code": "permissions",
+      "windsurf": "glob-trigger",
+      "github-copilot": "applyTo"
+    },
+    "ai-driven-activation": {
+      "claude-code": false,
+      "windsurf": true,
+      "github-copilot": false
+    },
+    "custom-agents": {
+      "claude-code": true,
+      "windsurf": false,
+      "github-copilot": true
+    }
+  }
+}
+```
+
+---
+
+## Validation Checklist
+
+When creating or converting templates, verify:
+
+- [ ] Main skill file is named `SKILL.md`
+- [ ] All directories and files use kebab-case
+- [ ] Content under 12,000 characters (Windsurf limit) or properly chunked
+- [ ] Quick start section under 6,000 characters (Copilot context limit)
+- [ ] Path-specific rules have valid glob patterns
+- [ ] Agent definitions include behavioral constraints
+- [ ] Platform-specific features are tagged appropriately
+- [ ] Gitignore includes LOCAL.md and state/ directory
+- [ ] Reverse mapping is documented for conversions
+
+---
+
+## Sources
+
+- TERMINOLOGY-MAPPING.md (File Organization section)
+- CAPABILITY-MATRIX.md (File Organization section)
+- GAP-ANALYSIS.md (Workaround patterns)
+- Official documentation from Claude Code, Windsurf, and GitHub Copilot
diff --git a/STATE.md b/STATE.md
new file mode 100644
index 0000000..d6438a2
--- /dev/null
+++ b/STATE.md
@@ -0,0 +1,148 @@
+# Template for Cross AI Assistant Compatability - Project State
+
+## Current Status
+
+**Phase:** Phase 5 - Semantic Content Transformation
+**Last Updated:** 2026-01-12
+**Working On:** Ready to plan Phase 5
+
+## Key Decisions
+
+### Decision 1: Project Scope
+- **Date:** 2026-01-12
+- **Decision:** Focus on capability mapping, terminology translation, and workaround patterns for AI editor compatibility
+- **Rationale:** Different AI tools (Claude Code, Windsurf, GitHub Copilot) have different capabilities and terminologies that prevent workflow portability
+- **Implications:** Need to build mapping system, emulation patterns, and choose between Claude Code as standard vs. custom standard format
+
+### Decision 2: Initial Target Tools
+- **Date:** 2026-01-12
+- **Decision:** Start with Claude Code and Windsurf (1-2 tools)
+- **Rationale:** Manageable scope, these are the primary tools in use, can expand later
+- **Implications:** Focus on mapping between these specific systems first before generalizing
+
+### Decision 3: Research Methodology
+- **Date:** 2026-01-12
+- **Decision:** Use parallel online research agents + real-world skill analysis
+- **Rationale:** Comprehensive research from official docs, community resources, and practical examples
+- **Implications:** High-quality research foundation for Phase 2 decisions
+
+### Decision 4: Expand Scope to Three Platforms
+- **Date:** 2026-01-12
+- **Decision:** Include GitHub Copilot/Codex in addition to Claude Code and Windsurf
+- **Rationale:** Copilot has largest market share, mature enterprise features, and unique MCP integration; critical to consider for compatibility template
+- **Implications:** More comprehensive standard format needed, superset approach recommended to accommodate all three platforms
+
+### Decision 5: Superset + Platform Adapter Architecture
+- **Date:** 2026-01-12
+- **Decision:** Use superset standard format with platform-specific adapters
+- **Rationale:**
+  - Preserves ALL features from ALL platforms in standard format
+  - Platform adapters handle downgrading/emulation for less capable targets
+  - Future-proof: new features can be added without breaking existing templates
+  - Clear compatibility markers tell users what works where
+- **Implications:** Need to define superset schema, file structure, and three platform adapters
+
+### Decision 6: Phase 2 Verification and Approval
+- **Date:** 2026-01-12
+- **Decision:** Approve Phase 2 completion with minor documentation fixes
+- **Rationale:**
+  - All 16 acceptance criteria met and verified by 5 independent agents
+  - Two high-confidence issues identified and fixed (applyTo normalization, hook naming)
+  - Overall quality score: 88/100 (Very Good)
+  - Remaining issues are LOW/MEDIUM priority enhancements, not blockers
+- **Implications:** Ready to proceed to Phase 3 (Workaround Pattern Library)
+
+### Decision 7: Priority 1 Fixes Completion
+- **Date:** 2026-01-12
+- **Decision:** Complete all 5 Priority 1 fixes before beginning Phase 3
+- **Rationale:**
+  - Issues identified during verification are critical for correctness and security
+  - Fixes are small scope (2-4 hours estimated, ~2 hours actual)
+  - Better to have accurate foundation before building Phase 3 patterns
+- **Changes Made:**
+  - STANDARD-SCHEMA.md: Updated model identifiers, added 2 missing fields
+  - STANDARD-STRUCTURE.md: Fixed 3 mapping errors, added user-level directory table
+  - PLATFORM-ADAPTERS.md: Clarified permission scoping algorithm, added Security Considerations section (Section 6)
+- **Implications:** Documentation now current as of January 2026, ready for Phase 3
+
+### Decision 8: Insert Phase 5 - Semantic Content Transformation
+- **Date:** 2026-01-12
+- **Decision:** Insert new Phase 5 after Phase 4, renumber subsequent phases
+- **Rationale:**
+  - Phase 4 transforms metadata (frontmatter) but passes workflow content through unchanged
+  - Platform-specific constructs in content (e.g., "spawn agent X") become nonsensical on platforms that don't support them
+  - Need semantic parsing to identify constructs like agent spawning, tool calls, context switches
+  - Need content transformers to rewrite constructs for each target platform (inline agents for Windsurf, decompose for Copilot)
+  - This enables true cross-platform portability beyond just metadata transformation
+- **Impact:**
+  - Old Phase 5 (Reference Implementation) → Phase 6
+  - Old Phase 6 (Documentation and Polish) → Phase 7
+  - No files renamed (no PLAN-phase-5.md or PLAN-phase-6.md existed)
+- **Implications:** Roadmap now has 7 phases, ready to plan Phase 5
+
+---
+
+## Active Blockers
+
+[No blockers currently]
+
+---
+
+## Progress Summary
+
+### Completed
+- Project initialization
+- Vision and goals defined
+- Roadmap created with 6 phases
+- **Phase 1: Research and Discovery (2026-01-12)**
+  - RESEARCH-claude-code.md created with comprehensive architecture documentation
+  - RESEARCH-windsurf.md created with comprehensive architecture documentation
+  - RESEARCH-github-copilot.md created with comprehensive architecture documentation
+  - CAPABILITY-MATRIX.md created comparing all features across three platforms
+  - TERMINOLOGY-MAPPING.md created with cross-platform translation tables
+  - GAP-ANALYSIS.md created with 10 workaround patterns for emulation
+
+### In Progress
+- None
+
+### Completed (Phase 3)
+- WORKAROUND-PATTERNS.md created with 3 complete emulation patterns (1,844 lines)
+  - Pattern 1: Skill Emulation for Windsurf (emulate Claude Code skills using workflows + rules)
+  - Pattern 2: Workflow Emulation for Claude Code (emulate Windsurf workflows using skills)
+  - Pattern 3: Working Set Limitation for GitHub Copilot (handle 10-file limit with decomposition)
+- 3 example files created in examples/ directory:
+  - examples/skill-example.md - Test runner skill adapted for all platforms (390 lines)
+  - examples/workflow-example.md - Multi-file refactor workflow adapted for Claude Code (339 lines)
+  - examples/copilot-limited-context.md - 28-file database refactor decomposed for Copilot (1,152 lines)
+- Cross-references added to PLATFORM-ADAPTERS.md and GAP-ANALYSIS.md linking to patterns
+- All patterns manually traceable with step-by-step execution flows
+- Summary table added to WORKAROUND-PATTERNS.md for quick pattern reference
+- 3 atomic git commits (one per task) documenting Phase 3 implementation
+
+### Completed (Phase 2)
+- STANDARD-SCHEMA.md created with complete superset YAML frontmatter specification (962 lines)
+- STANDARD-STRUCTURE.md created with directory layout and platform mappings (610 lines)
+- PLATFORM-ADAPTERS.md created with transformation rules for all three platforms (1,823 lines)
+- VERIFICATION-phase-2.md created with comprehensive parallel agent analysis
+  - SANA agent verified platform capabilities against January 2026 sources
+  - 7 HIQ agents (1 Opus, 6 Sonnet) verified architecture, schema, structure, logic, clarity, cross-references, and implementation
+  - Overall verification score: 8.2/10
+  - Identified 5 Priority 1 issues documented in ISSUES.md
+- ISSUES.md updated with priority-ordered action items from verification
+- All Phase 2 verification criteria from PLAN-phase-2.md met
+
+### Next Steps
+1. ✅ **COMPLETED** - Phases 1-4 all complete
+2. Plan Phase 5 (Semantic Content Transformation) - newly inserted phase
+3. Execute Phase 5 implementation
+4. Proceed to Phase 6 (Reference Implementation) and Phase 7 (Documentation)
+
+---
+
+## Notes
+
+Requirements are expected to change frequently - design should prioritize flexibility and extensibility over rigid specifications.
+
+---
+
+**Maintained by:** Get Shit Done workflow
diff --git a/SUMMARY.md b/SUMMARY.md
new file mode 100644
index 0000000..4f03a92
--- /dev/null
+++ b/SUMMARY.md
@@ -0,0 +1,141 @@
+# Project Summary - Template for Cross AI Assistant Compatibility
+
+## Phase 3: Workaround Pattern Library
+
+### Task 1: Design and Document Skill Emulation Pattern for Windsurf
+**Status:** Completed
+**Date:** 2026-01-12
+**Commit:** c3c12454fa56510988a0056209b2c5ab141e6638
+
+**Changes:**
+- Created WORKAROUND-PATTERNS.md with complete Skill Emulation Pattern
+- Created examples/skill-example.md demonstrating pattern usage
+- Added cross-references to PLATFORM-ADAPTERS.md and GAP-ANALYSIS.md
+
+**Verification:** All 7 acceptance criteria met, pattern manually traceable
+
+### Task 2: Design and Document Workflow Emulation Pattern for Claude Code
+**Status:** Completed
+**Date:** 2026-01-12
+**Commit:** adaffce58adcc2d164261e9e2e1b2778fdbda4de
+
+**Changes:**
+- Added Workflow Emulation Pattern section to WORKAROUND-PATTERNS.md
+- Created examples/workflow-example.md demonstrating multi-file context workflow
+- Added cross-references to PLATFORM-ADAPTERS.md and STANDARD-STRUCTURE.md
+
+**Verification:** All 8 acceptance criteria met, pattern manually traceable
+
+### Task 3: Design Pattern for GitHub Copilot Working Set Limitation
+**Status:** Completed
+**Date:** 2026-01-12
+**Commit:** 812d314f29c26703f57bc865588299625dd357ca
+
+**Changes:**
+- Added Working Set Limitation Pattern section to WORKAROUND-PATTERNS.md
+- Created examples/copilot-limited-context.md demonstrating skill decomposition
+- Added cross-references to PLATFORM-ADAPTERS.md and GAP-ANALYSIS.md
+- Added summary table to WORKAROUND-PATTERNS.md showing all 3 patterns
+
+**Verification:** All 8 acceptance criteria met, pattern manually traceable
+
+---
+
+## Phase 3 Summary
+
+**Status:** Completed
+**Date:** 2026-01-12
+**Total Commits:** 3
+**Total Lines Added:** ~3,500 lines
+
+**Deliverables:**
+- WORKAROUND-PATTERNS.md with 3 complete emulation patterns
+- 3 example files demonstrating practical pattern usage
+- Cross-references linking patterns to existing documentation
+- All patterns manually traceable with execution flows
+- Summary table for quick pattern reference
+
+**Phase Completion Criteria:**
+- [x] All tasks completed (3/3)
+- [x] All acceptance criteria met (23/23 total across all tasks)
+- [x] WORKAROUND-PATTERNS.md created with 3 documented patterns
+- [x] 3 example files created in examples/ directory
+- [x] Cross-references added linking patterns to existing documentation
+- [x] Each pattern is manually traceable
+- [x] Summary table provides quick reference
+
+**Next Recommended Action:** `/gsd:verify-work 3` to perform user acceptance testing of Phase 3 deliverables
+
+---
+
+## Phase 5: Semantic Content Transformation
+
+### Task 1: Design Content Schema via Agent Iteration
+**Status:** Completed
+**Date:** 2026-01-12
+**Commit:** 9a6c590
+
+**Changes:**
+- Created CONTENT-SCHEMA.md defining 18 semantic constructs
+- Required constructs (10): agent-spawn, tool-call, context-switch, permission-reference, model-decision-trigger, glob-pattern, persona-rule, skill-chaining, context-gathering-protocol, activation-instruction
+- Discovered constructs (8): working-set-limit, checkpoint-commit, progress-tracking, workspace-command, test-command, advisory-warning, version-comment, execution-flow-section
+- Each construct includes detection pattern, examples, transformation notes
+- Includes transformation matrix for all platforms
+
+**Verification:** Schema reviewed with 9/10 confidence score, no blocking issues
+
+### Task 2: Implement Content Parser with Detection Engine
+**Status:** Completed
+**Date:** 2026-01-12
+**Commit:** ba5de49
+
+**Changes:**
+- Added SemanticConstruct, ContentAnalysis types to types.ts
+- Created content-parser.ts with 18 detection functions
+- Implemented code block skipping (fenced and inline)
+- Added overlap handling with priority-based filtering
+- Location tracking (start, end, line number)
+- Created comprehensive test suite (75 tests)
+
+**Verification:** npx mocha content-parser.test.ts - 75 tests passing
+
+### Task 3: Implement Content Transformers and CLI Integration
+**Status:** Completed
+**Date:** 2026-01-12
+**Commit:** 86de265
+
+**Changes:**
+- Added ContentTransformer interface and TransformedContent type
+- Created ClaudeCodeContentTransformer, WindsurfContentTransformer, CopilotContentTransformer
+- Updated adapters to integrate content transformation
+- Added createContentTransformer factory function
+- Created comprehensive test suite (48 tests)
+
+**Verification:** Full suite - 179 tests passing
+
+---
+
+## Phase 5 Summary
+
+**Status:** Completed
+**Date:** 2026-01-12
+**Total Commits:** 3
+**Total Tests Added:** 123 (75 parser + 48 transformer)
+
+**Deliverables:**
+- CONTENT-SCHEMA.md with 18 semantic constructs documented
+- Content parser with detection engine (content-parser.ts)
+- Three platform-specific content transformers (content-transformers.ts)
+- Updated adapters with content transformation integration
+- Comprehensive test coverage (179 total template-mapper tests)
+
+**Phase Completion Criteria:**
+- [x] All tasks completed (3/3)
+- [x] CONTENT-SCHEMA.md created with 18 documented constructs
+- [x] Content parser detects all construct types
+- [x] Transformers handle all platforms (Claude Code, Windsurf, GitHub Copilot)
+- [x] Code block detection prevents false positives
+- [x] Test coverage for all detection and transformation logic
+- [x] Adapters updated to use content transformation
+
+**Next Recommended Action:** `/gsd:verify-work 5` to perform user acceptance testing of Phase 5 deliverables
diff --git a/WORKAROUND-PATTERNS.md b/WORKAROUND-PATTERNS.md
new file mode 100644
index 0000000..c3b658c
--- /dev/null
+++ b/WORKAROUND-PATTERNS.md
@@ -0,0 +1,1736 @@
+# Workaround Patterns for Cross-Platform Template Compatibility
+
+**Version:** 1.0.0
+**Date:** 2026-01-12
+**Purpose:** Practical emulation patterns for capability gaps across AI assistant platforms
+
+---
+
+## Overview
+
+This document provides tested, practical workaround patterns for emulating missing capabilities across Claude Code, Windsurf, and GitHub Copilot. Each pattern includes:
+
+- **Problem Statement** - The capability gap being addressed
+- **Standard Format** - How the feature is expressed in the superset schema
+- **Emulation Strategy** - How to replicate the feature on platforms that lack native support
+- **Implementation Examples** - Working code samples
+- **Activation Mechanism** - How the pattern is triggered
+- **Known Limitations** - What the emulation cannot achieve
+- **Manual Traceability** - Step-by-step execution flow
+
+---
+
+## Pattern 1: Skill Emulation for Windsurf
+
+### Problem Statement
+
+**Gap:** Windsurf does not have Claude Code's "skills" feature - reusable, composable AI instructions that can be invoked by name and support subagent spawning.
+
+**Reference:** GAP-ANALYSIS.md Gap #W1 (Subagent Spawning)
+
+**Impact:**
+- Cannot create reusable command-like AI behaviors
+- Cannot delegate tasks to specialized agents
+- Cannot spawn isolated execution contexts
+- All work must be done in single Cascade session
+
+### Standard Format
+
+In the superset schema, a Claude Code skill looks like this:
+
+```yaml
+---
+name: security-review
+description: USE WHEN reviewing code for security vulnerabilities
+version: "1.0.0"
+allowed-tools:
+  - Read
+  - Grep
+  - Bash(npm audit)
+context: fork
+agent: security-specialist
+---
+
+# Security Review Skill
+
+## Objective
+Perform comprehensive security analysis of codebase.
+
+## Steps
+1. Scan for common vulnerabilities
+2. Review authentication/authorization
+3. Check for exposed secrets
+4. Generate security report
+```
+
+### Emulation Strategy
+
+Windsurf can emulate skills using a combination of:
+
+1. **Workflows as Skill Containers** - Store skill content in `.windsurf/workflows/{skill-name}.md`
+2. **Model Decision Triggers** - Use `trigger: model_decision` so Windsurf activates the workflow when relevant
+3. **Context Markers** - Add explicit context boundaries to simulate isolation
+4. **Persona Rules** - Use separate rule files to emulate custom agents
+5. **Advisory Restrictions** - Document tool/permission restrictions (not enforced)
+
+### Implementation Example
+
+**Input: Standard Format Skill**
+
+```yaml
+---
+name: commit-helper
+description: USE WHEN creating git commits. Helps write conventional commit messages.
+version: "1.0.0"
+allowed-tools:
+  - Bash(git status)
+  - Bash(git diff)
+  - Bash(git add)
+  - Bash(git commit)
+context: inherit
+---
+
+# Commit Helper
+
+## Process
+1. Run `git status` to see changes
+2. Run `git diff` to review modifications
+3. Ask user for commit type (feat/fix/docs/refactor/etc)
+4. Generate conventional commit message
+5. Execute commit with user approval
+```
+
+**Output: Windsurf-Adapted Workflow**
+
+**File:** `.windsurf/workflows/commit-helper.md`
+
+```yaml
+---
+description: USE WHEN creating git commits. Helps write conventional commit messages.
+trigger: model_decision
+labels:
+  - git
+  - automation
+  - commits
+---
+
+# Commit Helper
+
+<!-- Version: 1.0.0 -->
+<!-- Adapted from Claude Code skill -->
+
+## Tool Restrictions (Advisory)
+
+> **NOTE:** These restrictions rely on AI compliance and are NOT enforced by Windsurf.
+
+**Allowed Operations:**
+- Git status checks (`git status`)
+- View changes (`git diff`)
+- Stage files (`git add`)
+- Create commits (`git commit`)
+
+**Forbidden Operations:**
+- File editing
+- Non-git shell commands
+- Destructive git operations (force push, hard reset)
+
+**IMPORTANT:** Before using tools outside this list, ask user for permission.
+
+---
+
+## Execution Context
+
+This workflow uses inherited context (normal Cascade session).
+
+---
+
+## Process
+
+1. Run `git status` to see changes
+2. Run `git diff` to review modifications
+3. Ask user for commit type (feat/fix/docs/refactor/etc)
+4. Generate conventional commit message
+5. Execute commit with user approval
+
+---
+
+## Invocation
+
+This workflow activates automatically when:
+- User mentions "commit", "git commit", or "create a commit"
+- Windsurf's AI determines commit creation is relevant
+
+Manual invocation: `/commit-helper`
+```
+
+**For skills with custom agents:**
+
+If the standard format includes `agent: security-specialist`, create an additional rule file:
+
+**File:** `.windsurf/rules/agent-security-specialist.md`
+
+```yaml
+---
+trigger: manual
+description: Activate security-specialist persona with @rules:agent-security-specialist
+---
+
+# Security Specialist Persona
+
+When @rules:agent-security-specialist is active, adopt this persona:
+
+## Role
+You are a specialized security review agent focused on identifying vulnerabilities and security risks.
+
+## Behavioral Guidelines
+- Prioritize security issues by severity (Critical/High/Medium/Low)
+- Always check for OWASP Top 10 vulnerabilities
+- Focus on authentication, authorization, input validation, and data exposure
+- Provide specific remediation steps with code examples
+
+## Focus Areas
+- SQL injection and NoSQL injection
+- Cross-site scripting (XSS)
+- Authentication bypass
+- Authorization flaws
+- Exposed secrets and credentials
+- Insecure dependencies
+
+## Activation
+User invokes with: `@rules:agent-security-specialist`
+
+## Deactivation
+Returns to default Cascade behavior when user starts new topic.
+
+> **NOTE:** Tool restrictions cannot be enforced in Windsurf. Rely on AI compliance.
+```
+
+**Referencing the agent in the workflow:**
+
+Add this section to the workflow:
+
+```markdown
+## Agent Persona
+
+This workflow uses the **security-specialist** agent.
+Activate with: `@rules:agent-security-specialist` before running this workflow.
+```
+
+### Activation Mechanism
+
+**Model Decision Trigger:**
+
+```yaml
+trigger: model_decision
+description: USE WHEN creating git commits. Helps write conventional commit messages.
+```
+
+**How it works:**
+
+1. User mentions "commit" or related terms in conversation
+2. Windsurf's AI analyzes context and determines this workflow is relevant
+3. Workflow is automatically loaded and instructions become active
+4. AI follows the workflow steps to guide user through commit creation
+
+**Manual Trigger:**
+
+User can also explicitly invoke: `/commit-helper`
+
+**Activation Conditions:**
+
+The `description` field acts as a trigger condition. Best practices:
+
+- Start with "USE WHEN" to signal activation pattern
+- Include specific keywords AI should match (e.g., "git commits", "creating commits")
+- Describe the scenario where skill is relevant
+- Be specific enough to avoid false activations
+
+**Example Activation Descriptions:**
+
+```yaml
+# Good: Specific and clear
+description: USE WHEN reviewing Python code for security vulnerabilities
+
+# Good: Multiple trigger scenarios
+description: USE WHEN deploying to production OR when user asks about deployment process
+
+# Poor: Too vague (activates too often)
+description: Help with code
+
+# Poor: Too narrow (AI might miss valid scenarios)
+description: Only activate when user types exactly "run security scan"
+```
+
+### Known Limitations
+
+1. **No True Subagents:**
+   - Cannot spawn parallel isolated contexts
+   - All work happens in single Cascade session
+   - Context pollution risk (previous conversation affects workflow)
+
+2. **No Permission Enforcement:**
+   - `allowed-tools` converted to advisory instructions
+   - AI may ignore restrictions if prompted or deemed necessary
+   - No system-level enforcement like Claude Code
+
+3. **Manual Agent Activation:**
+   - Custom agents require manual `@rules:agent-{name}` invocation
+   - Agent cannot be automatically attached to workflow
+   - User must remember to activate persona before running workflow
+
+4. **Context Isolation:**
+   - `context: fork` can only be simulated with markers
+   - Workflow cannot truly start fresh session
+   - Prior conversation history always available to AI
+
+5. **Model Decision Reliability:**
+   - AI activation not guaranteed
+   - May activate when not needed (false positives)
+   - May fail to activate when appropriate (false negatives)
+   - Less deterministic than explicit skill invocation in Claude Code
+
+### Manual Traceability
+
+**Execution Flow: How Windsurf Processes the Emulated Skill**
+
+1. **User Action:** User says "help me commit these changes"
+
+2. **Model Decision:** Windsurf's AI:
+   - Analyzes user intent
+   - Scans available workflows with `trigger: model_decision`
+   - Matches "commit these changes" to workflow description "USE WHEN creating git commits"
+   - Decides to activate `commit-helper` workflow
+
+3. **Context Loading:** Windsurf loads `.windsurf/workflows/commit-helper.md`:
+   - Reads YAML frontmatter (description, trigger, labels)
+   - Parses markdown body as instructions
+   - Makes content available to AI's context window
+
+4. **Instruction Following:** AI reads and follows:
+   - Tool Restrictions section (advisory only)
+   - Process steps (1-5)
+   - Execution context notes
+
+5. **Execution:** AI executes workflow:
+   - Runs `git status` (Step 1)
+   - Runs `git diff` (Step 2)
+   - Asks user for commit type (Step 3)
+   - Generates conventional commit message (Step 4)
+   - Requests user approval and commits (Step 5)
+
+6. **Completion:** Workflow completes, Cascade returns to normal mode
+
+**Verification Points:**
+
+- **Before:** `.windsurf/workflows/commit-helper.md` exists and is valid YAML+Markdown
+- **During:** AI mentions following the workflow or references specific steps
+- **After:** User receives conventional commit message and commit is created
+
+**Debugging:**
+
+If workflow doesn't activate:
+1. Check file exists: `.windsurf/workflows/commit-helper.md`
+2. Verify YAML frontmatter is valid
+3. Try manual invocation: `/commit-helper`
+4. Check description includes relevant keywords
+5. Ensure `trigger: model_decision` is set
+
+If workflow activates incorrectly:
+1. Make description more specific
+2. Add negative keywords ("do NOT activate when...")
+3. Consider changing to `trigger: manual` for explicit control
+
+---
+
+## Pattern 2: Workflow Emulation for Claude Code
+
+### Problem Statement
+
+**Gap:** Claude Code skills lack Windsurf's AI-driven activation (model decision triggers) and automatic multi-file context awareness. This creates challenges when adapting Windsurf workflows that rely on:
+
+- **AI-Driven Activation:** Windsurf workflows activate automatically when Cascade determines they're relevant to the current task
+- **Multi-File Context:** Windsurf automatically loads all files matching glob patterns into context
+- **Contextual Awareness:** Workflows have access to related files without explicit Read operations
+
+**Reference:** PLATFORM-ADAPTERS.md Section 4.1 (Claude Code Adapter)
+
+**Impact:**
+- Claude Code skills require manual invocation by user
+- Skills must explicitly gather file context using Read/Grep/Glob tools
+- AI cannot automatically determine when a skill is relevant
+- Multi-file refactoring requires sequential, explicit file loading
+
+### Standard Format
+
+In the superset schema, a Windsurf workflow with AI activation looks like this:
+
+```yaml
+---
+description: USE WHEN refactoring React components for better modularity
+trigger: model_decision
+globs:
+  - "src/components/**/*.tsx"
+  - "src/components/**/*.ts"
+labels:
+  - refactoring
+  - react
+---
+
+# Refactor Components Workflow
+
+## Prerequisites
+
+Windsurf's multi-file context automatically gathers:
+- All components in src/components/
+- Related hooks and utilities
+- Component test files
+
+## Steps
+1. Analyze all components for duplicate logic
+2. Extract shared patterns
+3. Update imports across files
+4. Verify tests pass
+```
+
+Key features:
+- `trigger: model_decision` - AI decides when to activate
+- `globs` - Files automatically loaded into context
+- No explicit Read operations needed
+
+### Emulation Strategy
+
+Claude Code can emulate Windsurf workflows using:
+
+1. **Description-Based Activation Hints** - Include trigger keywords in skill description to help AI suggest skill usage
+2. **Explicit Context Gathering** - Add "Step 0" that uses Glob/Grep/Read to build multi-file context
+3. **Context Gathering Checklist** - Document which files must be loaded before proceeding
+4. **Activation Guidance** - Clearly state when user should invoke skill
+5. **Comprehensive Descriptions** - Embed activation scenarios in `description` field
+
+### Implementation Example
+
+**Input: Windsurf Workflow (Standard Format)**
+
+```yaml
+---
+description: USE WHEN user asks to optimize API performance
+trigger: model_decision
+globs:
+  - "src/api/**/*.ts"
+  - "src/middleware/**/*.ts"
+labels:
+  - performance
+  - optimization
+---
+
+# API Performance Optimization
+
+## Steps
+1. Profile current API response times
+2. Identify slow endpoints
+3. Optimize database queries
+4. Add caching where appropriate
+```
+
+**Output: Claude Code Skill (Adapted Format)**
+
+**File:** `.claude/skills/optimize-api-performance/SKILL.md`
+
+```yaml
+---
+name: optimize-api-performance
+description: >
+  USE WHEN user asks to optimize API performance, improve response times,
+  reduce latency, or speed up endpoints. Analyzes API routes, identifies
+  bottlenecks, optimizes queries, and implements caching strategies.
+  Activate when user mentions: optimize API, slow endpoints, improve performance,
+  reduce latency, speed up API, or cache API responses.
+version: "1.0.0"
+allowed-tools:
+  - Read
+  - Grep
+  - Glob
+  - Bash(npm run profile)
+context: inherit
+permissions:
+  allow:
+    - Read(src/api/**/*.ts)
+    - Read(src/middleware/**/*.ts)
+    - Read(src/database/**/*.ts)
+---
+
+# API Performance Optimization Skill
+
+## Purpose
+
+Profile API performance, identify slow endpoints, optimize database queries, and implement caching strategies.
+
+**Emulated Multi-File Context:** This skill replicates Windsurf's automatic multi-file loading by explicitly gathering context before optimization begins.
+
+---
+
+## Context Gathering Protocol
+
+**IMPORTANT:** Before beginning performance analysis, gather comprehensive context:
+
+### Step 0: Multi-File Context Acquisition
+
+Execute these operations to simulate Windsurf's automatic context loading:
+
+1. **List all API route files:**
+   ```
+   Glob: src/api/**/*.ts
+   ```
+
+2. **Find middleware:**
+   ```
+   Glob: src/middleware/**/*.ts
+   ```
+
+3. **Identify database query files:**
+   ```
+   Grep: pattern="query|findMany|findUnique" path="src/"
+   ```
+
+4. **Locate caching logic:**
+   ```
+   Grep: pattern="cache|redis|memcached" path="src/"
+   ```
+
+**Context Checklist:**
+- [ ] All API routes identified
+- [ ] Middleware files loaded
+- [ ] Database query patterns discovered
+- [ ] Existing caching mechanisms found
+
+**Only proceed to profiling once context gathering is complete.**
+
+---
+
+## Optimization Steps
+
+### Step 1: Profile Current Performance
+Run profiling tools to measure:
+- API response times
+- Database query durations
+- Memory usage patterns
+
+### Step 2: Identify Bottlenecks
+Analyze profiling results to find:
+- Slowest endpoints (>500ms response time)
+- N+1 query problems
+- Missing indexes
+- Unoptimized queries
+
+### Step 3: Optimize Queries
+Based on gathered context from Step 0:
+- Refactor slow queries in identified files
+- Add database indexes
+- Implement query result caching
+
+### Step 4: Verify Improvements
+Re-run profiling to confirm:
+- Response times reduced by ≥30%
+- Query count decreased
+- No functionality regressions
+
+---
+
+## Activation Instructions
+
+**Manual Invocation (Required):**
+
+Unlike Windsurf's automatic activation, this skill must be manually invoked.
+
+**When to invoke this skill:**
+
+Use when user mentions:
+- "optimize API performance"
+- "slow endpoints"
+- "improve response times"
+- "reduce API latency"
+- "speed up the API"
+- "cache API responses"
+
+**Invocation command:** `/optimize-api-performance`
+
+**Description-based matching:** The skill's description includes trigger keywords to help AI recognize relevance, but user must still explicitly invoke the skill.
+
+---
+
+## Multi-File Context Simulation
+
+**Windsurf Capability:** Automatic multi-file context via `globs: ["src/api/**/*.ts"]`
+**Claude Code Emulation:** Explicit context gathering in Step 0
+
+### How Context Gathering Works
+
+**Windsurf (Automatic):**
+```yaml
+globs:
+  - "src/api/**/*.ts"  # All files loaded into context automatically
+  - "src/middleware/**/*.ts"
+```
+- Files loaded before workflow starts
+- Cascade has full visibility into all matched files
+- No explicit Read operations needed
+
+**Claude Code (Explicit):**
+```markdown
+### Step 0: Multi-File Context Acquisition
+
+1. Glob: src/api/**/*.ts
+2. Glob: src/middleware/**/*.ts
+3. Read each identified file
+4. Build mental model of API structure
+```
+- Files discovered using Glob
+- Files loaded sequentially using Read
+- AI builds context incrementally
+- Explicit checklist ensures completeness
+
+### Context Gathering Best Practices
+
+1. **Always include Step 0** in workflow-adapted skills
+2. **Use Glob to discover files** before Reading them
+3. **Document expected files** in context checklist
+4. **Verify context completeness** before proceeding
+5. **Batch Read operations** for efficiency
+
+---
+
+## Activation Mechanism Comparison
+
+### Windsurf: AI-Driven Activation
+
+```yaml
+trigger: model_decision
+description: USE WHEN user asks to optimize API performance
+```
+
+**How it works:**
+1. User says: "The API is slow, can you help?"
+2. Windsurf's model decision engine:
+   - Analyzes user intent
+   - Scans workflows with `trigger: model_decision`
+   - Matches "API is slow" to description keywords
+   - Automatically activates workflow
+3. Workflow executes without user needing to know its name
+
+**Advantages:**
+- Zero friction - AI handles activation
+- User doesn't need to know workflow names
+- Natural conversation flow
+
+### Claude Code: Description-Based Hints
+
+```yaml
+description: >
+  USE WHEN user asks to optimize API performance, improve response times,
+  reduce latency, or speed up endpoints.
+  Activate when user mentions: optimize API, slow endpoints, improve performance.
+```
+
+**How it works:**
+1. User says: "The API is slow, can you help?"
+2. Claude Code AI:
+   - Recognizes keywords in user message
+   - Scans skill descriptions for matches
+   - **Suggests** the skill to user: "I can help with `/optimize-api-performance` skill"
+3. User **must manually invoke**: `/optimize-api-performance`
+4. Skill executes
+
+**Advantages:**
+- Explicit user control over skill execution
+- AI can suggest relevant skills
+- Clear activation point for debugging
+
+**Limitations:**
+- Requires user action to invoke
+- Adds friction to workflow
+- User must remember to invoke suggested skill
+
+### Emulation Pattern: Rich Descriptions
+
+To compensate for lack of automatic activation, include comprehensive trigger conditions in the `description` field:
+
+**Template:**
+```yaml
+description: >
+  USE WHEN {primary use case}.
+  {Detailed explanation of what skill does}.
+  Activate when user mentions: {keyword 1}, {keyword 2}, {keyword 3}.
+```
+
+**Example:**
+```yaml
+description: >
+  USE WHEN refactoring React components for better modularity and reusability.
+  Analyzes component structure, extracts shared logic, and improves modularity.
+  Activate when user mentions: refactor components, improve component structure,
+  extract shared logic, split components, or modularize React code.
+```
+
+**Best Practices:**
+- Start with "USE WHEN" to signal activation pattern
+- List 5-10 trigger phrases users might say
+- Include synonyms and variations
+- Be specific about use cases
+- Mention file types/patterns if relevant
+
+---
+
+## Known Limitations
+
+1. **No Automatic Activation:**
+   - Windsurf: Workflow activates automatically via model decision
+   - Claude Code: User must manually invoke skill
+   - Mitigation: Rich descriptions help AI suggest relevant skills
+   - Impact: Higher friction, requires user awareness of skill names
+
+2. **Manual Context Gathering Required:**
+   - Windsurf: `globs` field loads files automatically
+   - Claude Code: Must use Glob/Grep/Read in Step 0
+   - Risk: AI might skip context gathering, leading to incomplete analysis
+   - Mitigation: Make Step 0 mandatory, include context checklist
+
+3. **No True Model Decision Engine:**
+   - Windsurf: AI evaluates relevance automatically
+   - Claude Code: Relies on description matching and user judgment
+   - Limitation: User must recognize when skill is appropriate
+   - Workaround: Provide clear "when to use" guidance in skill body
+
+4. **Sequential Context Loading:**
+   - Windsurf: All files loaded simultaneously
+   - Claude Code: Files loaded one-by-one
+   - Impact: Slower context gathering, more verbose execution
+   - Mitigation: Use Glob to batch-discover files before Reading
+
+5. **Context Window Constraints:**
+   - Windsurf: Optimized for multi-file workflows
+   - Claude Code: Large file counts may exceed context limits
+   - Workaround: Prioritize most relevant files, use chunking for large operations
+
+### Manual Traceability
+
+**Execution Flow: How Claude Code Processes the Emulated Workflow**
+
+1. **User Action:** User says "our API endpoints are slow, help optimize them"
+
+2. **AI Recognition:** Claude Code AI:
+   - Scans skill descriptions
+   - Matches "slow" and "optimize" to `optimize-api-performance` description
+   - Suggests: "I can help with the `/optimize-api-performance` skill which analyzes API routes and optimizes performance"
+
+3. **User Invocation:** User types: `/optimize-api-performance`
+
+4. **Skill Loading:** Claude Code:
+   - Loads `.claude/skills/optimize-api-performance/SKILL.md`
+   - Reads YAML frontmatter (name, description, allowed-tools, permissions)
+   - Parses markdown body as instructions
+   - Makes content available to AI
+
+5. **Context Gathering (Step 0):** AI executes:
+   ```
+   Glob: src/api/**/*.ts       → Discovers 15 API route files
+   Glob: src/middleware/**/*.ts → Discovers 3 middleware files
+   Grep: "query|findMany"       → Finds database query patterns
+   Read: {identified files}     → Loads file contents
+   ```
+
+6. **Context Verification:** AI checks context checklist:
+   - [x] All API routes identified
+   - [x] Middleware files loaded
+   - [x] Database query patterns discovered
+   - [x] Existing caching mechanisms found
+
+7. **Workflow Execution:** AI follows optimization steps:
+   - Step 1: Profile performance (uses gathered file context)
+   - Step 2: Identify bottlenecks (analyzes loaded files)
+   - Step 3: Optimize queries (modifies files in context)
+   - Step 4: Verify improvements
+
+8. **Completion:** Skill completes, results reported to user
+
+**Verification Points:**
+
+- **Before:** `.claude/skills/optimize-api-performance/SKILL.md` exists and is valid
+- **During:** AI executes Step 0 context gathering before proceeding to analysis
+- **During:** AI references specific files from gathered context
+- **After:** Optimizations applied to files identified in Step 0
+- **After:** User receives performance improvement report
+
+**Debugging:**
+
+If skill doesn't work as expected:
+
+1. **Skill not suggested:**
+   - Check description includes relevant keywords
+   - Ensure "USE WHEN" statement matches user intent
+   - Add more trigger phrases to description
+
+2. **Context gathering incomplete:**
+   - Verify Step 0 is clearly marked as mandatory
+   - Check context checklist is present
+   - Ensure Glob patterns match actual file locations
+
+3. **Multi-file coordination fails:**
+   - Confirm AI loaded all relevant files in Step 0
+   - Check that subsequent steps reference gathered context
+   - Verify permissions allow access to required files
+
+4. **Compared to Windsurf:**
+   - Execute same task in Windsurf (automatic activation, automatic context)
+   - Execute in Claude Code (manual invocation, explicit context gathering)
+   - Verify outcomes are equivalent despite different mechanisms
+
+---
+
+## Pattern Application Guide
+
+**When to use this pattern:**
+
+Use Workflow Emulation Pattern when converting Windsurf workflows to Claude Code skills if the workflow:
+
+- ✅ Uses `trigger: model_decision` for AI-driven activation
+- ✅ Relies on `globs` to automatically load multiple files
+- ✅ Requires multi-file context awareness
+- ✅ Performs coordinated changes across related files
+- ✅ Benefits from understanding relationships between files
+
+**When NOT to use this pattern:**
+
+Skip this pattern if:
+
+- ❌ Workflow is single-file focused
+- ❌ Manual invocation is acceptable
+- ❌ Context requirements are simple
+- ❌ No multi-file coordination needed
+
+**Example Use Cases:**
+
+- **Refactoring workflows** - Extract shared logic across components
+- **Performance optimization** - Analyze and optimize API routes
+- **Migration tasks** - Update imports across multiple files
+- **Code review** - Analyze related files for consistency
+- **Dependency updates** - Update usage patterns across codebase
+
+---
+
+## Complete Example
+
+See `examples/workflow-example.md` for a complete, working example that demonstrates:
+
+- Original Windsurf workflow with model_decision trigger and globs
+- Adapted Claude Code skill with explicit context gathering
+- Step 0 context acquisition protocol
+- Context checklist for verification
+- Activation guidance for users
+- Comparison of Windsurf automatic vs Claude Code explicit approaches
+
+---
+
+## Pattern Summary Table
+
+| Pattern Name | Platform | Gap Addressed | Emulation Approach | Key Limitations |
+|-------------|----------|---------------|-------------------|-----------------|
+| **Skill Emulation** | Windsurf | No skills/subagents | Workflows + Model Decision + Persona Rules | No true isolation, no permission enforcement, manual agent activation |
+| **Workflow Emulation** | Claude Code | No AI-driven activation, no automatic multi-file context | Rich descriptions + Explicit context gathering (Step 0) | Manual invocation required, sequential context loading, no model decision engine |
+
+---
+
+## Cross-References
+
+- **GAP-ANALYSIS.md** - Gap #W1 (Subagent Spawning)
+- **PLATFORM-ADAPTERS.md** - Section 2.2 (Windsurf Emulation Patterns)
+- **PLATFORM-ADAPTERS.md** - Section 4.1 (Claude Code Adapter) - Workflow transformation rules
+- **STANDARD-SCHEMA.md** - Skill field definitions
+- **STANDARD-STRUCTURE.md** - Workflow file organization
+- **examples/workflow-example.md** - Complete working example of workflow emulation
+
+---
+
+## Pattern 3: Working Set Limitation Pattern for GitHub Copilot
+
+### Problem Statement
+
+**Gap:** GitHub Copilot has severe working set and context limitations that make large-scale refactoring and complex multi-file operations extremely difficult or impossible.
+
+**Reference:** GAP-ANALYSIS.md Gap #GH1 (Working Set and Context Limitations)
+
+**Impact:**
+- Maximum 10 files in working set at once
+- Maximum 20 files for context awareness
+- ~6,000 character context window for fast models
+- Quality degrades on files >782 lines
+- Significant problems on files >5,000 lines
+- Cannot effectively work on larger projects
+- Community considering alternatives due to restrictions
+
+### Standard Format
+
+In the superset schema, a skill designed for large-scale operations looks like this:
+
+```yaml
+---
+name: refactor-authentication
+description: Refactor authentication system across the entire codebase
+version: "1.0.0"
+allowed-tools:
+  - Read
+  - Write
+  - Grep
+  - Glob
+context: inherit
+permissions:
+  allow:
+    - Read(src/**/auth*.ts)
+    - Read(src/**/user*.ts)
+    - Write(src/**/auth*.ts)
+    - Write(src/**/user*.ts)
+---
+
+# Authentication System Refactor
+
+## Scope
+Refactor the authentication system across 25+ files:
+- src/auth/*.ts (8 files)
+- src/api/auth/*.ts (6 files)
+- src/middleware/auth*.ts (3 files)
+- src/models/user*.ts (4 files)
+- src/services/auth*.ts (4 files)
+
+## Objectives
+1. Standardize authentication patterns
+2. Extract shared logic
+3. Update all import references
+4. Ensure tests pass
+```
+
+This would fail on GitHub Copilot due to exceeding the 10-file working set limit.
+
+### Emulation Strategy
+
+GitHub Copilot can handle large operations using a combination of:
+
+1. **Skill Decomposition** - Break large skills into smaller, focused sub-skills that each operate on ≤10 files
+2. **Batch Processing** - Process files in sequential batches with checkpoints
+3. **File Prioritization** - Keep most-referenced/core files in working set, rotate peripheral files
+4. **Skill Chaining** - Create skills that reference and build upon each other
+5. **@workspace Fallback** - Document when to use `@workspace` for discovery vs batching for implementation
+
+### Implementation Example
+
+**Input: Standard Format Skill (Too Large for Copilot)**
+
+```yaml
+---
+name: refactor-authentication
+description: Refactor authentication system across the entire codebase
+version: "1.0.0"
+allowed-tools:
+  - Read
+  - Write
+  - Grep
+context: inherit
+platforms: [claude-code, windsurf, github-copilot]
+---
+
+# Authentication System Refactor
+
+## Scope
+Refactor authentication across 25 files in:
+- src/auth/ (8 files)
+- src/api/auth/ (6 files)
+- src/middleware/ (3 files)
+- src/models/ (4 files)
+- src/services/ (4 files)
+
+## Objectives
+1. Standardize authentication patterns
+2. Extract shared logic
+3. Update all import references
+4. Ensure tests pass
+```
+
+**Output: Decomposed Sub-Skills for GitHub Copilot**
+
+**Decision Tree Applied:**
+
+1. **Count affected files:** 25 files
+2. **Exceeds 10-file limit?** Yes
+3. **Can be logically split?** Yes (by module)
+4. **Strategy:** Decompose into sub-skills
+
+**File 1:** `.github/prompts/refactor-auth-core.prompt.md`
+
+```yaml
+---
+description: Refactor core authentication logic (Part 1 of 4)
+applyTo:
+  - "src/auth/*.ts"
+mode: agent
+---
+
+# Authentication Refactor - Part 1: Core Logic
+
+<!-- Part 1 of 4: Core Authentication Module -->
+<!-- Version: 1.0.0 -->
+
+## Scope
+
+**This prompt handles:** Core authentication files in `src/auth/` (8 files)
+
+**Working Set (8 files):**
+1. src/auth/auth-service.ts
+2. src/auth/jwt-handler.ts
+3. src/auth/password-hash.ts
+4. src/auth/session-manager.ts
+5. src/auth/token-validator.ts
+6. src/auth/auth-middleware.ts
+7. src/auth/auth-types.ts
+8. src/auth/auth-utils.ts
+
+## Objectives
+
+1. Standardize authentication patterns in core module
+2. Extract shared logic within src/auth/
+3. Ensure consistent error handling
+4. Document exported interfaces
+
+## Workflow
+
+### Step 1: Analyze Core Files
+Review all 8 files in src/auth/ for:
+- Duplicate logic
+- Inconsistent patterns
+- Shared utilities that should be extracted
+
+### Step 2: Standardize Patterns
+Apply consistent patterns for:
+- JWT token handling
+- Password hashing
+- Session management
+- Error responses
+
+### Step 3: Extract Shared Logic
+Create new files if needed (within 10-file limit):
+- src/auth/auth-constants.ts (if needed)
+- src/auth/auth-errors.ts (if needed)
+
+### Step 4: Update Internal Imports
+Update imports within src/auth/ module only.
+Do NOT modify external imports yet (handled in Part 4).
+
+### Step 5: Checkpoint
+Create commit: `refactor(auth): part 1 - standardize core auth module`
+
+## Next Steps
+
+After completing this part:
+1. Run tests: `npm test src/auth/`
+2. Verify no regressions
+3. Proceed to Part 2: `/prompt refactor-auth-api`
+
+## Related Files (Not Modified Here)
+
+The following files depend on src/auth/ but are handled in later parts:
+- src/api/auth/*.ts (Part 2)
+- src/middleware/*.ts (Part 3)
+- src/models/*.ts, src/services/*.ts (Part 4)
+```
+
+**File 2:** `.github/prompts/refactor-auth-api.prompt.md`
+
+```yaml
+---
+description: Refactor authentication API routes (Part 2 of 4)
+applyTo:
+  - "src/api/auth/*.ts"
+  - "src/auth/auth-types.ts"
+mode: agent
+---
+
+# Authentication Refactor - Part 2: API Routes
+
+<!-- Part 2 of 4: API Integration -->
+<!-- Version: 1.0.0 -->
+
+## Prerequisites
+
+**IMPORTANT:** Complete Part 1 (`refactor-auth-core`) before starting this part.
+
+Part 1 should have:
+- Standardized core authentication patterns
+- Extracted shared logic
+- Created stable interfaces in src/auth/
+
+## Scope
+
+**This prompt handles:** Authentication API routes (6 files) + core types reference (1 file)
+
+**Working Set (7 files):**
+1. src/api/auth/login-route.ts
+2. src/api/auth/register-route.ts
+3. src/api/auth/logout-route.ts
+4. src/api/auth/refresh-route.ts
+5. src/api/auth/verify-route.ts
+6. src/api/auth/password-reset-route.ts
+7. src/auth/auth-types.ts (reference - core types)
+
+**Rationale:** Keep auth-types.ts in working set as reference for consistent interface usage.
+
+## Objectives
+
+1. Update API routes to use standardized auth patterns from Part 1
+2. Ensure all routes use consistent error handling
+3. Update imports to reference refactored core module
+4. Maintain API contract (no breaking changes)
+
+## Workflow
+
+### Step 1: Review Core Changes
+Read src/auth/auth-types.ts to understand new interfaces from Part 1.
+
+### Step 2: Update API Routes
+For each route file:
+- Update imports from src/auth/
+- Use standardized authentication methods
+- Apply consistent error handling
+- Maintain backward compatibility
+
+### Step 3: Verify API Contracts
+Ensure response formats unchanged (no breaking API changes).
+
+### Step 4: Checkpoint
+Create commit: `refactor(auth): part 2 - update API routes to use core auth`
+
+## Next Steps
+
+After completing this part:
+1. Run tests: `npm test src/api/auth/`
+2. Test API endpoints manually if needed
+3. Proceed to Part 3: `/prompt refactor-auth-middleware`
+
+## Related Files (Not Modified Here)
+
+- src/middleware/*.ts (Part 3)
+- src/models/*.ts, src/services/*.ts (Part 4)
+```
+
+**File 3:** `.github/prompts/refactor-auth-middleware.prompt.md`
+
+```yaml
+---
+description: Refactor authentication middleware (Part 3 of 4)
+applyTo:
+  - "src/middleware/*.ts"
+  - "src/auth/auth-types.ts"
+mode: agent
+---
+
+# Authentication Refactor - Part 3: Middleware
+
+<!-- Part 3 of 4: Middleware Integration -->
+<!-- Version: 1.0.0 -->
+
+## Prerequisites
+
+**IMPORTANT:** Complete Parts 1 and 2 before starting this part.
+
+Previous parts should have:
+- Part 1: Standardized core authentication module
+- Part 2: Updated API routes to use new patterns
+
+## Scope
+
+**This prompt handles:** Authentication middleware (3 files) + core types reference (1 file)
+
+**Working Set (4 files):**
+1. src/middleware/auth-required.ts
+2. src/middleware/role-check.ts
+3. src/middleware/token-refresh.ts
+4. src/auth/auth-types.ts (reference - core types)
+
+**Rationale:** Middleware is tightly coupled to auth-types, keep in working set for reference.
+
+## Objectives
+
+1. Update middleware to use refactored authentication service
+2. Ensure consistent error responses
+3. Update imports to use standardized core module
+4. Maintain middleware interface (no breaking changes to route handlers)
+
+## Workflow
+
+### Step 1: Review Core Interface
+Read src/auth/auth-types.ts and src/auth/auth-service.ts (from Part 1).
+
+### Step 2: Update Middleware
+For each middleware file:
+- Update imports from src/auth/
+- Use standardized authentication methods
+- Apply consistent error handling
+- Ensure middleware signature unchanged
+
+### Step 3: Verify Middleware Contracts
+Test that existing routes using this middleware still work.
+
+### Step 4: Checkpoint
+Create commit: `refactor(auth): part 3 - update middleware to use core auth`
+
+## Next Steps
+
+After completing this part:
+1. Run tests: `npm test src/middleware/`
+2. Test middleware integration with sample routes
+3. Proceed to Part 4: `/prompt refactor-auth-finalize`
+
+## Related Files (Not Modified Here)
+
+- src/models/*.ts, src/services/*.ts (Part 4 - final integration)
+```
+
+**File 4:** `.github/prompts/refactor-auth-finalize.prompt.md`
+
+```yaml
+---
+description: Finalize authentication refactor - update remaining integrations (Part 4 of 4)
+applyTo:
+  - "src/models/user*.ts"
+  - "src/services/auth*.ts"
+  - "src/auth/auth-types.ts"
+mode: agent
+---
+
+# Authentication Refactor - Part 4: Finalization
+
+<!-- Part 4 of 4: Final Integration and Verification -->
+<!-- Version: 1.0.0 -->
+
+## Prerequisites
+
+**IMPORTANT:** Complete Parts 1, 2, and 3 before starting this part.
+
+Previous parts should have:
+- Part 1: Core authentication module standardized
+- Part 2: API routes updated
+- Part 3: Middleware updated
+
+## Scope
+
+**This prompt handles:** Remaining authentication-related files (8 files)
+
+**Working Set (9 files):**
+1. src/models/user.ts
+2. src/models/user-session.ts
+3. src/models/user-token.ts
+4. src/models/user-role.ts
+5. src/services/auth-service.ts
+6. src/services/auth-email-service.ts
+7. src/services/auth-logger.ts
+8. src/services/auth-audit.ts
+9. src/auth/auth-types.ts (reference - ensure consistency)
+
+## Objectives
+
+1. Update models and services to align with refactored auth core
+2. Ensure all cross-references are updated
+3. Remove any deprecated imports or patterns
+4. Run full test suite and verify system-wide consistency
+
+## Workflow
+
+### Step 1: Update Models
+Update user-related models:
+- Align with auth-types.ts interfaces
+- Update imports
+- Ensure database schema compatibility
+
+### Step 2: Update Services
+Update authentication services:
+- Use standardized core authentication methods
+- Update imports
+- Apply consistent error handling
+
+### Step 3: System-Wide Verification
+Run comprehensive tests:
+```bash
+npm test
+```
+
+Check for:
+- No import errors
+- All tests pass
+- No deprecated patterns remain
+
+### Step 4: Final Checkpoint
+Create commit: `refactor(auth): part 4 - finalize integration across all modules`
+
+### Step 5: Integration Test
+Run integration tests to verify:
+- Full authentication flow works
+- All API endpoints function
+- Middleware applies correctly
+- Models integrate properly
+
+## Completion Checklist
+
+- [ ] All 25 files refactored across 4 parts
+- [ ] Full test suite passes
+- [ ] No import errors
+- [ ] No deprecated patterns remain
+- [ ] Integration tests pass
+- [ ] Documentation updated (if needed)
+
+## Rollback Plan
+
+If integration issues discovered:
+1. Review commits from all 4 parts
+2. Identify problematic part
+3. Rollback specific commit: `git revert <commit-hash>`
+4. Fix issues and re-run that part
+
+## Summary
+
+This completes the 4-part authentication refactor:
+- **Part 1:** Core module (8 files)
+- **Part 2:** API routes (6 files)
+- **Part 3:** Middleware (3 files)
+- **Part 4:** Models & services (8 files)
+- **Total:** 25 files refactored within Copilot's 10-file working set limit
+```
+
+**File 5:** `.github/prompts/refactor-auth-coordinator.prompt.md`
+
+```yaml
+---
+description: Coordinate full authentication refactor (use this as entry point)
+mode: agent
+---
+
+# Authentication Refactor - Coordinator
+
+<!-- Master prompt for orchestrating the 4-part refactor -->
+<!-- Version: 1.0.0 -->
+
+## Overview
+
+This refactor has been decomposed into 4 sequential parts to work within GitHub Copilot's 10-file working set limit.
+
+**Original Scope:** 25 files across multiple modules
+**Copilot Limit:** 10 files per working set
+**Solution:** 4 batched sub-tasks, each ≤10 files
+
+## Execution Order
+
+Execute prompts in this order:
+
+### Part 1: Core Authentication Module
+**Prompt:** `/prompt refactor-auth-core`
+**Files:** 8 files in src/auth/
+**Duration:** ~15-20 minutes
+**Checkpoint:** Commit after completion
+
+### Part 2: API Routes
+**Prompt:** `/prompt refactor-auth-api`
+**Files:** 6 API route files + 1 reference file
+**Duration:** ~15-20 minutes
+**Checkpoint:** Commit after completion
+
+### Part 3: Middleware
+**Prompt:** `/prompt refactor-auth-middleware`
+**Files:** 3 middleware files + 1 reference file
+**Duration:** ~10-15 minutes
+**Checkpoint:** Commit after completion
+
+### Part 4: Models & Services
+**Prompt:** `/prompt refactor-auth-finalize`
+**Files:** 8 model/service files + 1 reference file
+**Duration:** ~15-20 minutes
+**Checkpoint:** Final commit
+
+## Total Estimated Time
+
+Approximately 55-75 minutes for complete refactor.
+
+## Progress Tracking
+
+Create `REFACTOR-PROGRESS.md` to track completion:
+
+```markdown
+# Authentication Refactor Progress
+
+- [ ] Part 1: Core module (src/auth/)
+- [ ] Part 2: API routes (src/api/auth/)
+- [ ] Part 3: Middleware (src/middleware/)
+- [ ] Part 4: Models & services (src/models/, src/services/)
+
+## Notes
+- Started: [date]
+- Current part: [1/2/3/4]
+- Issues: [any blockers]
+```
+
+## When to Use @workspace Instead
+
+**Use this decomposed approach when:**
+- You need to MODIFY >10 files
+- Changes are implementation-heavy
+- Files are tightly coupled
+- Need precise control over changes
+
+**Use @workspace when:**
+- You need to SEARCH/ANALYZE many files (read-only)
+- Gathering context about patterns
+- Planning refactor (not implementing yet)
+- Exploring codebase structure
+
+## Alternative: @workspace for Discovery, Prompts for Implementation
+
+**Step 1: Discovery Phase**
+```
+@workspace find all files that import from src/auth/
+```
+
+Use @workspace to understand scope (can reference >10 files for analysis).
+
+**Step 2: Implementation Phase**
+Execute the 4-part prompt sequence to make actual changes (respects 10-file limit).
+
+## Troubleshooting
+
+**If Part N fails:**
+1. Review commit from Part N-1
+2. Ensure previous parts completed successfully
+3. Check test output for specific errors
+4. Fix errors and re-run Part N
+
+**If working set limit hit:**
+- Verify file count in "Working Set" section of prompt
+- Remove non-essential reference files
+- Split part into sub-parts if needed
+
+## Next Steps
+
+1. Review this coordinator prompt to understand full scope
+2. Create `REFACTOR-PROGRESS.md` for tracking
+3. Start with Part 1: `/prompt refactor-auth-core`
+4. Follow the sequence through Part 4
+5. Run final integration tests
+```
+
+### Activation Mechanism
+
+**Skill Chaining:**
+
+Each sub-skill references the next in sequence:
+1. Part 1 → Directs to Part 2
+2. Part 2 → Directs to Part 3
+3. Part 3 → Directs to Part 4
+4. Part 4 → Completion checklist
+
+**Coordinator Pattern:**
+
+The coordinator prompt serves as the entry point and provides:
+- Complete overview
+- Execution order
+- Progress tracking
+- When to use @workspace vs batched prompts
+
+**Manual Invocation:**
+
+User invokes each part sequentially:
+```
+/prompt refactor-auth-coordinator  # Read overview
+/prompt refactor-auth-core          # Part 1
+/prompt refactor-auth-api           # Part 2
+/prompt refactor-auth-middleware    # Part 3
+/prompt refactor-auth-finalize      # Part 4
+```
+
+### Decision Tree: When to Split vs When to Use @workspace
+
+```
+                    Start: Large Operation
+                             |
+                             v
+                    Count affected files
+                             |
+                +-----------+ +------------+
+                |                          |
+                v                          v
+            ≤10 files                  >10 files
+                |                          |
+                v                          v
+        Use single prompt          Is operation read-only
+        with all files             (analysis/search)?
+                                           |
+                                +----------+-----------+
+                                |                      |
+                                v                      v
+                            Yes (read-only)        No (write/modify)
+                                |                      |
+                                v                      v
+                        Use @workspace          Can be logically split?
+                        for discovery                  |
+                        (no 10-file limit)  +----------+-----------+
+                                            |                      |
+                                            v                      v
+                                        Yes (logical splits)   No (tightly coupled)
+                                            |                      |
+                                            v                      v
+                                    Decompose into           File Prioritization:
+                                    sub-skills               1. Keep core files (most-referenced)
+                                    (Pattern 3)              2. Rotate peripheral files
+                                                             3. Process in passes
+                                                             4. May exceed 10-file limit
+                                                                (quality degradation risk)
+```
+
+**Decision Criteria:**
+
+1. **Use Single Prompt (≤10 files):**
+   - Operation affects 10 or fewer files
+   - All files can fit in working set
+   - Example: Refactor single module
+
+2. **Use @workspace (Read-Only, Any Size):**
+   - Discovery and analysis phase
+   - Searching across many files
+   - Planning refactor scope
+   - Understanding dependencies
+   - Example: "Find all usages of deprecated API"
+
+3. **Use Decomposition (>10 files, Logical Splits):**
+   - Operation affects >10 files
+   - Can be divided by module, feature, or layer
+   - Each part can be independent or sequential
+   - Example: Refactor authentication (25 files across modules)
+
+4. **Use File Prioritization (>10 files, Tightly Coupled):**
+   - Operation affects >10 files that must be modified together
+   - Cannot easily split into independent batches
+   - Keep most-referenced files in working set, rotate others
+   - **Risk:** Quality degradation, may not work well
+   - Example: Rename a core interface used in 30 files
+
+### File Prioritization Heuristics
+
+When you MUST work with >10 tightly coupled files, prioritize as follows:
+
+**Priority 1: Core/Root Files (Always in Working Set)**
+- Root type definitions (interfaces, types)
+- Base classes or services
+- Files most frequently imported by others
+- Configuration files that affect all modules
+
+**Priority 2: Direct Dependents (Rotate in Working Set)**
+- Files that directly import from core files
+- Process in groups of 3-5 at a time
+- Keep core files + batch of dependents ≤10 total
+
+**Priority 3: Peripheral Files (Process Last)**
+- Files that import from direct dependents
+- Utility files with minimal cross-references
+- Test files (can often be batch-updated separately)
+
+**Heuristic Algorithm:**
+
+```
+1. Identify core files (≤3 files):
+   - Run: grep -r "import.*from.*{core-file}" src/
+   - Files with most imports = core files
+
+2. Calculate working set:
+   - Core files (3) + Batch of dependents (7) = 10 total
+
+3. Execute in passes:
+   - Pass 1: Core files + Batch 1 dependents (10 files)
+   - Pass 2: Core files + Batch 2 dependents (10 files)
+   - Pass 3: Core files + Batch 3 dependents (10 files)
+   - ...continue until all dependents processed
+
+4. Final pass:
+   - Core files + Peripheral files (verify consistency)
+```
+
+**Example:**
+
+Refactoring `user-types.ts` (core) used by 30 files:
+
+**Working Set Pass 1:**
+1. user-types.ts (core)
+2. user-service.ts (direct dependent)
+3. user-repository.ts (direct dependent)
+4. user-controller.ts (direct dependent)
+5. user-validator.ts (direct dependent)
+6. user-transformer.ts (direct dependent)
+7. auth-service.ts (uses user-types)
+8. profile-service.ts (uses user-types)
+9. admin-controller.ts (uses user-types)
+10. user-dto.ts (direct dependent)
+
+**Working Set Pass 2:**
+1. user-types.ts (core - keep in all passes)
+2. api-user-routes.ts (dependent)
+3. api-profile-routes.ts (dependent)
+4. middleware-user-auth.ts (dependent)
+5. ...continue with next batch
+
+### Known Limitations
+
+1. **Decomposition Overhead:**
+   - Requires manual splitting of large skills
+   - Developer must understand logical boundaries
+   - More prompts to maintain (coordinator + N sub-prompts)
+   - Risk of inconsistency across batches
+
+2. **Coordination Complexity:**
+   - User must manually execute prompts in sequence
+   - No automatic orchestration between batches
+   - Progress tracking is manual (PROGRESS.md file)
+   - Easy to lose context between batches
+
+3. **Not True Parallelization:**
+   - Batches must be sequential (dependencies between parts)
+   - Cannot process batches in parallel
+   - Each batch requires manual checkpoint (commit)
+   - Total time longer than if 10-file limit didn't exist
+
+4. **File Prioritization Risks:**
+   - Quality degradation when >10 tightly coupled files
+   - May miss cross-file dependencies in rotated-out files
+   - Copilot context limited even with prioritization
+   - Not reliable for complex refactors (use decomposition instead)
+
+5. **@workspace Limitations:**
+   - Good for discovery, but cannot make changes to >10 files
+   - Must transition to batched prompts for implementation
+   - Context switching between discovery and implementation phases
+   - @workspace results may exceed Copilot's ability to act on findings
+
+6. **No Enforcement:**
+   - Decomposition pattern is manual (developer-driven)
+   - No system to enforce batch boundaries
+   - Developer can attempt >10 files and hit quality issues
+   - Requires discipline to follow pattern
+
+### Manual Traceability
+
+**Execution Flow: How GitHub Copilot Processes Decomposed Skill**
+
+1. **User Action:** User says "refactor the authentication system"
+
+2. **AI Suggestion:** GitHub Copilot AI:
+   - Recognizes this is a large operation (>10 files)
+   - May suggest: "This affects many files. Use `/prompt refactor-auth-coordinator` to see the batched approach."
+
+3. **User Reads Coordinator:** User types: `/prompt refactor-auth-coordinator`
+
+4. **Coordinator Loaded:** GitHub Copilot:
+   - Loads `.github/prompts/refactor-auth-coordinator.prompt.md`
+   - Displays overview showing 4-part decomposition
+   - Shows execution order and progress tracking guidance
+   - User understands the batched approach
+
+5. **User Starts Part 1:** User types: `/prompt refactor-auth-core`
+
+6. **Part 1 Execution:** GitHub Copilot:
+   - Loads `.github/prompts/refactor-auth-core.prompt.md`
+   - Reads working set: 8 files in src/auth/
+   - Opens files in working set (≤10 file limit)
+   - Analyzes files for duplicate logic
+   - Standardizes patterns across 8 files
+   - Proposes changes
+
+7. **User Reviews and Applies:** User:
+   - Reviews proposed changes
+   - Applies changes
+   - Runs tests: `npm test src/auth/`
+   - Creates checkpoint commit
+
+8. **User Continues to Part 2:** User types: `/prompt refactor-auth-api`
+
+9. **Part 2 Execution:** GitHub Copilot:
+   - Loads `.github/prompts/refactor-auth-api.prompt.md`
+   - Reads working set: 6 API files + 1 reference file (7 total)
+   - Opens files in working set
+   - Updates API routes to use refactored core from Part 1
+   - Proposes changes
+
+10. **Repeat for Parts 3 and 4:**
+    - Part 3: Middleware (4 files)
+    - Part 4: Models & services (9 files)
+    - Each part creates checkpoint commit
+
+11. **Completion:** After Part 4:
+    - User runs full test suite
+    - Verifies all 25 files refactored successfully
+    - Reviews 4 checkpoint commits
+    - Marks REFACTOR-PROGRESS.md as complete
+
+**Verification Points:**
+
+- **Before:** `.github/prompts/refactor-auth-*.prompt.md` files exist (5 files)
+- **During Part 1:** AI works with exactly 8 files from src/auth/
+- **During Part 2:** AI works with exactly 7 files (6 API + 1 reference)
+- **During Part 3:** AI works with exactly 4 files (3 middleware + 1 reference)
+- **During Part 4:** AI works with exactly 9 files (8 models/services + 1 reference)
+- **After Each Part:** Checkpoint commit created, tests pass
+- **After Part 4:** All 25 files refactored, full test suite passes
+
+**Debugging:**
+
+If decomposition doesn't work as expected:
+
+1. **File count exceeds 10 in a part:**
+   - Review working set in that part's prompt
+   - Remove non-essential reference files
+   - Split part into sub-parts (Part 2A, Part 2B)
+
+2. **Cross-part dependencies break:**
+   - Check that earlier parts completed successfully
+   - Review checkpoint commits
+   - Ensure reference files (auth-types.ts) in working sets where needed
+
+3. **Quality degradation even with ≤10 files:**
+   - Files may be too large (>782 lines)
+   - Consider decomposing large files first
+   - Use file prioritization within the part
+
+4. **Coordination overhead too high:**
+   - Consider if @workspace + manual implementation is faster
+   - Evaluate if refactor can be simplified
+   - Check if Claude Code or Windsurf would be better suited
+
+---
+
+## Pattern Summary Table
+
+| Pattern Name | Platform | Gap Addressed | Emulation Approach | Key Limitations |
+|--------------|----------|---------------|-------------------|-----------------|
+| **Skill Emulation** | Windsurf | No skills/subagents (GAP-W1) | Workflows + Model Decision + Persona Rules | No true isolation, no permission enforcement, manual agent activation |
+| **Workflow Emulation** | Claude Code | No AI-driven activation, no automatic multi-file context (GAP-C1) | Rich descriptions + Explicit context gathering (Step 0) | Manual invocation required, sequential context loading, no model decision engine |
+| **Working Set Limitation** | GitHub Copilot | 10-file working set limit, 20-file context limit (GAP-GH1) | Skill decomposition + Batch processing + File prioritization + Skill chaining + @workspace for discovery | Manual decomposition overhead, sequential-only batches, coordination complexity, no enforcement |
+
+---
+
+## Cross-References
+
+- **GAP-ANALYSIS.md** - Gap #W1 (Subagent Spawning), Gap #GH1 (Working Set Limitations), Gap #C1 (AI-Driven Activation)
+- **PLATFORM-ADAPTERS.md** - Section 2.2 (Windsurf Emulation Patterns), Section 3.2 (GitHub Copilot Emulation Patterns), Section 4.1 (Claude Code Adapter)
+- **STANDARD-SCHEMA.md** - Skill field definitions
+- **STANDARD-STRUCTURE.md** - Workflow file organization
+- **examples/workflow-example.md** - Complete working example of workflow emulation
+- **examples/copilot-limited-context.md** - Complete working example of working set limitation pattern
+
+---
+
+## Sources
+
+- RESEARCH-windsurf.md (Windsurf workflow capabilities, model decision triggers, multi-file context)
+- RESEARCH-claude-code.md (Claude Code skill system, manual invocation)
+- RESEARCH-github-copilot.md (GitHub Copilot working set limits, context constraints, @workspace capabilities)
+- GAP-ANALYSIS.md (Capability gaps)
+- PLATFORM-ADAPTERS.md (Transformation rules, Claude Code adapter, GitHub Copilot adapter)
diff --git a/examples/copilot-limited-context.md b/examples/copilot-limited-context.md
new file mode 100644
index 0000000..2776039
--- /dev/null
+++ b/examples/copilot-limited-context.md
@@ -0,0 +1,1152 @@
+# Example: GitHub Copilot Working Set Limitation Pattern
+
+**Date:** 2026-01-12
+**Pattern:** Working Set Limitation Pattern (Pattern 3)
+**Purpose:** Demonstrate skill decomposition for GitHub Copilot's 10-file working set limit
+
+---
+
+## Scenario
+
+You need to refactor the database access layer across your application. The refactor affects 28 files:
+
+- `src/database/connection.ts` (core)
+- `src/database/query-builder.ts` (core)
+- `src/database/transaction.ts` (core)
+- `src/repositories/user-repository.ts`
+- `src/repositories/product-repository.ts`
+- `src/repositories/order-repository.ts`
+- `src/repositories/payment-repository.ts`
+- `src/repositories/inventory-repository.ts`
+- `src/repositories/customer-repository.ts`
+- `src/repositories/vendor-repository.ts`
+- `src/repositories/audit-repository.ts`
+- `src/services/user-service.ts`
+- `src/services/product-service.ts`
+- `src/services/order-service.ts`
+- `src/services/payment-service.ts`
+- `src/services/inventory-service.ts`
+- `src/services/analytics-service.ts`
+- `src/api/controllers/user-controller.ts`
+- `src/api/controllers/product-controller.ts`
+- `src/api/controllers/order-controller.ts`
+- `src/api/controllers/payment-controller.ts`
+- `src/api/controllers/inventory-controller.ts`
+- `src/models/user-model.ts`
+- `src/models/product-model.ts`
+- `src/models/order-model.ts`
+- `src/models/payment-model.ts`
+- `src/models/inventory-model.ts`
+- `src/types/database-types.ts` (shared types)
+
+**Total:** 28 files
+
+**Problem:** GitHub Copilot's 10-file working set limit makes this impossible to handle in a single prompt.
+
+**Solution:** Apply Working Set Limitation Pattern to decompose into 4 batched sub-skills.
+
+---
+
+## Step 1: Apply Decision Tree
+
+### Question 1: Count affected files
+**Answer:** 28 files
+
+### Question 2: Exceeds 10-file limit?
+**Answer:** Yes (28 > 10)
+
+### Question 3: Is operation read-only (analysis/search)?
+**Answer:** No, this is a write-heavy refactor (modifying database access patterns)
+
+### Question 4: Can be logically split?
+**Answer:** Yes, can split by layer:
+- Part 1: Core database module (3 files)
+- Part 2: Repository layer (8 files)
+- Part 3: Service layer (6 files)
+- Part 4: API controllers + Models (11 files)
+
+**Decision:** Use skill decomposition pattern
+
+---
+
+## Step 2: Decompose Into Sub-Skills
+
+### Original Monolithic Skill (Won't Work on Copilot)
+
+**File:** `.github/prompts/refactor-database.prompt.md` (NOT SUITABLE)
+
+```yaml
+---
+description: Refactor database access layer across entire application
+applyTo:
+  - "src/database/**/*.ts"
+  - "src/repositories/**/*.ts"
+  - "src/services/**/*.ts"
+  - "src/api/controllers/**/*.ts"
+  - "src/models/**/*.ts"
+mode: agent
+---
+
+# Database Layer Refactor
+
+## Scope
+Refactor database access across 28 files to:
+- Migrate from raw SQL to query builder
+- Standardize transaction handling
+- Add connection pooling
+- Implement retry logic
+
+## Files Affected
+- src/database/ (3 files)
+- src/repositories/ (8 files)
+- src/services/ (6 files)
+- src/api/controllers/ (5 files)
+- src/models/ (5 files)
+- src/types/ (1 file)
+
+## Tasks
+1. Update core database module with query builder
+2. Refactor all repositories to use query builder
+3. Update services to use new repository methods
+4. Update API controllers to use new service methods
+5. Update models to reflect new database schema
+```
+
+**Problem:** 28 files far exceeds Copilot's 10-file limit. This will fail or produce poor results.
+
+---
+
+### Decomposed Skills (Works Within Copilot Limits)
+
+#### Part 1: Core Database Module
+
+**File:** `.github/prompts/refactor-database-core.prompt.md`
+
+```yaml
+---
+description: Refactor core database module (Part 1 of 4)
+applyTo:
+  - "src/database/*.ts"
+  - "src/types/database-types.ts"
+mode: agent
+---
+
+# Database Refactor - Part 1: Core Module
+
+<!-- Part 1 of 4: Core Database Infrastructure -->
+<!-- Version: 1.0.0 -->
+
+## Scope
+
+**This prompt handles:** Core database infrastructure (3 files) + shared types (1 file)
+
+**Working Set (4 files):**
+1. src/database/connection.ts
+2. src/database/query-builder.ts
+3. src/database/transaction.ts
+4. src/types/database-types.ts (shared types - keep as reference)
+
+**Why these files:**
+- Core files that all other layers depend on
+- Must be refactored first to establish new patterns
+- Types needed as reference for interface consistency
+
+## Objectives
+
+1. Migrate from raw SQL strings to query builder API
+2. Implement connection pooling
+3. Add transaction retry logic
+4. Standardize error handling
+
+## Workflow
+
+### Step 1: Update Query Builder
+
+Refactor `src/database/query-builder.ts`:
+- Replace SQL template strings with query builder methods
+- Add type-safe query construction
+- Implement parameter sanitization
+
+**Example Pattern:**
+
+```typescript
+// OLD (raw SQL):
+const result = await db.query(
+  'SELECT * FROM users WHERE email = $1',
+  [email]
+);
+
+// NEW (query builder):
+const result = await db
+  .select('*')
+  .from('users')
+  .where('email', '=', email)
+  .execute();
+```
+
+### Step 2: Update Connection Management
+
+Refactor `src/database/connection.ts`:
+- Implement connection pooling (max 20 connections)
+- Add connection health checks
+- Implement graceful shutdown
+
+### Step 3: Update Transaction Handling
+
+Refactor `src/database/transaction.ts`:
+- Add automatic retry logic (max 3 retries)
+- Implement deadlock detection
+- Add transaction timeout (30 seconds)
+
+### Step 4: Update Shared Types
+
+Update `src/types/database-types.ts`:
+- Add query builder result types
+- Add connection pool types
+- Add transaction types
+
+### Step 5: Verify Core Module
+
+Test the core module:
+```bash
+npm test src/database/
+```
+
+### Step 6: Checkpoint
+
+Create commit:
+```
+refactor(db): part 1 - migrate core module to query builder with pooling
+```
+
+## Next Steps
+
+After completing this part:
+1. Ensure all core database tests pass
+2. Review new query builder API for repositories
+3. Proceed to Part 2: `/prompt refactor-database-repositories`
+
+## Related Files (Not Modified Here)
+
+Dependencies on core module (handled in later parts):
+- src/repositories/*.ts (Part 2 - will use new query builder)
+- src/services/*.ts (Part 3 - indirect dependency)
+- src/api/controllers/*.ts (Part 4 - indirect dependency)
+- src/models/*.ts (Part 4 - may need updates)
+```
+
+---
+
+#### Part 2: Repository Layer
+
+**File:** `.github/prompts/refactor-database-repositories.prompt.md`
+
+```yaml
+---
+description: Refactor repository layer to use new query builder (Part 2 of 4)
+applyTo:
+  - "src/repositories/*.ts"
+  - "src/database/query-builder.ts"
+mode: agent
+---
+
+# Database Refactor - Part 2: Repository Layer
+
+<!-- Part 2 of 4: Repository Refactoring -->
+<!-- Version: 1.0.0 -->
+
+## Prerequisites
+
+**IMPORTANT:** Complete Part 1 (`refactor-database-core`) before starting this part.
+
+Part 1 should have:
+- Migrated core database module to query builder
+- Implemented connection pooling
+- Added transaction retry logic
+- Updated shared database types
+
+## Scope
+
+**This prompt handles:** All repositories (8 files) + query builder reference (1 file)
+
+**Working Set (9 files):**
+1. src/repositories/user-repository.ts
+2. src/repositories/product-repository.ts
+3. src/repositories/order-repository.ts
+4. src/repositories/payment-repository.ts
+5. src/repositories/inventory-repository.ts
+6. src/repositories/customer-repository.ts
+7. src/repositories/vendor-repository.ts
+8. src/repositories/audit-repository.ts
+9. src/database/query-builder.ts (reference - new API)
+
+**Rationale:** Keep query-builder.ts in working set as reference for correct API usage.
+
+## Objectives
+
+1. Refactor all repository methods to use query builder instead of raw SQL
+2. Standardize error handling across repositories
+3. Add transaction support to multi-step operations
+4. Ensure repository interfaces remain unchanged (backward compatibility)
+
+## Workflow
+
+### Step 1: Review Query Builder API
+
+Read `src/database/query-builder.ts` to understand new API from Part 1.
+
+**Key Methods:**
+- `.select()`, `.from()`, `.where()`, `.join()`
+- `.insert()`, `.update()`, `.delete()`
+- `.transaction()`, `.execute()`
+
+### Step 2: Refactor User Repository
+
+Update `src/repositories/user-repository.ts`:
+
+**Example Migration:**
+
+```typescript
+// OLD (raw SQL):
+async findByEmail(email: string): Promise<User | null> {
+  const result = await db.query(
+    'SELECT * FROM users WHERE email = $1',
+    [email]
+  );
+  return result.rows[0] || null;
+}
+
+// NEW (query builder):
+async findByEmail(email: string): Promise<User | null> {
+  const result = await this.db
+    .select('*')
+    .from('users')
+    .where('email', '=', email)
+    .execute();
+  return result[0] || null;
+}
+```
+
+### Step 3: Refactor Remaining Repositories
+
+Apply same pattern to:
+- product-repository.ts
+- order-repository.ts
+- payment-repository.ts
+- inventory-repository.ts
+- customer-repository.ts
+- vendor-repository.ts
+- audit-repository.ts
+
+### Step 4: Add Transaction Support
+
+For repositories with multi-step operations, add transaction support:
+
+```typescript
+async createOrderWithItems(order: Order, items: OrderItem[]): Promise<Order> {
+  return await this.db.transaction(async (tx) => {
+    const createdOrder = await tx
+      .insert(order)
+      .into('orders')
+      .returning('*')
+      .execute();
+
+    await tx
+      .insert(items)
+      .into('order_items')
+      .execute();
+
+    return createdOrder;
+  });
+}
+```
+
+### Step 5: Verify Repository Tests
+
+Run repository tests:
+```bash
+npm test src/repositories/
+```
+
+Ensure:
+- All repository methods work correctly
+- Interfaces unchanged (no breaking changes)
+- Transactions commit/rollback properly
+
+### Step 6: Checkpoint
+
+Create commit:
+```
+refactor(db): part 2 - migrate repositories to query builder
+```
+
+## Next Steps
+
+After completing this part:
+1. Ensure all repository tests pass
+2. Verify no breaking changes to repository interfaces
+3. Proceed to Part 3: `/prompt refactor-database-services`
+
+## Related Files (Not Modified Here)
+
+Consumers of repositories (handled in later parts):
+- src/services/*.ts (Part 3 - uses repositories, should still work)
+- src/api/controllers/*.ts (Part 4 - indirect consumers)
+```
+
+---
+
+#### Part 3: Service Layer
+
+**File:** `.github/prompts/refactor-database-services.prompt.md`
+
+```yaml
+---
+description: Update service layer for new database patterns (Part 3 of 4)
+applyTo:
+  - "src/services/*.ts"
+  - "src/repositories/user-repository.ts"
+mode: agent
+---
+
+# Database Refactor - Part 3: Service Layer
+
+<!-- Part 3 of 4: Service Layer Updates -->
+<!-- Version: 1.0.0 -->
+
+## Prerequisites
+
+**IMPORTANT:** Complete Parts 1 and 2 before starting this part.
+
+Previous parts should have:
+- Part 1: Core database module with query builder
+- Part 2: Repositories refactored to use query builder
+
+## Scope
+
+**This prompt handles:** Service layer (6 files) + repository reference (1 file)
+
+**Working Set (7 files):**
+1. src/services/user-service.ts
+2. src/services/product-service.ts
+3. src/services/order-service.ts
+4. src/services/payment-service.ts
+5. src/services/inventory-service.ts
+6. src/services/analytics-service.ts
+7. src/repositories/user-repository.ts (reference - example of new patterns)
+
+**Rationale:** Services use repositories. While repository interfaces unchanged, may need to handle new error types or transaction patterns.
+
+## Objectives
+
+1. Update services to handle new database error types
+2. Optimize service methods to leverage query builder features (e.g., joins)
+3. Add transaction coordination across multiple repositories
+4. Ensure service interfaces remain unchanged (backward compatibility)
+
+## Workflow
+
+### Step 1: Review Repository Changes
+
+Read `src/repositories/user-repository.ts` to understand new patterns from Part 2.
+
+**Key Changes:**
+- Repositories now return typed results from query builder
+- New transaction support for multi-step operations
+- Standardized error handling
+
+### Step 2: Update Error Handling
+
+Update service error handling for new database errors:
+
+```typescript
+// Services now handle query builder errors
+try {
+  const user = await this.userRepository.findById(userId);
+} catch (error) {
+  if (error instanceof QueryBuilderError) {
+    // Handle query builder specific errors
+    throw new ServiceError('Database query failed', error);
+  }
+  throw error;
+}
+```
+
+### Step 3: Optimize Service Methods
+
+Leverage query builder features for complex operations:
+
+```typescript
+// OLD (N+1 query problem):
+async getOrdersWithCustomers() {
+  const orders = await orderRepository.findAll();
+  for (const order of orders) {
+    order.customer = await customerRepository.findById(order.customerId);
+  }
+  return orders;
+}
+
+// NEW (single query with join):
+async getOrdersWithCustomers() {
+  // Repository now supports joins via query builder
+  return await orderRepository.findAllWithCustomers();
+}
+```
+
+### Step 4: Add Cross-Repository Transactions
+
+For services coordinating multiple repositories, use transactions:
+
+```typescript
+async placeOrder(userId: string, items: CartItem[]): Promise<Order> {
+  return await this.db.transaction(async (tx) => {
+    // Deduct inventory
+    await this.inventoryRepository.deductStock(items, tx);
+
+    // Create order
+    const order = await this.orderRepository.create(userId, items, tx);
+
+    // Process payment
+    await this.paymentRepository.charge(order.total, tx);
+
+    return order;
+  });
+}
+```
+
+### Step 5: Update Remaining Services
+
+Apply optimizations to:
+- product-service.ts
+- payment-service.ts
+- inventory-service.ts
+- analytics-service.ts
+
+### Step 6: Verify Service Tests
+
+Run service tests:
+```bash
+npm test src/services/
+```
+
+Ensure:
+- Services still work correctly
+- No breaking changes to service interfaces
+- Transactions commit/rollback properly
+
+### Step 7: Checkpoint
+
+Create commit:
+```
+refactor(db): part 3 - update services for new database patterns
+```
+
+## Next Steps
+
+After completing this part:
+1. Ensure all service tests pass
+2. Verify service interfaces unchanged
+3. Proceed to Part 4: `/prompt refactor-database-finalize`
+
+## Related Files (Not Modified Here)
+
+Consumers of services (handled in Part 4):
+- src/api/controllers/*.ts (Part 4 - uses services)
+- src/models/*.ts (Part 4 - may need minor updates)
+```
+
+---
+
+#### Part 4: API Controllers and Models
+
+**File:** `.github/prompts/refactor-database-finalize.prompt.md`
+
+```yaml
+---
+description: Finalize database refactor - update controllers and models (Part 4 of 4)
+applyTo:
+  - "src/api/controllers/*.ts"
+  - "src/models/*.ts"
+  - "src/types/database-types.ts"
+mode: agent
+---
+
+# Database Refactor - Part 4: Finalization
+
+<!-- Part 4 of 4: Controllers, Models, and Final Verification -->
+<!-- Version: 1.0.0 -->
+
+## Prerequisites
+
+**IMPORTANT:** Complete Parts 1, 2, and 3 before starting this part.
+
+Previous parts should have:
+- Part 1: Core database module with query builder
+- Part 2: Repositories refactored
+- Part 3: Services updated
+
+## Scope
+
+**This prompt handles:** API controllers (5 files) + Models (5 files) + Types (1 file)
+
+**Working Set (11 files):**
+
+**NOTICE:** This exceeds the ideal 10-file limit, but these files are loosely coupled enough that quality should remain acceptable. If quality issues occur, split into Part 4A (controllers) and Part 4B (models).
+
+1. src/api/controllers/user-controller.ts
+2. src/api/controllers/product-controller.ts
+3. src/api/controllers/order-controller.ts
+4. src/api/controllers/payment-controller.ts
+5. src/api/controllers/inventory-controller.ts
+6. src/models/user-model.ts
+7. src/models/product-model.ts
+8. src/models/order-model.ts
+9. src/models/payment-model.ts
+10. src/models/inventory-model.ts
+11. src/types/database-types.ts (reference - ensure consistency)
+
+## Objectives
+
+1. Update controllers to handle new service error types
+2. Update models to reflect new database schema (if changed)
+3. Verify end-to-end functionality
+4. Run full test suite and integration tests
+5. Document breaking changes (if any)
+
+## Workflow
+
+### Step 1: Update API Controllers
+
+Controllers are mostly unaffected (services maintain interfaces), but may need error handling updates:
+
+```typescript
+// Update error responses for new database errors
+app.get('/users/:id', async (req, res) => {
+  try {
+    const user = await userService.findById(req.params.id);
+    res.json(user);
+  } catch (error) {
+    if (error instanceof ServiceError && error.cause instanceof QueryBuilderError) {
+      // Handle database-specific errors
+      res.status(500).json({ error: 'Database error', details: error.message });
+    } else {
+      res.status(500).json({ error: 'Internal server error' });
+    }
+  }
+});
+```
+
+### Step 2: Update Models (If Needed)
+
+If database schema changed during refactor, update models:
+
+```typescript
+// Example: Add new field if schema changed
+interface User {
+  id: string;
+  email: string;
+  createdAt: Date;
+  updatedAt: Date;
+  // NEW: If added during refactor
+  lastLoginAt?: Date;
+}
+```
+
+### Step 3: Update Database Types
+
+Review `src/types/database-types.ts` for any final type updates needed.
+
+### Step 4: System-Wide Verification
+
+Run comprehensive test suite:
+
+```bash
+# Unit tests
+npm test
+
+# Integration tests
+npm run test:integration
+
+# E2E tests (if available)
+npm run test:e2e
+```
+
+### Step 5: Manual Testing
+
+Test critical flows manually:
+1. User registration and login
+2. Product catalog browsing
+3. Order creation and payment
+4. Inventory updates
+
+### Step 6: Final Checkpoint
+
+Create commit:
+```
+refactor(db): part 4 - finalize controllers and models, verify system integrity
+```
+
+## Completion Checklist
+
+- [ ] All 28 files refactored across 4 parts
+- [ ] Core database module uses query builder (Part 1)
+- [ ] Repositories use query builder (Part 2)
+- [ ] Services optimized and use transactions (Part 3)
+- [ ] Controllers and models updated (Part 4)
+- [ ] Full test suite passes
+- [ ] Integration tests pass
+- [ ] No breaking API changes (or documented)
+- [ ] Performance improved (benchmark if needed)
+
+## Rollback Plan
+
+If critical issues discovered:
+
+1. **Identify problematic part:**
+   - Review commits from all 4 parts
+   - Check test failures for clues
+   - Identify which layer has issues
+
+2. **Rollback specific part:**
+   ```bash
+   git log --oneline  # Find commit hash
+   git revert <commit-hash>
+   ```
+
+3. **Fix and re-run:**
+   - Fix issues in that part
+   - Re-run the prompt for that part
+   - Verify tests pass
+   - Continue from there
+
+## Performance Verification
+
+**Optional:** Benchmark database performance improvements:
+
+```bash
+# Run before/after benchmarks
+npm run benchmark:database
+```
+
+Expected improvements:
+- Connection pooling: 30-50% faster under load
+- Query builder: Similar or better performance vs raw SQL
+- Transaction retry: Reduced deadlock failures
+
+## Summary
+
+This completes the 4-part database refactor:
+- **Part 1:** Core module (4 files)
+- **Part 2:** Repositories (9 files)
+- **Part 3:** Services (7 files)
+- **Part 4:** Controllers & models (11 files)
+- **Total:** 28 files refactored within Copilot's constraints
+
+**Key Achievements:**
+- Migrated to query builder (type-safe queries)
+- Added connection pooling (better performance)
+- Implemented transaction retry logic (improved reliability)
+- Maintained backward compatibility (no breaking API changes)
+
+## Next Steps (Optional)
+
+**Future Enhancements:**
+- Add query caching layer
+- Implement read replicas for scaling
+- Add database monitoring and alerting
+- Optimize slow queries identified in benchmarks
+```
+
+---
+
+#### Coordinator Prompt
+
+**File:** `.github/prompts/refactor-database-coordinator.prompt.md`
+
+```yaml
+---
+description: Coordinate full database refactor (use this as entry point)
+mode: agent
+---
+
+# Database Refactor - Coordinator
+
+<!-- Master prompt for orchestrating the 4-part refactor -->
+<!-- Version: 1.0.0 -->
+
+## Overview
+
+This database refactor has been decomposed into 4 sequential parts to work within GitHub Copilot's 10-file working set limit.
+
+**Original Scope:** 28 files across database, repository, service, controller, and model layers
+**Copilot Limit:** 10 files per working set
+**Solution:** 4 batched sub-tasks, each ≤11 files (Part 4 slightly exceeds but should work)
+
+## Why Decomposition Was Necessary
+
+**Challenge:** Copilot cannot effectively refactor >10 files simultaneously
+**Risk Without Decomposition:** Quality degradation, missed dependencies, incomplete refactors
+
+**Solution Benefits:**
+- Each part stays within working set limits
+- Clear dependency chain (Part 1 → 2 → 3 → 4)
+- Checkpoint commits allow rollback
+- Easier to review and test incrementally
+
+## Execution Order
+
+Execute prompts in this order:
+
+### Part 1: Core Database Module
+**Prompt:** `/prompt refactor-database-core`
+**Files:** 4 files (database core + types)
+**Duration:** ~15-20 minutes
+**Checkpoint:** Commit after completion
+**Tests:** `npm test src/database/`
+
+### Part 2: Repository Layer
+**Prompt:** `/prompt refactor-database-repositories`
+**Files:** 9 files (8 repositories + query builder reference)
+**Duration:** ~25-30 minutes
+**Checkpoint:** Commit after completion
+**Tests:** `npm test src/repositories/`
+
+### Part 3: Service Layer
+**Prompt:** `/prompt refactor-database-services`
+**Files:** 7 files (6 services + repository reference)
+**Duration:** ~20-25 minutes
+**Checkpoint:** Commit after completion
+**Tests:** `npm test src/services/`
+
+### Part 4: Controllers and Models
+**Prompt:** `/prompt refactor-database-finalize`
+**Files:** 11 files (5 controllers + 5 models + types)
+**Duration:** ~20-25 minutes
+**Checkpoint:** Final commit
+**Tests:** `npm test` (full suite)
+
+## Total Estimated Time
+
+Approximately 80-100 minutes for complete refactor.
+
+## Progress Tracking
+
+Create `REFACTOR-PROGRESS.md` to track completion:
+
+```markdown
+# Database Refactor Progress
+
+## Status
+- [ ] Part 1: Core database module (4 files)
+- [ ] Part 2: Repository layer (9 files)
+- [ ] Part 3: Service layer (7 files)
+- [ ] Part 4: Controllers & models (11 files)
+
+## Checkpoint Commits
+- Part 1: [commit hash]
+- Part 2: [commit hash]
+- Part 3: [commit hash]
+- Part 4: [commit hash]
+
+## Test Results
+- Part 1 tests: [pass/fail]
+- Part 2 tests: [pass/fail]
+- Part 3 tests: [pass/fail]
+- Part 4 tests: [pass/fail]
+
+## Notes
+- Started: [date]
+- Current part: [1/2/3/4]
+- Issues: [any blockers or decisions made]
+```
+
+## When to Use @workspace Instead
+
+**Use this decomposed approach when:**
+- You need to MODIFY files (write operations)
+- Changes are implementation-heavy
+- Files are tightly coupled and must be coordinated
+- Need precise control over changes
+
+**Use @workspace when:**
+- You need to SEARCH/ANALYZE many files (read-only)
+- Planning the refactor scope
+- Understanding current patterns and dependencies
+- Generating migration documentation
+
+**Recommended Workflow:**
+
+1. **Discovery Phase (Use @workspace):**
+   ```
+   @workspace analyze database access patterns across the codebase
+   @workspace find all files that import from src/database/
+   @workspace show examples of current SQL usage
+   ```
+
+2. **Planning Phase (Use @workspace):**
+   ```
+   @workspace document current database architecture
+   @workspace identify repositories that need refactoring
+   ```
+
+3. **Implementation Phase (Use Decomposed Prompts):**
+   - Execute Part 1: Core module refactor
+   - Execute Part 2: Repository refactor
+   - Execute Part 3: Service refactor
+   - Execute Part 4: Controller & model updates
+
+## Decision Points
+
+### Should You Split Part 4 Further?
+
+Part 4 has 11 files (slightly over 10-file limit).
+
+**Keep as single part IF:**
+- Files are loosely coupled (controllers and models are mostly independent)
+- Quality remains acceptable during execution
+- Test suite passes after Part 4
+
+**Split into Part 4A and 4B IF:**
+- Quality degrades during execution
+- Copilot misses dependencies between controllers and models
+- Test failures indicate incomplete refactor
+
+**If splitting needed:**
+
+**Part 4A: Controllers** (6 files)
+- src/api/controllers/*.ts (5 files)
+- src/types/database-types.ts (1 reference)
+
+**Part 4B: Models** (6 files)
+- src/models/*.ts (5 files)
+- src/types/database-types.ts (1 reference)
+
+## Troubleshooting
+
+### Part N Fails
+
+1. Review commit from Part N-1
+2. Ensure previous parts completed successfully
+3. Check test output for specific errors
+4. Verify file count in working set ≤10
+5. Fix errors and re-run Part N
+
+### Working Set Limit Hit
+
+- Verify "Working Set" section in prompt lists ≤10 files
+- Remove non-essential reference files
+- Split part into sub-parts (4A, 4B)
+
+### Quality Degradation
+
+If Copilot produces poor results:
+- Check if files are too large (>782 lines)
+- Consider decomposing large files first
+- Verify working set count ≤10
+- Try splitting part into smaller batches
+
+### Tests Fail After a Part
+
+1. Review changes in that part's commit
+2. Run tests for just that layer: `npm test src/{layer}/`
+3. Fix failures before proceeding to next part
+4. Re-run tests to confirm fix
+5. Update checkpoint commit if needed
+
+## Alternative Strategies
+
+### Strategy 1: Layer-by-Layer (Current Approach)
+- Part 1: Core
+- Part 2: Repositories
+- Part 3: Services
+- Part 4: Controllers & Models
+
+**Pros:** Clear dependency chain, logical progression
+**Cons:** Must complete all parts sequentially
+
+### Strategy 2: Feature-by-Feature
+- Part 1: User feature (user-repo, user-service, user-controller, user-model)
+- Part 2: Product feature (product-repo, product-service, product-controller, product-model)
+- Part 3: Order feature (order-repo, order-service, order-controller, order-model)
+- Part 4: Payment & Inventory features
+
+**Pros:** Each part delivers complete vertical slice, can test end-to-end per part
+**Cons:** More complex dependency management, core module changes repeated
+
+**When to use Feature-by-Feature:**
+- Features are mostly independent
+- Want to deliver incremental value
+- Can test each feature end-to-end immediately
+
+## Final Checklist
+
+After completing all 4 parts:
+
+- [ ] All 28 files refactored
+- [ ] 4 checkpoint commits created
+- [ ] All unit tests pass (`npm test`)
+- [ ] All integration tests pass (`npm run test:integration`)
+- [ ] No breaking API changes (or documented)
+- [ ] Performance benchmarked (optional)
+- [ ] Documentation updated (if needed)
+- [ ] REFACTOR-PROGRESS.md completed
+
+## Next Steps
+
+1. Review this coordinator prompt to understand full scope
+2. Create `REFACTOR-PROGRESS.md` for tracking
+3. Optional: Use @workspace for discovery phase
+4. Start with Part 1: `/prompt refactor-database-core`
+5. Follow the sequence through Part 4
+6. Run final integration tests
+7. Create final summary commit
+
+## Estimated ROI
+
+**Investment:**
+- Time: 80-100 minutes across 4 parts
+- Effort: Moderate (follow prompts sequentially)
+
+**Return:**
+- Type-safe database queries (fewer runtime errors)
+- Connection pooling (30-50% performance improvement under load)
+- Transaction retry logic (improved reliability)
+- Standardized patterns (easier maintenance)
+- Better developer experience (autocomplete for queries)
+```
+
+---
+
+## Step 3: When to Use @workspace vs Decomposition
+
+### Use @workspace for Discovery
+
+**Scenario:** You want to understand the current state before refactoring.
+
+**Example:**
+
+```
+@workspace analyze how database connections are currently managed
+@workspace find all SQL queries in the codebase
+@workspace show examples of transaction usage patterns
+@workspace list all files that import from src/database/
+```
+
+**Benefits:**
+- Can analyze >10 files (no working set limit for read-only)
+- Get high-level overview
+- Understand scope before decomposing
+- Identify patterns and anti-patterns
+
+**Limitations:**
+- Read-only (cannot make changes)
+- Must transition to decomposed prompts for implementation
+
+### Use Decomposition for Implementation
+
+**Scenario:** You need to actually refactor the 28 files.
+
+**Example:**
+
+After using @workspace to understand scope, execute:
+
+```
+/prompt refactor-database-coordinator  # Read overview
+/prompt refactor-database-core         # Part 1 (4 files)
+/prompt refactor-database-repositories # Part 2 (9 files)
+/prompt refactor-database-services     # Part 3 (7 files)
+/prompt refactor-database-finalize     # Part 4 (11 files)
+```
+
+**Benefits:**
+- Can modify files (write operations)
+- Stays within working set limits
+- Clear checkpoints (commits per part)
+- Easier to review and test incrementally
+
+**Limitations:**
+- Manual orchestration required
+- Takes longer than monolithic approach would (if it worked)
+- Must maintain context across parts
+
+---
+
+## Step 4: File Prioritization Example
+
+**Scenario:** Part 4 has 11 files (over the 10-file limit), but they're loosely coupled enough that quality might be acceptable.
+
+**If Quality Degrades:** Apply file prioritization heuristic.
+
+### Prioritization Algorithm
+
+**Priority 1: Core/Root Files (Always in Working Set)**
+- `src/types/database-types.ts` (imported by all controllers and models)
+
+**Priority 2: High-Value Files (Rotate in Batches)**
+- Controllers (5 files) - higher priority (API facing)
+- Models (5 files) - lower priority (internal structures)
+
+### Execution with Prioritization
+
+**Pass 1: Controllers + Types**
+
+**Working Set (6 files):**
+1. src/types/database-types.ts (core)
+2. src/api/controllers/user-controller.ts
+3. src/api/controllers/product-controller.ts
+4. src/api/controllers/order-controller.ts
+5. src/api/controllers/payment-controller.ts
+6. src/api/controllers/inventory-controller.ts
+
+**Pass 2: Models + Types**
+
+**Working Set (6 files):**
+1. src/types/database-types.ts (core - keep in both passes)
+2. src/models/user-model.ts
+3. src/models/product-model.ts
+4. src/models/order-model.ts
+5. src/models/payment-model.ts
+6. src/models/inventory-model.ts
+
+**Result:** Split Part 4 into Part 4A (controllers) and Part 4B (models), each within 10-file limit.
+
+---
+
+## Verification
+
+### Acceptance Criteria Met
+
+- [x] Working Set Limitation Pattern section added to WORKAROUND-PATTERNS.md
+- [x] Decision tree documented for when to split templates vs use @workspace
+- [x] examples/copilot-limited-context.md shows practical skill decomposition
+- [x] File prioritization heuristics clearly documented
+- [x] Skill chaining pattern explained with code examples
+- [x] Pattern is manually traceable (coordinator → part 1 → part 2 → part 3 → part 4)
+
+### Example Demonstrates
+
+1. **Decomposition Strategy:** 28-file refactor split into 4 parts (4, 9, 7, 11 files)
+2. **Skill Chaining:** Each part references the next in "Next Steps" section
+3. **Coordinator Pattern:** Master prompt orchestrates execution order
+4. **File Prioritization:** Part 4 demonstrates prioritization when approaching limit
+5. **@workspace Guidance:** Clear explanation of when to use @workspace vs decomposed prompts
+6. **Decision Tree Application:** Shows applying decision tree to determine decomposition strategy
+7. **Manual Traceability:** Clear execution flow from coordinator through all 4 parts
+8. **Checkpoint Commits:** Each part creates commit for rollback capability
+9. **Progress Tracking:** REFACTOR-PROGRESS.md for manual tracking
+
+---
+
+## Summary
+
+This example demonstrates the **Working Set Limitation Pattern** for GitHub Copilot:
+
+- **Problem:** 28-file refactor exceeds 10-file working set limit
+- **Solution:** Decompose into 4 sequential parts, each ≤11 files
+- **Coordinator:** Master prompt provides overview and execution guidance
+- **Chaining:** Each part references the next, creating clear progression
+- **Checkpoints:** Commits after each part allow rollback and incremental testing
+- **@workspace Alternative:** Use for discovery, decomposition for implementation
+- **File Prioritization:** Applied when part approaches or exceeds limit
+
+**Key Takeaway:** Large operations on GitHub Copilot require manual decomposition and orchestration, but the pattern provides a systematic approach to work within platform constraints.
diff --git a/examples/skill-example.md b/examples/skill-example.md
new file mode 100644
index 0000000..01851a4
--- /dev/null
+++ b/examples/skill-example.md
@@ -0,0 +1,390 @@
+# Example: Cross-Platform Skill Template
+
+This file demonstrates a skill written in the superset standard format that can be adapted to all three platforms (Claude Code, Windsurf, GitHub Copilot).
+
+---
+
+## Standard Format (Superset)
+
+**File:** `.ai-templates/skills/test-runner/SKILL.md`
+
+```yaml
+---
+# ============================================
+# CORE FIELDS (Universal)
+# ============================================
+name: test-runner
+description: USE WHEN running tests. Executes test suites and analyzes results.
+version: "1.0.0"
+
+# ============================================
+# CLAUDE CODE FIELDS
+# ============================================
+allowed-tools:
+  - Bash(npm test)
+  - Bash(npm run test:*)
+  - Read
+  - Grep
+model: sonnet
+context: inherit
+permissions:
+  allow:
+    - Read(tests/**)
+    - Read(src/**)
+    - Bash(npm test*)
+  deny:
+    - Write(**)
+
+# ============================================
+# WINDSURF FIELDS
+# ============================================
+trigger: model_decision
+globs:
+  - "**/*.test.ts"
+  - "**/*.spec.ts"
+  - "tests/**/*"
+labels:
+  - testing
+  - automation
+  - quality
+
+# ============================================
+# GITHUB COPILOT FIELDS
+# ============================================
+applyTo:
+  - "**/*.test.ts"
+  - "**/*.spec.ts"
+mode: agent
+
+# ============================================
+# CROSS-PLATFORM FIELDS
+# ============================================
+platforms:
+  - claude-code
+  - windsurf
+  - github-copilot
+---
+
+# Test Runner
+
+Execute test suites and provide analysis of results.
+
+## Process
+
+### 1. Identify Tests
+- Scan for test files matching `*.test.ts` or `*.spec.ts`
+- List available test scripts in `package.json`
+- Ask user which tests to run (all, unit, integration, specific)
+
+### 2. Execute Tests
+- Run selected test command
+- Capture output including passes, failures, and errors
+- Monitor for test timeouts or crashes
+
+### 3. Analyze Results
+- Parse test output
+- Identify failing tests
+- Extract error messages and stack traces
+- Categorize failures (assertions, errors, timeouts)
+
+### 4. Report Findings
+- Summarize: X passed, Y failed out of Z total
+- List failing tests with file locations
+- Show error messages for failures
+- Suggest next steps (fix code, update tests, check dependencies)
+
+## Output Format
+
+```
+TEST RESULTS
+============
+Status: [PASS|FAIL]
+Passed: X/Z (XX%)
+Failed: Y/Z (XX%)
+
+FAILURES:
+---------
+1. tests/auth/login.test.ts:42
+   Test: "should reject invalid credentials"
+   Error: Expected status 401, received 500
+
+2. tests/api/users.test.ts:88
+   Test: "should create new user"
+   Error: ValidationError: email is required
+
+NEXT STEPS:
+-----------
+- Fix server error in login handler (returning 500 instead of 401)
+- Add email validation to user creation endpoint
+```
+```
+
+---
+
+## Windsurf Adaptation
+
+Following the **Skill Emulation Pattern** from WORKAROUND-PATTERNS.md:
+
+**File:** `.windsurf/workflows/test-runner.md`
+
+```yaml
+---
+description: USE WHEN running tests. Executes test suites and analyzes results.
+trigger: model_decision
+globs:
+  - "**/*.test.ts"
+  - "**/*.spec.ts"
+  - "tests/**/*"
+labels:
+  - testing
+  - automation
+  - quality
+---
+
+# Test Runner
+
+<!-- Version: 1.0.0 -->
+<!-- Adapted from cross-platform skill template -->
+
+## Tool Restrictions (Advisory)
+
+> **NOTE:** These restrictions rely on AI compliance and are NOT enforced by Windsurf.
+
+**Allowed Operations:**
+- Run test commands (`npm test`, `npm run test:*`)
+- Read test files (`tests/**`)
+- Read source files (`src/**`)
+- Search for test patterns
+
+**Forbidden Operations:**
+- Writing or editing files
+- Modifying test configuration
+- Installing dependencies
+- Committing changes
+
+**IMPORTANT:** Before using tools outside this list, ask user for permission.
+
+---
+
+## Execution Context
+
+This workflow uses inherited context (normal Cascade session).
+
+---
+
+## Process
+
+### 1. Identify Tests
+- Scan for test files matching `*.test.ts` or `*.spec.ts`
+- List available test scripts in `package.json`
+- Ask user which tests to run (all, unit, integration, specific)
+
+### 2. Execute Tests
+- Run selected test command
+- Capture output including passes, failures, and errors
+- Monitor for test timeouts or crashes
+
+### 3. Analyze Results
+- Parse test output
+- Identify failing tests
+- Extract error messages and stack traces
+- Categorize failures (assertions, errors, timeouts)
+
+### 4. Report Findings
+- Summarize: X passed, Y failed out of Z total
+- List failing tests with file locations
+- Show error messages for failures
+- Suggest next steps (fix code, update tests, check dependencies)
+
+## Output Format
+
+```
+TEST RESULTS
+============
+Status: [PASS|FAIL]
+Passed: X/Z (XX%)
+Failed: Y/Z (XX%)
+
+FAILURES:
+---------
+1. tests/auth/login.test.ts:42
+   Test: "should reject invalid credentials"
+   Error: Expected status 401, received 500
+
+2. tests/api/users.test.ts:88
+   Test: "should create new user"
+   Error: ValidationError: email is required
+
+NEXT STEPS:
+-----------
+- Fix server error in login handler (returning 500 instead of 401)
+- Add email validation to user creation endpoint
+```
+
+---
+
+## Invocation
+
+This workflow activates automatically when:
+- User mentions "run tests", "test suite", or "check tests"
+- User is working in test files (matches globs)
+- Windsurf's AI determines testing is relevant to current task
+
+Manual invocation: `/test-runner`
+```
+
+---
+
+## Claude Code Adaptation
+
+The skill works natively in Claude Code with minimal changes:
+
+**File:** `.claude/skills/test-runner/SKILL.md`
+
+```yaml
+---
+name: test-runner
+description: USE WHEN running tests. Executes test suites and analyzes results.
+version: "1.0.0"
+allowed-tools:
+  - Bash(npm test)
+  - Bash(npm run test:*)
+  - Read
+  - Grep
+model: sonnet
+context: inherit
+---
+
+# Test Runner
+
+Execute test suites and provide analysis of results.
+
+[Same process and output format as standard template]
+```
+
+**File:** `.claude/settings.json` (permissions merged)
+
+```json
+{
+  "permissions": {
+    "allow": [
+      "Read(tests/**)",
+      "Read(src/**)",
+      "Bash(npm test*)"
+    ],
+    "deny": [
+      "Write(**)"
+    ]
+  }
+}
+```
+
+---
+
+## GitHub Copilot Adaptation
+
+**File:** `.github/prompts/test-runner.prompt.md`
+
+```yaml
+---
+description: USE WHEN running tests. Executes test suites and analyzes results.
+applyTo:
+  - "**/*.test.ts"
+  - "**/*.spec.ts"
+mode: agent
+---
+
+# Test Runner
+
+<!-- Version: 1.0.0 -->
+
+## Operational Constraints
+
+**This prompt has the following tool restrictions:**
+
+Allowed:
+- Run test commands (`npm test`, `npm run test:*`)
+- Read test files (`tests/**`)
+- Read source files (`src/**`)
+
+Not Allowed:
+- Writing or editing files
+- Installing dependencies
+- Committing changes
+
+Please adhere to these constraints throughout execution.
+
+---
+
+[Same process and output format as standard template]
+```
+
+---
+
+## Comparison Summary
+
+| Aspect | Claude Code | Windsurf | GitHub Copilot |
+|--------|------------|----------|----------------|
+| **Format** | Native skill | Emulated as workflow | Emulated as prompt |
+| **Activation** | Auto-invoke via description | Model decision trigger | Apply to file patterns |
+| **Permissions** | Enforced by system | Advisory only | Advisory only |
+| **File Location** | `.claude/skills/` | `.windsurf/workflows/` | `.github/prompts/` |
+| **Agent Support** | Native | Emulated via persona rules | Inline persona in prompt |
+| **Invocation** | Auto or `/skill` | Auto or `/workflow` | Auto when editing matching files |
+
+---
+
+## Testing the Pattern
+
+### Manual Traceability Test
+
+**Scenario:** User wants to run tests in a TypeScript project
+
+**Windsurf Execution Flow:**
+
+1. **User:** "Can you run the tests and show me the results?"
+
+2. **Model Decision:**
+   - AI scans workflows with `trigger: model_decision`
+   - Matches "run the tests" to description "USE WHEN running tests"
+   - Activates `test-runner` workflow
+
+3. **Context Loading:**
+   - Reads `.windsurf/workflows/test-runner.md`
+   - Parses frontmatter and markdown body
+   - Loads instructions into AI context
+
+4. **Execution:**
+   - **Step 1:** AI uses Glob to scan for `*.test.ts` files
+   - **Step 1:** AI reads `package.json` to find test scripts
+   - **Step 1:** AI asks: "I found unit tests and integration tests. Which would you like to run?"
+
+5. **User:** "Run all tests"
+
+6. **Execution Continues:**
+   - **Step 2:** AI runs `npm test`
+   - **Step 2:** Captures output showing 45 passed, 2 failed
+   - **Step 3:** Parses failures, extracts error messages
+   - **Step 4:** Formats report according to template
+
+7. **Output:** AI presents formatted test results with failures highlighted
+
+8. **Completion:** Workflow completes, Cascade returns to normal mode
+
+**Verification:**
+- File exists: `.windsurf/workflows/test-runner.md`
+- YAML frontmatter valid
+- Workflow activated on keyword "run tests"
+- All 4 process steps executed
+- Output matches defined format
+- No forbidden operations performed (no file writes)
+
+---
+
+## Key Takeaways
+
+1. **One Source, Multiple Targets:** Write skill once in standard format, adapt to all platforms
+2. **Graceful Degradation:** Features not available on a platform become advisory instructions
+3. **Clear Documentation:** Each adaptation documents what works and what's emulated
+4. **Practical Testing:** Example includes manual trace to verify pattern works
+5. **Platform Strengths:** Each platform's adaptation uses its native features where possible
diff --git a/examples/workflow-example.md b/examples/workflow-example.md
new file mode 100644
index 0000000..13a0dac
--- /dev/null
+++ b/examples/workflow-example.md
@@ -0,0 +1,339 @@
+# Example: Windsurf Workflow → Claude Code Skill
+
+**Purpose:** Demonstrates how to convert a Windsurf workflow with AI-driven activation and multi-file context into a Claude Code skill.
+
+---
+
+## Original Windsurf Workflow
+
+**File:** `.windsurf/workflows/refactor-components.md`
+
+```yaml
+---
+description: USE WHEN refactoring React components for better modularity and reusability
+trigger: model_decision
+globs:
+  - "src/components/**/*.tsx"
+  - "src/components/**/*.ts"
+labels:
+  - refactoring
+  - react
+  - components
+author: "Engineering Team"
+---
+
+# Refactor Components Workflow
+
+## Context
+
+This workflow analyzes multiple React component files to identify refactoring opportunities, extract shared logic, and improve component modularity.
+
+## Prerequisites
+
+Windsurf's multi-file context automatically gathers:
+- All components in src/components/
+- Related hooks and utilities
+- Component test files
+- Shared types and interfaces
+
+## Workflow Steps
+
+### Step 1: Component Analysis
+Analyze all components in src/components/ to:
+- Identify duplicate logic patterns
+- Find components violating Single Responsibility Principle
+- Locate shared UI patterns that could be extracted
+
+### Step 2: Extraction Planning
+Create refactoring plan:
+- List components to be split
+- Identify shared hooks to extract
+- Document new component hierarchy
+
+### Step 3: Implementation
+Execute refactoring:
+- Extract shared logic to custom hooks
+- Split large components into smaller ones
+- Create shared UI components
+- Update imports across files
+
+### Step 4: Verification
+Ensure refactoring success:
+- Run TypeScript compiler to check types
+- Execute tests to verify functionality
+- Review component tree for improved structure
+
+## AI Activation Triggers
+
+This workflow activates when user mentions:
+- "refactor components"
+- "improve component structure"
+- "extract shared logic"
+- "split this component"
+- "modularize React code"
+
+Cascade's model decision engine evaluates context and activates this workflow automatically.
+```
+
+---
+
+## Adapted Claude Code Skill
+
+**File:** `.claude/skills/refactor-components/SKILL.md`
+
+```yaml
+---
+name: refactor-components
+description: >
+  USE WHEN refactoring React components for better modularity and reusability.
+  Analyzes component structure, extracts shared logic, and improves modularity.
+  Activate when user mentions: refactor components, improve component structure,
+  extract shared logic, split components, or modularize React code.
+version: "1.0.0"
+allowed-tools:
+  - Read
+  - Write
+  - Edit
+  - Grep
+  - Glob
+  - Bash(npm run tsc)
+  - Bash(npm test)
+context: inherit
+permissions:
+  allow:
+    - Read(src/components/**/*.tsx)
+    - Read(src/components/**/*.ts)
+    - Read(src/hooks/**/*.ts)
+    - Read(src/types/**/*.ts)
+    - Write(src/components/**/*.tsx)
+    - Write(src/hooks/**/*.ts)
+  deny:
+    - Write(src/components/index.ts)
+---
+
+# Refactor Components Skill
+
+## Purpose
+
+Analyze React component structure to identify refactoring opportunities, extract shared logic, and improve component modularity.
+
+**Emulated Multi-File Context:** This skill replicates Windsurf's multi-file awareness by explicitly gathering context from related files before proceeding with refactoring steps.
+
+---
+
+## Context Gathering Protocol
+
+**IMPORTANT:** Before beginning refactoring analysis, gather comprehensive context:
+
+### Step 0: Multi-File Context Acquisition
+
+Execute these Read/Grep operations to simulate Windsurf's automatic multi-file context:
+
+1. **List all component files:**
+   ```bash
+   Glob: src/components/**/*.tsx
+   Glob: src/components/**/*.ts
+   ```
+
+2. **Identify related hooks:**
+   ```bash
+   Grep: pattern="export.*use[A-Z]" path="src/hooks/"
+   ```
+
+3. **Find shared types:**
+   ```bash
+   Read: src/types/components.ts
+   Read: src/types/common.ts
+   ```
+
+4. **Locate component tests:**
+   ```bash
+   Glob: src/components/**/*.test.tsx
+   ```
+
+**Context Checklist:**
+- [ ] All component files identified
+- [ ] Related hooks discovered
+- [ ] Shared types loaded
+- [ ] Test files mapped
+
+**Only proceed to analysis once context gathering is complete.**
+
+---
+
+## Workflow Steps
+
+### Step 1: Component Analysis
+
+Analyze gathered components to:
+- Identify duplicate logic patterns
+- Find components violating Single Responsibility Principle
+- Locate shared UI patterns that could be extracted
+
+**Files to examine:**
+- All files from Step 0 context gathering
+- Focus on components with >150 lines
+- Components with similar naming patterns (e.g., UserCard, ProductCard, OrderCard)
+
+### Step 2: Extraction Planning
+
+Create refactoring plan document: `REFACTORING-PLAN.md`
+
+Include:
+- Components to be split (with rationale)
+- Shared hooks to extract (with proposed names)
+- New component hierarchy diagram
+- Impact assessment (which files will change)
+
+**Ask user for approval before proceeding.**
+
+### Step 3: Implementation
+
+Execute refactoring based on approved plan:
+
+1. Extract shared logic to custom hooks
+2. Split large components into smaller ones
+3. Create shared UI components
+4. Update imports across files
+
+**Work incrementally:**
+- Refactor one component at a time
+- Commit after each successful refactoring
+- Run tests between changes
+
+### Step 4: Verification
+
+Ensure refactoring success:
+
+```bash
+# Type check
+npm run tsc
+
+# Run tests
+npm test
+```
+
+**Verification checklist:**
+- [ ] TypeScript compiles without errors
+- [ ] All tests pass
+- [ ] No duplicate logic remains
+- [ ] Component tree improved
+- [ ] Imports updated correctly
+
+---
+
+## Activation Instructions
+
+**Manual Invocation (Required):**
+
+Unlike Windsurf's automatic activation, this skill must be manually invoked.
+
+**When to invoke this skill:**
+
+Use this skill when user mentions any of these phrases:
+- "refactor components"
+- "improve component structure"
+- "extract shared logic"
+- "split this component"
+- "modularize React code"
+- "clean up components"
+
+**Invocation command:** `/refactor-components`
+
+**Description-based matching:** The skill's `description` field includes trigger keywords that help AI determine relevance, but the user must still explicitly invoke the skill.
+
+---
+
+## Multi-File Context Simulation
+
+**Windsurf Capability:** Automatic multi-file context awareness
+**Claude Code Emulation:** Explicit context gathering via Read/Grep/Glob
+
+### Context Gathering Strategy
+
+Instead of Windsurf's automatic multi-file loading, this skill uses explicit context gathering:
+
+**Phase 1: Discovery**
+- Use `Glob` to find all relevant files
+- Use `Grep` to identify patterns across files
+- Use `Read` to load file contents
+
+**Phase 2: Analysis**
+- Process gathered files to build mental model
+- Identify relationships between files
+- Map dependencies and imports
+
+**Phase 3: Execution**
+- Make changes based on comprehensive context
+- Update multiple files in coordinated fashion
+- Maintain consistency across file boundaries
+
+**Limitation:** Context gathering is sequential and explicit, not automatic like Windsurf. The AI must remember to execute Step 0 before proceeding with analysis.
+
+---
+
+## Known Limitations
+
+1. **No AI-Driven Activation:**
+   - Windsurf: Cascade automatically activates workflow when relevant
+   - Claude Code: User must manually invoke skill with `/refactor-components`
+   - Mitigation: Include trigger keywords in description to help AI suggest skill usage
+
+2. **Manual Context Gathering:**
+   - Windsurf: Multi-file context loaded automatically via `globs` field
+   - Claude Code: Must explicitly use Glob/Grep/Read in Step 0
+   - Risk: AI might skip context gathering and make uninformed decisions
+
+3. **No Model Decision Engine:**
+   - Windsurf: AI evaluates whether workflow is relevant to current task
+   - Claude Code: Relies on user to recognize when skill is appropriate
+   - Workaround: Comprehensive description with activation scenarios
+
+4. **Shared Context (Not Isolated):**
+   - Using `context: inherit` means skill runs in main session
+   - Prior conversation history affects execution
+   - Alternative: Use `context: fork` for isolation, but loses multi-file context
+
+---
+
+## Verification Steps
+
+**How to verify this emulation pattern works:**
+
+1. **Test context gathering:**
+   - Run Step 0 commands
+   - Verify AI gathers all component files before analysis
+   - Confirm AI has loaded hooks, types, tests
+
+2. **Test multi-file refactoring:**
+   - Provide skill with multiple related components
+   - Verify it extracts shared logic across files
+   - Check that imports are updated consistently
+
+3. **Test activation description:**
+   - Ask AI "how should I refactor my React components?"
+   - Verify AI suggests invoking this skill
+   - Confirm description helps AI match user intent
+
+4. **Compare to Windsurf:**
+   - Execute same refactoring in Windsurf (auto-activation)
+   - Execute in Claude Code (manual invocation + context gathering)
+   - Verify outcomes are equivalent despite different activation methods
+
+---
+
+## Migration Notes
+
+**Converting Windsurf workflows to Claude Code skills:**
+
+This example demonstrates the transformation pattern:
+
+| Windsurf Feature | Claude Code Equivalent | Implementation |
+|-----------------|----------------------|----------------|
+| `trigger: model_decision` | Manual invocation | Add activation keywords to `description` |
+| `globs: [patterns]` | Explicit context gathering | Step 0: Use Glob/Grep to find files |
+| Automatic context loading | Sequential Read operations | Document files to read in workflow |
+| AI-driven activation | User-driven invocation | Provide clear "when to use" guidance |
+| Multi-file awareness | Explicit file mapping | Build file relationships in analysis phase |
+
+**Key Principle:** Make implicit capabilities explicit through structured instructions.
diff --git a/packages/cli/docs/development-guide.md b/packages/cli/docs/development-guide.md
index 605297c..e0e2c30 100644
--- a/packages/cli/docs/development-guide.md
+++ b/packages/cli/docs/development-guide.md
@@ -111,9 +111,44 @@ npm run build
 ./bin/run.js launch
 ```
 
-### File Watching (Optional)
+### Watch Mode Development
 
-TypeScript compiler in watch mode:
+AIW CLI includes integrated watch mode scripts for streamlined development:
+
+```bash
+# Combined watch: rebuilds code AND runs tests on changes
+npm run watch
+
+# TypeScript only: watch and rebuild on source changes
+npm run dev:watch
+
+# Tests only: watch and re-run tests on changes
+npm run test:watch
+
+# TypeScript compiler only (no template watching)
+npm run build:watch
+```
+
+**What each watch script does:**
+
+| Script | Purpose |
+|--------|---------|
+| `watch` | Runs both `dev:watch` and `test:watch` in parallel |
+| `dev:watch` | Compiles TypeScript + syncs templates to dist |
+| `test:watch` | Runs Mocha in watch mode, re-tests on changes |
+| `build:watch` | TypeScript compiler in watch mode only |
+| `templates:watch` | Watches `src/templates/` and copies to `dist/templates/` |
+
+**Recommended workflow:**
+
+```bash
+# Terminal: Start watch mode
+npm run watch
+
+# Now edit files - tests and builds update automatically!
+```
+
+**Manual approach (if preferred):**
 
 ```bash
 # Terminal 1: Watch and rebuild on changes
diff --git a/packages/cli/package-lock.json b/packages/cli/package-lock.json
index d6f2b6f..05b066f 100644
--- a/packages/cli/package-lock.json
+++ b/packages/cli/package-lock.json
@@ -14,6 +14,7 @@
         "@oclif/plugin-help": "^6",
         "@oclif/plugin-plugins": "^5",
         "chalk": "^5.6.2",
+        "gray-matter": "^4.0.3",
         "ora": "^9.0.0"
       },
       "bin": {
@@ -6914,6 +6915,19 @@
         "url": "https://opencollective.com/eslint"
       }
     },
+    "node_modules/esprima": {
+      "version": "4.0.1",
+      "resolved": "https://registry.npmjs.org/esprima/-/esprima-4.0.1.tgz",
+      "integrity": "sha512-eGuFFw7Upda+g4p+QHvnW0RyTX/SVeJBDM/gCtMARO0cLuT2HcEKnTPvhjV6aGeqrCB/sbNop0Kszm0jsaWU4A==",
+      "license": "BSD-2-Clause",
+      "bin": {
+        "esparse": "bin/esparse.js",
+        "esvalidate": "bin/esvalidate.js"
+      },
+      "engines": {
+        "node": ">=4"
+      }
+    },
     "node_modules/esquery": {
       "version": "1.7.0",
       "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.7.0.tgz",
@@ -6960,6 +6974,18 @@
         "node": ">=0.10.0"
       }
     },
+    "node_modules/extend-shallow": {
+      "version": "2.0.1",
+      "resolved": "https://registry.npmjs.org/extend-shallow/-/extend-shallow-2.0.1.tgz",
+      "integrity": "sha512-zCnTtlxNoAiDc3gqY2aYAWFx7XWWiasuF2K8Me5WbN8otHKTUKBwjPtNpRs/rbUZm7KxWAaNj7P1a/p52GbVug==",
+      "license": "MIT",
+      "dependencies": {
+        "is-extendable": "^0.1.0"
+      },
+      "engines": {
+        "node": ">=0.10.0"
+      }
+    },
     "node_modules/fast-deep-equal": {
       "version": "3.1.3",
       "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
@@ -7550,6 +7576,43 @@
       "dev": true,
       "license": "ISC"
     },
+    "node_modules/gray-matter": {
+      "version": "4.0.3",
+      "resolved": "https://registry.npmjs.org/gray-matter/-/gray-matter-4.0.3.tgz",
+      "integrity": "sha512-5v6yZd4JK3eMI3FqqCouswVqwugaA9r4dNZB1wwcmrD02QkV5H0y7XBQW8QwQqEaZY1pM9aqORSORhJRdNK44Q==",
+      "license": "MIT",
+      "dependencies": {
+        "js-yaml": "^3.13.1",
+        "kind-of": "^6.0.2",
+        "section-matter": "^1.0.0",
+        "strip-bom-string": "^1.0.0"
+      },
+      "engines": {
+        "node": ">=6.0"
+      }
+    },
+    "node_modules/gray-matter/node_modules/argparse": {
+      "version": "1.0.10",
+      "resolved": "https://registry.npmjs.org/argparse/-/argparse-1.0.10.tgz",
+      "integrity": "sha512-o5Roy6tNG4SL/FOkCAN6RzjiakZS25RLYFrcMttJqbdd8BWrnA+fGz57iN5Pb06pvBGvl5gQ0B48dJlslXvoTg==",
+      "license": "MIT",
+      "dependencies": {
+        "sprintf-js": "~1.0.2"
+      }
+    },
+    "node_modules/gray-matter/node_modules/js-yaml": {
+      "version": "3.14.2",
+      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-3.14.2.tgz",
+      "integrity": "sha512-PMSmkqxr106Xa156c2M265Z+FTrPl+oxd/rgOQy2tijQeK5TxQ43psO1ZCwhVOSdnn+RzkzlRz/eY4BgJBYVpg==",
+      "license": "MIT",
+      "dependencies": {
+        "argparse": "^1.0.7",
+        "esprima": "^4.0.0"
+      },
+      "bin": {
+        "js-yaml": "bin/js-yaml.js"
+      }
+    },
     "node_modules/has-bigints": {
       "version": "1.1.0",
       "resolved": "https://registry.npmjs.org/has-bigints/-/has-bigints-1.1.0.tgz",
@@ -8032,6 +8095,15 @@
         "url": "https://github.com/sponsors/sindresorhus"
       }
     },
+    "node_modules/is-extendable": {
+      "version": "0.1.1",
+      "resolved": "https://registry.npmjs.org/is-extendable/-/is-extendable-0.1.1.tgz",
+      "integrity": "sha512-5BMULNob1vgFX6EjQw5izWDxrecWK9AM72rugNr0TFldMOi0fj6Jk+zeKIt0xGj4cEfQIJth4w3OKWOJ4f+AFw==",
+      "license": "MIT",
+      "engines": {
+        "node": ">=0.10.0"
+      }
+    },
     "node_modules/is-extglob": {
       "version": "2.1.1",
       "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
@@ -8583,6 +8655,15 @@
         "json-buffer": "3.0.1"
       }
     },
+    "node_modules/kind-of": {
+      "version": "6.0.3",
+      "resolved": "https://registry.npmjs.org/kind-of/-/kind-of-6.0.3.tgz",
+      "integrity": "sha512-dcS1ul+9tmeD95T+x28/ehLgd9mENa3LsvDTtzm3vyBEO7RPptvAD+t44WVXaUjTBRcrpFeFlC8WCruUR456hw==",
+      "license": "MIT",
+      "engines": {
+        "node": ">=0.10.0"
+      }
+    },
     "node_modules/levn": {
       "version": "0.4.1",
       "resolved": "https://registry.npmjs.org/levn/-/levn-0.4.1.tgz",
@@ -12634,6 +12715,19 @@
       "dev": true,
       "license": "MIT"
     },
+    "node_modules/section-matter": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/section-matter/-/section-matter-1.0.0.tgz",
+      "integrity": "sha512-vfD3pmTzGpufjScBh50YHKzEu2lxBWhVEHsNGoEXmCmn2hKGfeNLYMzCJpe8cD7gqX7TJluOVpBkAequ6dgMmA==",
+      "license": "MIT",
+      "dependencies": {
+        "extend-shallow": "^2.0.1",
+        "kind-of": "^6.0.0"
+      },
+      "engines": {
+        "node": ">=4"
+      }
+    },
     "node_modules/semver": {
       "version": "7.7.3",
       "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.3.tgz",
@@ -13045,6 +13139,12 @@
       "dev": true,
       "license": "CC0-1.0"
     },
+    "node_modules/sprintf-js": {
+      "version": "1.0.3",
+      "resolved": "https://registry.npmjs.org/sprintf-js/-/sprintf-js-1.0.3.tgz",
+      "integrity": "sha512-D9cPgkvLlV3t3IzL0D0YLvGA9Ahk4PcvVwUbN0dSGr1aP0Nrt4AEnTUbuGvquEC0mA64Gqt1fzirlRs5ibXx8g==",
+      "license": "BSD-3-Clause"
+    },
     "node_modules/stable-hash": {
       "version": "0.0.5",
       "resolved": "https://registry.npmjs.org/stable-hash/-/stable-hash-0.0.5.tgz",
@@ -13270,6 +13370,15 @@
         "node": ">=4"
       }
     },
+    "node_modules/strip-bom-string": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/strip-bom-string/-/strip-bom-string-1.0.0.tgz",
+      "integrity": "sha512-uCC2VHvQRYu+lMh4My/sFNmF2klFymLX1wHJeXnbEJERpV/ZsVuonzerjfrGpIGF7LBVa1O7i9kjiWvJiFck8g==",
+      "license": "MIT",
+      "engines": {
+        "node": ">=0.10.0"
+      }
+    },
     "node_modules/strip-indent": {
       "version": "3.0.0",
       "resolved": "https://registry.npmjs.org/strip-indent/-/strip-indent-3.0.0.tgz",
diff --git a/packages/cli/package.json b/packages/cli/package.json
index 16a18dc..64ed4c6 100644
--- a/packages/cli/package.json
+++ b/packages/cli/package.json
@@ -15,6 +15,7 @@
     "@oclif/plugin-help": "^6",
     "@oclif/plugin-plugins": "^5",
     "chalk": "^5.6.2",
+    "gray-matter": "^4.0.3",
     "ora": "^9.0.0"
   },
   "devDependencies": {
@@ -27,10 +28,12 @@
     "@types/sinon": "^21.0.0",
     "c8": "^10.1.3",
     "chai": "^4",
+    "chokidar": "^5.0.0",
     "eslint": "^9",
     "eslint-config-oclif": "^6",
     "eslint-config-prettier": "^10",
     "mocha": "^10",
+    "npm-run-all2": "^8.0.4",
     "oclif": "^4",
     "prettier": "^3.7.4",
     "shx": "^0.3.3",
@@ -78,8 +81,11 @@
   },
   "scripts": {
     "build": "shx rm -rf dist && tsc -b && shx cp -r src/templates dist/",
+    "build:watch": "tsc -b --watch",
     "check": "npm run lint && npm run build",
     "clean": "shx rm -rf dist",
+    "dev": "npm run build && node --loader ts-node/esm bin/dev.js",
+    "dev:watch": "run-p build:watch templates:watch",
     "format": "prettier --write \"src/**/*.ts\" \"test/**/*.ts\"",
     "format:check": "prettier --check \"src/**/*.ts\" \"test/**/*.ts\"",
     "lint": "eslint",
@@ -87,9 +93,12 @@
     "postpack": "shx rm -f oclif.manifest.json",
     "posttest": "npm run lint",
     "prepack": "oclif manifest && oclif readme",
+    "templates:watch": "node --loader ts-node/esm src/lib/watch-templates.ts",
     "test": "mocha --forbid-only \"test/**/*.test.ts\"",
+    "test:watch": "mocha --watch \"test/**/*.test.ts\"",
     "test:coverage": "c8 npm test",
-    "version": "oclif readme && git add README.md"
+    "version": "oclif readme && git add README.md",
+    "watch": "run-p dev:watch test:watch"
   },
   "types": "dist/index.d.ts"
 }
diff --git a/packages/cli/src/commands/convert/index.ts b/packages/cli/src/commands/convert/index.ts
new file mode 100644
index 0000000..c951472
--- /dev/null
+++ b/packages/cli/src/commands/convert/index.ts
@@ -0,0 +1,233 @@
+import {promises as fs} from 'node:fs'
+import {dirname, join, resolve} from 'node:path'
+
+import {Args, Flags} from '@oclif/core'
+
+import BaseCommand from '../../lib/base-command.js'
+import {
+  parseTemplate,
+  ClaudeCodeAdapter,
+  WindsurfAdapter,
+} from '../../lib/template-mapper/index.js'
+import type {
+  Platform,
+  PlatformAdapter,
+  TransformationResult,
+  TransformationWarning,
+} from '../../lib/template-mapper/types.js'
+import {EXIT_CODES} from '../../types/exit-codes.js'
+
+/**
+ * Supported platform targets for conversion
+ */
+const SUPPORTED_PLATFORMS: Platform[] = ['claude-code', 'windsurf']
+
+/**
+ * Get adapter instance for a platform
+ */
+function getAdapter(platform: Platform): PlatformAdapter {
+  switch (platform) {
+    case 'claude-code': {
+      return new ClaudeCodeAdapter()
+    }
+
+    case 'windsurf': {
+      return new WindsurfAdapter()
+    }
+
+    default: {
+      throw new Error(`Unsupported platform: ${platform}`)
+    }
+  }
+}
+
+/**
+ * Format a warning for display
+ */
+function formatWarning(warning: TransformationWarning): string {
+  const prefix = `[${warning.category}]`
+  let message = `${prefix} ${warning.message}`
+  if (warning.field) {
+    message += ` (field: ${warning.field})`
+  }
+
+  if (warning.details) {
+    message += `\n    ${warning.details}`
+  }
+
+  return message
+}
+
+/**
+ * Convert templates between AI assistant platform formats.
+ *
+ * Takes a template file written in the standard superset format and converts
+ * it to platform-specific formats for Claude Code or Windsurf.
+ */
+export default class Convert extends BaseCommand {
+  static override args = {
+    source: Args.file({
+      description: 'Path to template file to convert',
+      required: true,
+    }),
+  }
+
+  static override description = 'Convert templates between AI assistant platform formats'
+
+  static override examples = [
+    '<%= config.bin %> <%= command.id %> template.md --to claude-code',
+    '<%= config.bin %> <%= command.id %> template.md --to windsurf',
+    '<%= config.bin %> <%= command.id %> template.md --to claude-code --to windsurf',
+    '<%= config.bin %> <%= command.id %> template.md --to claude-code --output ./output',
+    '<%= config.bin %> <%= command.id %> template.md --to windsurf --dry-run',
+  ]
+
+  static override flags = {
+    ...BaseCommand.baseFlags,
+    'dry-run': Flags.boolean({
+      description: 'Show what would be generated without writing files',
+      default: false,
+    }),
+    output: Flags.string({
+      char: 'o',
+      description: 'Output directory (default: current directory)',
+      default: '.',
+    }),
+    strict: Flags.boolean({
+      description: 'Fail on any incompatibility instead of generating warnings',
+      default: false,
+    }),
+    to: Flags.string({
+      char: 't',
+      description: 'Target platform(s): claude-code, windsurf',
+      multiple: true,
+      required: true,
+    }),
+  }
+
+  async run(): Promise<void> {
+    const {args, flags} = await this.parse(Convert)
+    const sourcePath = resolve(args.source)
+    const outputDir = resolve(flags.output)
+    const dryRun = flags['dry-run']
+    const strict = flags.strict
+    const targetPlatforms = flags.to as Platform[]
+
+    // Validate target platforms
+    for (const platform of targetPlatforms) {
+      if (!SUPPORTED_PLATFORMS.includes(platform)) {
+        this.logError(`Unsupported platform: ${platform}`)
+        this.logInfo(`Supported platforms: ${SUPPORTED_PLATFORMS.join(', ')}`)
+        this.exit(EXIT_CODES.INVALID_USAGE)
+      }
+    }
+
+    // Parse the source template
+    const spinner = this.spinner(`Parsing ${args.source}`)
+    spinner.start()
+
+    let template
+    try {
+      template = await parseTemplate(sourcePath)
+      spinner.succeed('Template parsed successfully')
+    } catch (error) {
+      spinner.fail('Failed to parse template')
+      this.logError((error as Error).message)
+      this.exit(EXIT_CODES.INVALID_USAGE)
+    }
+
+    this.logDebug(`Parsed template: ${template.metadata.name || 'unnamed'}`)
+    this.logDebug(`Description: ${template.metadata.description || 'none'}`)
+
+    // Convert to each target platform
+    const results: Map<Platform, TransformationResult> = new Map()
+    let totalWarnings = 0
+    let totalFiles = 0
+    let hasErrors = false
+
+    for (const platform of targetPlatforms) {
+      const platformSpinner = this.spinner(`Converting to ${platform}`)
+      platformSpinner.start()
+
+      const adapter = getAdapter(platform)
+      const result = adapter.transform(template, {
+        outputDir,
+        strict,
+      })
+
+      results.set(platform, result)
+
+      if (!result.success) {
+        platformSpinner.fail(`Failed to convert to ${platform}`)
+        if (result.error) {
+          this.logError(result.error)
+        }
+
+        hasErrors = true
+        continue
+      }
+
+      totalWarnings += result.warnings.length
+      totalFiles += result.files.size
+
+      platformSpinner.succeed(`Converted to ${platform}: ${result.files.size} file(s)`)
+
+      // Show warnings
+      if (result.warnings.length > 0) {
+        this.logInfo('')
+        this.logWarning(`${result.warnings.length} warning(s) for ${platform}:`)
+        for (const warning of result.warnings) {
+          this.logWarning(formatWarning(warning))
+        }
+      }
+
+      // Write or display files
+      if (dryRun) {
+        this.logInfo('')
+        this.logInfo(`Would generate files for ${platform}:`)
+        for (const [path] of result.files) {
+          this.logInfo(`  ${path}`)
+        }
+      } else {
+        // Write files
+        for (const [relativePath, content] of result.files) {
+          const fullPath = join(outputDir, relativePath)
+          const dir = dirname(fullPath)
+
+          // Ensure directory exists
+          await fs.mkdir(dir, {recursive: true})
+
+          // Write file
+          await fs.writeFile(fullPath, content, 'utf8')
+          this.logDebug(`Wrote: ${fullPath}`)
+        }
+
+        this.logInfo(`Generated ${result.files.size} file(s) for ${platform}`)
+      }
+    }
+
+    // Summary
+    this.logInfo('')
+    if (hasErrors && strict) {
+      this.logError('Conversion failed with errors')
+      this.exit(EXIT_CODES.GENERAL_ERROR)
+    }
+
+    if (dryRun) {
+      this.logSuccess(`Dry run complete: Would generate ${totalFiles} file(s) with ${totalWarnings} warning(s)`)
+    } else {
+      this.logSuccess(`Conversion complete: Generated ${totalFiles} file(s) with ${totalWarnings} warning(s)`)
+    }
+
+    // List all generated files
+    this.logInfo('')
+    this.logInfo('Generated files:')
+    for (const [platform, result] of results) {
+      if (result.success) {
+        for (const [path] of result.files) {
+          this.logInfo(`  [${platform}] ${path}`)
+        }
+      }
+    }
+  }
+}
diff --git a/packages/cli/src/lib/template-mapper/adapters/claude-code.ts b/packages/cli/src/lib/template-mapper/adapters/claude-code.ts
new file mode 100644
index 0000000..3a9d99e
--- /dev/null
+++ b/packages/cli/src/lib/template-mapper/adapters/claude-code.ts
@@ -0,0 +1,360 @@
+/**
+ * Claude Code Platform Adapter
+ *
+ * Transforms templates from the standard superset format to Claude Code native format.
+ * Claude Code is the most feature-complete platform, so this adapter primarily
+ * strips unused fields and restructures output for Claude Code's directory conventions.
+ *
+ * Reference: PLATFORM-ADAPTERS.md Section 1 (Claude Code Adapter)
+ */
+
+import type {
+  ParsedTemplate,
+  PlatformAdapter,
+  TransformationResult,
+  TransformationWarning,
+  TransformOptions,
+} from '../types.js'
+import {parseContent} from '../content-parser.js'
+import {ClaudeCodeContentTransformer} from '../content-transformers.js'
+
+/**
+ * Fields that are Claude Code native and passed through directly
+ */
+const CLAUDE_CODE_NATIVE_FIELDS = [
+  'name',
+  'description',
+  'version',
+  'allowed-tools',
+  'model',
+  'context',
+  'agent',
+  'disable-model-invocation',
+  'argument-hint',
+  'hooks',
+  'language',
+] as const
+
+/**
+ * Fields from other platforms that are dropped for Claude Code
+ */
+const DROPPED_FIELDS = {
+  // Windsurf-only fields
+  trigger: 'Windsurf-only: Claude Code uses description for auto-invocation',
+  globs: 'Windsurf-only: Use permissions patterns instead',
+  labels: 'Windsurf-only: No categorization system in Claude Code',
+  alwaysApply: 'Windsurf-only: Use CLAUDE.md for always-on content',
+  author: 'Windsurf-only: No attribution field in Claude Code',
+
+  // GitHub Copilot-only fields
+  applyTo: 'Copilot-only: Use permissions patterns instead',
+  excludeAgent: 'Copilot-only: No agent exclusion in Claude Code',
+  mode: 'Copilot-only: All Claude Code skills are implicitly agent mode',
+  tools: 'Copilot-only: Use allowed-tools instead',
+  infer: 'Copilot-only: Use description for auto-invocation',
+  target: 'Copilot-only: Not applicable',
+  handoffs: 'Copilot-only: Not applicable',
+  'mcp-servers': 'Copilot-only: Configure MCP in settings.json',
+
+  // Meta-fields (processed, not passed through)
+  platforms: 'Meta-field: Used by adapter routing',
+  compatibility: 'Meta-field: Documentation only',
+  emulation: 'Meta-field: Used by other adapters',
+} as const
+
+/**
+ * Generate YAML frontmatter for Claude Code SKILL.md format
+ */
+function generateFrontmatter(template: ParsedTemplate): string {
+  const {metadata} = template
+  const lines: string[] = ['---']
+
+  // Required/recommended fields
+  if (metadata.name) {
+    lines.push(`name: ${metadata.name}`)
+  }
+
+  if (metadata.description) {
+    // Use block scalar for multi-line descriptions
+    if (metadata.description.includes('\n')) {
+      lines.push('description: |')
+      for (const line of metadata.description.split('\n')) {
+        lines.push(`  ${line}`)
+      }
+    } else {
+      lines.push(`description: ${metadata.description}`)
+    }
+  }
+
+  if (metadata.version) {
+    lines.push(`version: "${metadata.version}"`)
+  }
+
+  // Claude Code specific fields
+  if (metadata['allowed-tools'] && metadata['allowed-tools'].length > 0) {
+    lines.push('allowed-tools:')
+    for (const tool of metadata['allowed-tools']) {
+      lines.push(`  - ${tool}`)
+    }
+  }
+
+  if (metadata.model) {
+    lines.push(`model: ${metadata.model}`)
+  }
+
+  if (metadata.context) {
+    lines.push(`context: ${metadata.context}`)
+  }
+
+  if (metadata.agent) {
+    lines.push(`agent: ${metadata.agent}`)
+  }
+
+  if (metadata['disable-model-invocation'] !== undefined) {
+    lines.push(`disable-model-invocation: ${metadata['disable-model-invocation']}`)
+  }
+
+  if (metadata['argument-hint']) {
+    lines.push(`argument-hint: "${metadata['argument-hint']}"`)
+  }
+
+  if (metadata.language) {
+    lines.push(`language: ${metadata.language}`)
+  }
+
+  // Hooks are complex - serialize them properly
+  if (metadata.hooks) {
+    lines.push('hooks:')
+    if (metadata.hooks.PreToolUse) {
+      lines.push('  PreToolUse:')
+      for (const hook of metadata.hooks.PreToolUse) {
+        lines.push(`    - matcher: "${hook.matcher || '*'}"`)
+        if (hook.once !== undefined) {
+          lines.push(`      once: ${hook.once}`)
+        }
+
+        lines.push('      hooks:')
+        for (const h of hook.hooks) {
+          lines.push(`        - type: ${h.type}`)
+          lines.push(`          command: "${h.command}"`)
+          if (h.timeout !== undefined) {
+            lines.push(`          timeout: ${h.timeout}`)
+          }
+        }
+      }
+    }
+
+    if (metadata.hooks.PostToolUse) {
+      lines.push('  PostToolUse:')
+      for (const hook of metadata.hooks.PostToolUse) {
+        if (hook.matcher) {
+          lines.push(`    - matcher: "${hook.matcher}"`)
+        }
+
+        lines.push('      hooks:')
+        for (const h of hook.hooks) {
+          lines.push(`        - type: ${h.type}`)
+          lines.push(`          command: "${h.command}"`)
+        }
+      }
+    }
+
+    if (metadata.hooks.Stop) {
+      lines.push('  Stop:')
+      for (const hook of metadata.hooks.Stop) {
+        lines.push('    - hooks:')
+        for (const h of hook.hooks) {
+          lines.push(`        - type: ${h.type}`)
+          lines.push(`          command: "${h.command}"`)
+        }
+      }
+    }
+  }
+
+  lines.push('---')
+  return lines.join('\n')
+}
+
+/**
+ * Generate settings.json content for permissions
+ * Note: This should be MERGED with existing settings.json, not replace it
+ */
+function generateSettingsJson(template: ParsedTemplate): string | null {
+  const {permissions} = template.metadata
+  if (!permissions || (!permissions.allow?.length && !permissions.deny?.length)) {
+    return null
+  }
+
+  const settings: {permissions: {allow?: string[]; deny?: string[]}} = {
+    permissions: {},
+  }
+
+  if (permissions.allow && permissions.allow.length > 0) {
+    settings.permissions.allow = permissions.allow
+  }
+
+  if (permissions.deny && permissions.deny.length > 0) {
+    settings.permissions.deny = permissions.deny
+  }
+
+  return JSON.stringify(settings, null, 2)
+}
+
+/**
+ * Claude Code platform adapter
+ */
+export class ClaudeCodeAdapter implements PlatformAdapter {
+  readonly platform = 'claude-code' as const
+
+  /**
+   * Get the output path for the main skill file
+   */
+  getOutputPath(template: ParsedTemplate): string {
+    const name = template.metadata.name || 'unnamed-skill'
+    return `.claude/skills/${name}/SKILL.md`
+  }
+
+  /**
+   * Validate a template for Claude Code compatibility
+   */
+  validate(template: ParsedTemplate): TransformationWarning[] {
+    const warnings: TransformationWarning[] = []
+    const {metadata} = template
+
+    // Check required fields
+    if (!metadata.name) {
+      warnings.push({
+        category: 'UNSUPPORTED',
+        message: 'Missing required field: name',
+        details: 'Claude Code skills require a name field for identification',
+        field: 'name',
+      })
+    }
+
+    // Check for dropped fields and warn
+    for (const [field, reason] of Object.entries(DROPPED_FIELDS)) {
+      if (metadata[field as keyof typeof metadata] !== undefined) {
+        warnings.push({
+          category: 'UNSUPPORTED',
+          message: `Field '${field}' will be dropped`,
+          details: reason,
+          field,
+        })
+      }
+    }
+
+    // Validate model field if present
+    if (metadata.model) {
+      const validModels = [
+        'sonnet', 'opus', 'haiku',
+        'claude-sonnet-4-5-20250929',
+        'claude-opus-4-5-20251101',
+        'claude-haiku-4-20250107',
+      ]
+      if (!validModels.includes(metadata.model)) {
+        warnings.push({
+          category: 'DEGRADED',
+          message: `Unknown model: ${metadata.model}`,
+          details: 'Model may not be supported. Valid models: ' + validModels.join(', '),
+          field: 'model',
+        })
+      }
+    }
+
+    // Validate context field if present
+    if (metadata.context && !['inherit', 'fork'].includes(metadata.context)) {
+      warnings.push({
+        category: 'UNSUPPORTED',
+        message: `Invalid context value: ${metadata.context}`,
+        details: 'Context must be "inherit" or "fork"',
+        field: 'context',
+      })
+    }
+
+    // Warn about permissions being project-scoped
+    if (metadata.permissions) {
+      warnings.push({
+        category: 'SECURITY',
+        message: 'Permissions are project-scoped, not skill-scoped',
+        details:
+          'Permissions in skill frontmatter are merged into .claude/settings.json ' +
+          'and apply to the entire project, not just this skill. ' +
+          'Review accumulated permissions periodically.',
+        field: 'permissions',
+      })
+    }
+
+    return warnings
+  }
+
+  /**
+   * Transform a template to Claude Code format
+   */
+  transform(
+    template: ParsedTemplate,
+    _options: TransformOptions = {},
+  ): TransformationResult {
+    const warnings = this.validate(template)
+    const files = new Map<string, string>()
+
+    // Check if we should proceed despite validation issues
+    const hasErrors = warnings.some((w) =>
+      w.category === 'UNSUPPORTED' && w.field === 'name',
+    )
+    if (hasErrors) {
+      return {
+        platform: 'claude-code',
+        files,
+        warnings,
+        success: false,
+        error: 'Template missing required fields for Claude Code',
+      }
+    }
+
+    // Phase 5: Transform content using semantic analysis
+    const contentAnalysis = template.contentAnalysis || parseContent(template.content)
+    const transformer = new ClaudeCodeContentTransformer()
+    const contentResult = transformer.transform(contentAnalysis, template.content)
+    const transformedContent = contentResult.content
+    warnings.push(...contentResult.warnings)
+
+    // Generate main SKILL.md file
+    const frontmatter = generateFrontmatter(template)
+    const skillContent = `${frontmatter}\n\n${transformedContent}`
+    const outputPath = this.getOutputPath(template)
+    files.set(outputPath, skillContent)
+
+    // Generate settings.json if permissions are specified
+    const settingsJson = generateSettingsJson(template)
+    if (settingsJson) {
+      files.set('.claude/settings.json', settingsJson)
+      warnings.push({
+        category: 'SECURITY',
+        message: 'settings.json generated with permissions',
+        details:
+          'If .claude/settings.json already exists, you must manually merge ' +
+          'the permissions. The generated file will overwrite existing settings.',
+      })
+    }
+
+    // Note: Agent files are not generated here - they would need to be
+    // defined separately. We just reference them.
+    if (template.metadata.agent) {
+      warnings.push({
+        category: 'EMULATED',
+        message: `Skill references agent: ${template.metadata.agent}`,
+        details:
+          'Ensure .claude/agents/' + template.metadata.agent + '.md exists. ' +
+          'Agent definitions must be created separately.',
+        field: 'agent',
+      })
+    }
+
+    return {
+      platform: 'claude-code',
+      files,
+      warnings,
+      success: true,
+    }
+  }
+}
diff --git a/packages/cli/src/lib/template-mapper/adapters/index.ts b/packages/cli/src/lib/template-mapper/adapters/index.ts
new file mode 100644
index 0000000..37b1025
--- /dev/null
+++ b/packages/cli/src/lib/template-mapper/adapters/index.ts
@@ -0,0 +1,11 @@
+/**
+ * Platform Adapters
+ *
+ * Re-exports all platform adapter implementations.
+ */
+
+export {ClaudeCodeAdapter} from './claude-code.js'
+export {WindsurfAdapter} from './windsurf.js'
+
+// GitHub Copilot adapter will be added in future phase
+// export { GitHubCopilotAdapter } from './github-copilot.js'
diff --git a/packages/cli/src/lib/template-mapper/adapters/windsurf.ts b/packages/cli/src/lib/template-mapper/adapters/windsurf.ts
new file mode 100644
index 0000000..b002d29
--- /dev/null
+++ b/packages/cli/src/lib/template-mapper/adapters/windsurf.ts
@@ -0,0 +1,667 @@
+/**
+ * Windsurf Platform Adapter
+ *
+ * Transforms templates from the standard superset format to Windsurf native format.
+ * Windsurf has fewer native features than Claude Code, so this adapter uses
+ * emulation patterns extensively from WORKAROUND-PATTERNS.md.
+ *
+ * Reference: PLATFORM-ADAPTERS.md Section 2 (Windsurf Adapter)
+ */
+
+import type {
+  ParsedTemplate,
+  PlatformAdapter,
+  TransformationResult,
+  TransformationWarning,
+  TransformOptions,
+  PLATFORM_LIMITS,
+} from '../types.js'
+import {parseContent} from '../content-parser.js'
+import {WindsurfContentTransformer} from '../content-transformers.js'
+
+/**
+ * Fields that are Windsurf native and passed through directly
+ */
+const WINDSURF_NATIVE_FIELDS = [
+  'description',
+  'trigger',
+  'globs',
+  'labels',
+  'alwaysApply',
+  'author',
+] as const
+
+/**
+ * Character limit for Windsurf workflow files
+ */
+const WINDSURF_CHAR_LIMIT = 12000
+
+/**
+ * Generate YAML frontmatter for Windsurf workflow format
+ */
+function generateFrontmatter(template: ParsedTemplate): string {
+  const {metadata} = template
+  const lines: string[] = ['---']
+
+  // Description is the primary field (required)
+  if (metadata.description) {
+    // Use block scalar for multi-line descriptions
+    if (metadata.description.includes('\n')) {
+      lines.push('description: |')
+      for (const line of metadata.description.split('\n')) {
+        lines.push(`  ${line}`)
+      }
+    } else {
+      lines.push(`description: ${metadata.description}`)
+    }
+  }
+
+  // Trigger type - default to model_decision if skills need activation
+  if (metadata.trigger) {
+    lines.push(`trigger: ${metadata.trigger}`)
+  } else if (metadata.name) {
+    // If it's a skill being converted, use model_decision
+    lines.push('trigger: model_decision')
+  }
+
+  // Globs for file-triggered workflows
+  if (metadata.globs && metadata.globs.length > 0) {
+    lines.push('globs:')
+    for (const glob of metadata.globs) {
+      lines.push(`  - "${glob}"`)
+    }
+  }
+
+  // Labels for categorization
+  if (metadata.labels && metadata.labels.length > 0) {
+    lines.push('labels:')
+    for (const label of metadata.labels) {
+      lines.push(`  - ${label}`)
+    }
+  }
+
+  // Always apply flag
+  if (metadata.alwaysApply !== undefined) {
+    lines.push(`alwaysApply: ${metadata.alwaysApply}`)
+  }
+
+  // Author attribution
+  if (metadata.author) {
+    lines.push(`author: "${metadata.author}"`)
+  }
+
+  lines.push('---')
+  return lines.join('\n')
+}
+
+/**
+ * Generate tool restrictions advisory section
+ * Emulates Claude Code's allowed-tools feature
+ */
+function generateToolRestrictionsSection(template: ParsedTemplate): string | null {
+  const tools = template.metadata['allowed-tools']
+  if (!tools || tools.length === 0) {
+    return null
+  }
+
+  const lines = [
+    '## Tool Restrictions (Advisory)',
+    '',
+    '> **NOTE:** These restrictions rely on AI compliance and are NOT enforced by Windsurf.',
+    '',
+    '**Allowed Operations:**',
+  ]
+
+  for (const tool of tools) {
+    // Parse tool names like "Bash(git *)" to human-readable descriptions
+    if (tool.startsWith('Bash(')) {
+      const cmd = tool.slice(5, -1)
+      lines.push(`- Shell commands: \`${cmd}\``)
+    } else if (tool === 'Read') {
+      lines.push('- Read files')
+    } else if (tool === 'Write') {
+      lines.push('- Write/create files')
+    } else if (tool === 'Edit') {
+      lines.push('- Edit existing files')
+    } else if (tool === 'Grep') {
+      lines.push('- Search file contents (grep)')
+    } else if (tool === 'Glob') {
+      lines.push('- Find files by pattern (glob)')
+    } else if (tool === 'Task') {
+      lines.push('- Spawn subagent tasks (see note below)')
+    } else {
+      lines.push(`- ${tool}`)
+    }
+  }
+
+  lines.push('')
+  lines.push('**Forbidden Operations:**')
+
+  // Infer forbidden operations from what's not in allowed list
+  const allTools = ['Read', 'Write', 'Edit', 'Grep', 'Glob', 'Bash', 'Task']
+  const forbidden: string[] = []
+
+  if (!tools.includes('Write') && !tools.includes('Edit')) {
+    forbidden.push('- Writing or editing files')
+  }
+
+  if (!tools.some((t) => t.startsWith('Bash'))) {
+    forbidden.push('- Shell commands')
+  }
+
+  if (!tools.includes('Task')) {
+    forbidden.push('- Spawning subagent tasks')
+  }
+
+  if (forbidden.length === 0) {
+    lines.push('- (No explicit restrictions beyond allowed operations)')
+  } else {
+    lines.push(...forbidden)
+  }
+
+  lines.push('')
+  lines.push('**IMPORTANT:** Before using tools outside this list, ask user for permission.')
+
+  return lines.join('\n')
+}
+
+/**
+ * Generate context isolation markers
+ * Emulates Claude Code's context: fork feature
+ */
+function generateContextSection(template: ParsedTemplate): string | null {
+  if (template.metadata.context !== 'fork') {
+    return null
+  }
+
+  return [
+    '## Execution Context',
+    '',
+    '[CONTEXT: Isolated Execution - Treat as fresh session]',
+    '',
+    'This workflow simulates isolated subagent execution. Complete ALL steps within this workflow before responding to other requests.',
+    '',
+  ].join('\n')
+}
+
+/**
+ * Generate closing context marker
+ */
+function generateContextEndMarker(template: ParsedTemplate): string | null {
+  if (template.metadata.context !== 'fork') {
+    return null
+  }
+
+  return '\n\n[END CONTEXT: Return to normal session]'
+}
+
+/**
+ * Generate permissions advisory section
+ * Emulates Claude Code's permissions feature
+ */
+function generatePermissionsSection(template: ParsedTemplate): string | null {
+  const perms = template.metadata.permissions
+  if (!perms || (!perms.allow?.length && !perms.deny?.length)) {
+    return null
+  }
+
+  const lines = [
+    '## Access Permissions (Advisory)',
+    '',
+  ]
+
+  if (perms.allow && perms.allow.length > 0) {
+    lines.push('**Allowed:**')
+    for (const pattern of perms.allow) {
+      lines.push(`- \`${pattern}\``)
+    }
+
+    lines.push('')
+  }
+
+  if (perms.deny && perms.deny.length > 0) {
+    lines.push('**Forbidden:**')
+    for (const pattern of perms.deny) {
+      lines.push(`- \`${pattern}\``)
+    }
+
+    lines.push('')
+  }
+
+  lines.push('> **WARNING:** These restrictions are advisory only and NOT enforced by Windsurf.')
+
+  return lines.join('\n')
+}
+
+/**
+ * Generate agent persona reference section
+ */
+function generateAgentSection(template: ParsedTemplate): string | null {
+  const agent = template.metadata.agent
+  if (!agent) {
+    return null
+  }
+
+  return [
+    '## Agent Persona',
+    '',
+    `This workflow uses the **${agent}** agent.`,
+    `Activate with: \`@rules:agent-${agent}\` before running this workflow.`,
+    '',
+  ].join('\n')
+}
+
+/**
+ * Generate agent persona rule file content
+ */
+function generateAgentRuleFile(template: ParsedTemplate): string | null {
+  const agent = template.metadata.agent
+  if (!agent) {
+    return null
+  }
+
+  const agentName = agent.replace(/-/g, ' ').split(' ')
+    .map((w) => w.charAt(0).toUpperCase() + w.slice(1))
+    .join(' ')
+
+  return `---
+trigger: manual
+description: Activate ${agent} persona with @rules:agent-${agent}
+---
+
+# ${agentName} Persona
+
+When @rules:agent-${agent} is active, adopt this persona:
+
+## Role
+You are a specialized ${agentName.toLowerCase()} agent.
+
+## Behavioral Guidelines
+- Follow the workflow instructions precisely
+- Maintain focus on the task at hand
+- Ask for clarification if instructions are ambiguous
+
+## Activation
+User invokes with: \`@rules:agent-${agent}\`
+
+## Deactivation
+Returns to default Cascade behavior when user starts new topic.
+
+> **NOTE:** Tool restrictions cannot be enforced in Windsurf. Rely on AI compliance.
+`
+}
+
+/**
+ * Generate permissions warning rule file content
+ */
+function generatePermissionsRuleFile(template: ParsedTemplate): string | null {
+  const perms = template.metadata.permissions
+  if (!perms?.deny?.length) {
+    return null
+  }
+
+  const name = template.metadata.name || 'workflow'
+
+  // Create glob patterns for the rule trigger
+  const denyGlobs = perms.deny.map((pattern) => {
+    // Extract file pattern from permission string like "Read(.env)"
+    const match = pattern.match(/\w+\(([^)]+)\)/)
+    return match ? match[1] : pattern
+  })
+
+  return `---
+trigger: glob
+globs:
+${denyGlobs.map((g) => `  - "${g}"`).join('\n')}
+description: Security warning for restricted files
+---
+
+# SECURITY WARNING - Restricted File Access
+
+You are accessing a file that has ACCESS RESTRICTIONS.
+
+## Restricted Patterns
+
+**FORBIDDEN - Do NOT access these files:**
+${perms.deny.map((p) => `- \`${p}\``).join('\n')}
+
+## Required Actions
+
+1. **STOP** - Do not read or modify this file
+2. **WARN** - Alert the user about the attempted access
+3. **ASK** - Request explicit permission if access is truly needed
+
+> **WARNING:** These restrictions are NOT technically enforced.
+> Violating them may expose secrets or corrupt critical configurations.
+`
+}
+
+/**
+ * Generate pre-execution hooks as manual workflow steps (PreToolUse)
+ */
+function generatePreHooksSection(template: ParsedTemplate): string | null {
+  const hooks = template.metadata.hooks
+  if (!hooks?.PreToolUse) {
+    return null
+  }
+
+  const lines = [
+    '## Pre-Execution Checks',
+    '',
+    '**IMPORTANT:** Before making any file changes, run:',
+    '',
+  ]
+
+  for (const hook of hooks.PreToolUse) {
+    for (const h of hook.hooks) {
+      lines.push('```bash')
+      lines.push(h.command)
+      lines.push('```')
+      lines.push('')
+    }
+  }
+
+  return lines.join('\n')
+}
+
+/**
+ * Generate post-tool-use hooks as manual workflow steps (PostToolUse)
+ * These run after each tool completes, unlike Stop hooks which run at session end.
+ */
+function generatePostToolUseSection(template: ParsedTemplate): string | null {
+  const hooks = template.metadata.hooks
+  if (!hooks?.PostToolUse) {
+    return null
+  }
+
+  const lines = [
+    '## Post-Tool Validation',
+    '',
+    '**IMPORTANT:** After EACH file operation (read/write/edit), run:',
+    '',
+  ]
+
+  for (const hook of hooks.PostToolUse) {
+    // Include matcher info if specified
+    if (hook.matcher && hook.matcher !== '*') {
+      lines.push(`> Applies to: \`${hook.matcher}\` operations`)
+      lines.push('')
+    }
+
+    for (const h of hook.hooks) {
+      lines.push('```bash')
+      lines.push(h.command)
+      lines.push('```')
+      lines.push('')
+    }
+  }
+
+  lines.push('Run these commands after completing each tool operation before proceeding.')
+
+  return lines.join('\n')
+}
+
+/**
+ * Generate post-execution hooks section
+ */
+function generatePostHooksSection(template: ParsedTemplate): string | null {
+  const hooks = template.metadata.hooks
+  if (!hooks?.Stop) {
+    return null
+  }
+
+  const lines = [
+    '## Post-Execution Validation',
+    '',
+    '**IMPORTANT:** After completing work, run:',
+    '',
+  ]
+
+  for (const hook of hooks.Stop) {
+    for (const h of hook.hooks) {
+      lines.push('```bash')
+      lines.push(h.command)
+      lines.push('```')
+      lines.push('')
+    }
+  }
+
+  lines.push('Ensure all checks pass before considering the task complete.')
+
+  return lines.join('\n')
+}
+
+/**
+ * Windsurf platform adapter
+ */
+export class WindsurfAdapter implements PlatformAdapter {
+  readonly platform = 'windsurf' as const
+
+  /**
+   * Get the output path for the main workflow file
+   */
+  getOutputPath(template: ParsedTemplate): string {
+    const name = template.metadata.name || 'unnamed-workflow'
+    return `.windsurf/workflows/${name}.md`
+  }
+
+  /**
+   * Validate a template for Windsurf compatibility
+   */
+  validate(template: ParsedTemplate): TransformationWarning[] {
+    const warnings: TransformationWarning[] = []
+    const {metadata} = template
+
+    // Check required fields
+    if (!metadata.description) {
+      warnings.push({
+        category: 'UNSUPPORTED',
+        message: 'Missing recommended field: description',
+        details: 'Windsurf workflows should have a description for model_decision activation',
+        field: 'description',
+      })
+    }
+
+    // Warn about emulated features
+    if (metadata['allowed-tools'] && metadata['allowed-tools'].length > 0) {
+      warnings.push({
+        category: 'EMULATED',
+        message: 'allowed-tools converted to advisory instructions',
+        details:
+          'Tool restrictions are NOT enforced by Windsurf. ' +
+          'AI must voluntarily comply with documented restrictions.',
+        field: 'allowed-tools',
+      })
+    }
+
+    if (metadata.context === 'fork') {
+      warnings.push({
+        category: 'EMULATED',
+        message: 'context: fork emulated with markers',
+        details:
+          'Windsurf does not support true context isolation. ' +
+          'Markers are added but previous conversation history is still accessible.',
+        field: 'context',
+      })
+    }
+
+    if (metadata.agent) {
+      warnings.push({
+        category: 'EMULATED',
+        message: `agent: ${metadata.agent} converted to persona rule`,
+        details:
+          'Custom agent requires manual activation with @rules:agent-' + metadata.agent + '. ' +
+          'User must invoke persona before running workflow.',
+        field: 'agent',
+      })
+    }
+
+    if (metadata.permissions) {
+      warnings.push({
+        category: 'SECURITY',
+        message: 'Permissions converted to advisory warnings',
+        details:
+          'Windsurf does not enforce permissions. ' +
+          'A glob-triggered warning rule will be created, but access is not blocked.',
+        field: 'permissions',
+      })
+    }
+
+    if (metadata.hooks) {
+      warnings.push({
+        category: 'EMULATED',
+        message: 'Hooks converted to manual workflow steps',
+        details:
+          'Windsurf does not have lifecycle hooks. ' +
+          'Hook commands are documented as manual pre/post execution steps.',
+        field: 'hooks',
+      })
+    }
+
+    // Warn about dropped Claude Code-only fields
+    if (metadata.model) {
+      warnings.push({
+        category: 'UNSUPPORTED',
+        message: 'model field dropped',
+        details: 'Windsurf model selection is configured separately in IDE settings.',
+        field: 'model',
+      })
+    }
+
+    return warnings
+  }
+
+  /**
+   * Transform a template to Windsurf format
+   */
+  transform(
+    template: ParsedTemplate,
+    _options: TransformOptions = {},
+  ): TransformationResult {
+    const warnings = this.validate(template)
+    const files = new Map<string, string>()
+
+    // Phase 5: Transform content using semantic analysis
+    const contentAnalysis = template.contentAnalysis || parseContent(template.content)
+    const transformer = new WindsurfContentTransformer()
+    const contentResult = transformer.transform(contentAnalysis, template.content)
+    const transformedContent = contentResult.content
+    warnings.push(...contentResult.warnings)
+
+    // Build the main workflow content
+    const sections: string[] = []
+
+    // Frontmatter
+    sections.push(generateFrontmatter(template))
+
+    // Version comment
+    if (template.metadata.version) {
+      sections.push(`\n<!-- Version: ${template.metadata.version} -->`)
+    }
+
+    // Compatibility note if specified
+    const compat = template.metadata.compatibility?.windsurf
+    if (compat) {
+      sections.push('\n## Platform Compatibility Note')
+      sections.push('')
+      sections.push(`> **NOTE [COMPATIBILITY]:** This template has ${compat.status} support on Windsurf.`)
+      if (compat.notes) {
+        sections.push(`> ${compat.notes}`)
+      }
+
+      sections.push('')
+    }
+
+    // Agent persona section
+    const agentSection = generateAgentSection(template)
+    if (agentSection) {
+      sections.push('\n' + agentSection)
+    }
+
+    // Tool restrictions (emulated)
+    const toolsSection = generateToolRestrictionsSection(template)
+    if (toolsSection) {
+      sections.push('\n' + toolsSection)
+    }
+
+    // Permissions (emulated)
+    const permsSection = generatePermissionsSection(template)
+    if (permsSection) {
+      sections.push('\n' + permsSection)
+    }
+
+    // Pre-execution hooks (PreToolUse)
+    const preHooksSection = generatePreHooksSection(template)
+    if (preHooksSection) {
+      sections.push('\n---\n\n' + preHooksSection)
+    }
+
+    // Post-tool-use hooks (PostToolUse)
+    const postToolUseSection = generatePostToolUseSection(template)
+    if (postToolUseSection) {
+      sections.push('\n---\n\n' + postToolUseSection)
+    }
+
+    // Context isolation markers
+    const contextSection = generateContextSection(template)
+    if (contextSection) {
+      sections.push('\n---\n\n' + contextSection)
+    }
+
+    // Main content (using transformed content from Phase 5)
+    if (transformedContent) {
+      sections.push('\n' + transformedContent)
+    }
+
+    // Context end marker
+    const contextEnd = generateContextEndMarker(template)
+    if (contextEnd) {
+      sections.push(contextEnd)
+    }
+
+    // Post-execution hooks
+    const postHooksSection = generatePostHooksSection(template)
+    if (postHooksSection) {
+      sections.push('\n\n---\n\n' + postHooksSection)
+    }
+
+    const workflowContent = sections.join('')
+
+    // Check character limit
+    if (workflowContent.length > WINDSURF_CHAR_LIMIT) {
+      warnings.push({
+        category: 'LIMIT',
+        message: `Workflow exceeds ${WINDSURF_CHAR_LIMIT} character limit`,
+        details:
+          `Content is ${workflowContent.length} characters. ` +
+          'Consider splitting into multiple workflow files.',
+      })
+    }
+
+    // Main workflow file
+    const outputPath = this.getOutputPath(template)
+    files.set(outputPath, workflowContent)
+
+    // Generate agent persona rule file if needed
+    const agentRule = generateAgentRuleFile(template)
+    if (agentRule) {
+      const agentRulePath = `.windsurf/rules/agent-${template.metadata.agent}.md`
+      files.set(agentRulePath, agentRule)
+    }
+
+    // Generate permissions warning rule file if needed
+    const permsRule = generatePermissionsRuleFile(template)
+    if (permsRule) {
+      const name = template.metadata.name || 'workflow'
+      const permsRulePath = `.windsurf/rules/permissions-${name}.md`
+      files.set(permsRulePath, permsRule)
+    }
+
+    return {
+      platform: 'windsurf',
+      files,
+      warnings,
+      success: true,
+    }
+  }
+}
diff --git a/packages/cli/src/lib/template-mapper/content-parser.ts b/packages/cli/src/lib/template-mapper/content-parser.ts
new file mode 100644
index 0000000..9f8fc8a
--- /dev/null
+++ b/packages/cli/src/lib/template-mapper/content-parser.ts
@@ -0,0 +1,837 @@
+/**
+ * Content Parser with Semantic Construct Detection Engine
+ *
+ * Parses markdown workflow content to identify platform-specific semantic
+ * constructs that require transformation between AI assistant platforms.
+ *
+ * @module content-parser
+ */
+
+import type {
+  Platform,
+  SemanticConstruct,
+  SemanticConstructType,
+  ContentAnalysis,
+  ConstructLocation,
+} from './types.js'
+
+// =============================================================================
+// Detection Patterns
+// =============================================================================
+
+/**
+ * Regex patterns for detecting semantic constructs in content
+ * Each pattern is designed to match platform-specific syntax
+ */
+const PATTERNS: Record<SemanticConstructType, RegExp> = {
+  'agent-spawn':
+    /(?:spawn\s+(?:a\s+)?(?:new\s+)?agent|subagent|Task\s+tool|parallel\s+agent|delegate\s+to\s+agent|separate\s+context)/gi,
+
+  'tool-call':
+    /(?:use\s+(?:the\s+)?(?:Read|Write|Edit|Grep|Glob|Bash|Task|WebFetch|WebSearch|AskUserQuestion)\s+tool|call\s+(?:the\s+)?(?:Read|Write|Edit|Grep|Glob|Bash|Task)\s+tool|(?:Read|Write|Edit|Grep|Glob|Bash)\s*\(|run\s+(?:Read|Grep|Glob))/gi,
+
+  'context-switch':
+    /(?:context:\s*(?:fork|inherit)|fork\s+context|inherit\s+context|isolated\s+context|context\s+isolation|context\s+window|fresh\s+context|clean\s+context|shared\s+context)/gi,
+
+  'permission-reference':
+    /(?:allowed[- ]?tools|forbidden\s+operations|tool\s+restrictions?|permission\s+restrictions?|not\s+allowed|allow(?:ed)?:\s*-|deny:\s*-|before\s+using\s+tools\s+outside|rely\s+on\s+AI\s+compliance|advisory\s+(?:only|restrictions?)|cannot\s+be\s+enforced)/gi,
+
+  'model-decision-trigger':
+    /(?:USE\s+WHEN|trigger:\s*model_decision|model\s+decision|AI\s+determines|AI\s+decides|automatically\s+activates?|activates?\s+automatically|auto-?activation|activate\s+when\s+user\s+mentions|Cascade['s]?\s+(?:model\s+decision|determines))/gi,
+
+  'glob-pattern':
+    /(?:globs?:\s*\[|globs?:\s*-\s*["']|matching\s+glob|glob\s+pattern|\*\*\/\*\.(?:ts|tsx|js|jsx|py|md)|src\/\*\*\/|files?\s+matching\s+["']?\*|applyTo:\s*\[)/gi,
+
+  'persona-rule':
+    /(?:@rules:agent-[a-z-]+|agent\s+persona|persona\s+rule|security[-\s]specialist|specialized\s+agent|adopt\s+this\s+persona|behavioral\s+guidelines|specialized\s+[a-z]+\s+agent|custom\s+agent)/gi,
+
+  'skill-chaining':
+    /(?:\/prompt\s+[a-z-]+|Part\s+\d+\s+(?:of|→)\s+\d+|Proceed\s+to\s+Part\s+\d+|Next\s+Steps.*Part\s+\d+|→\s*Part\s+\d+|skill\s+chaining|invoke.*skill|chain.*skills?|\/[a-z-]+\s*$|execute.*prompt)/gim,
+
+  'context-gathering-protocol':
+    /(?:Step\s+0|Context\s+Gathering\s+Protocol|Multi-?File\s+Context\s+Acquisition|Context\s+Checklist|gather.*context|context\s+gathering|before\s+beginning.*gather|comprehensive\s+context|Only\s+proceed.*context)/gi,
+
+  'activation-instruction':
+    /(?:Manual\s+invocation|Invocation.*command|\/[a-z-]+\s*$|When\s+to\s+invoke|invoke\s+this\s+skill|invoke\s+with|user\s+must.*invoke|explicitly\s+invoke|Activation\s+Instructions|Manual\s+Trigger)/gim,
+
+  'working-set-limit':
+    /(?:working\s+set|10[-\s]file\s+limit|file\s+limit|working\s+set\s+limit|≤?\s*10\s+files?|in\s+batch|batch\s+of\s+files?|file\s+prioritization|exceeds?.*limit|within.*limit)/gi,
+
+  'checkpoint-commit':
+    /(?:checkpoint|create\s+commit|Checkpoint\s*:|commit\s+after|Step\s+\d+:\s*Checkpoint|git\s+commit.*refactor|rollback\s+plan|checkpoint\s+commit)/gi,
+
+  'progress-tracking':
+    /(?:REFACTOR-PROGRESS\.md|Progress\s+Tracking|Completion\s+Checklist|\[\s*[xX ]?\s*\].*completed?|progress\s+file|track.*progress|current\s+part|Status:)/gi,
+
+  'workspace-command':
+    /(?:@workspace\s+(?:analyze|find|show)|@workspace|workspace\s+search|use\s+@workspace)/gi,
+
+  'test-command':
+    /(?:npm\s+test|npm\s+run\s+test|run\s+tests?|test\s+suite|verify.*tests?|tests?\s+pass|pytest|jest|mocha|vitest)/gi,
+
+  'advisory-warning':
+    /(?:NOTE:.*not\s+enforced|advisory\s+only|rely\s+on\s+AI\s+compliance|cannot\s+be\s+enforced|IMPORTANT:.*restrictions|WARNING:.*limitations?|emulated|simulated|not\s+supported)/gi,
+
+  'version-comment':
+    /<!--\s*Version:\s*[\d.]+\s*-->|<!--\s*Part\s+\d+\s+of\s+\d+|<!--\s*Adapted\s+from/g,
+
+  'execution-flow-section':
+    /(?:Execution\s+Flow|Step-by-Step\s+Execution|Manual\s+Traceability|Intermediate\s+State|Verification\s+Points)/gi,
+}
+
+/**
+ * Mapping of construct types to their source platforms
+ */
+const SOURCE_PLATFORMS: Record<SemanticConstructType, Platform> = {
+  'agent-spawn': 'claude-code',
+  'tool-call': 'claude-code',
+  'context-switch': 'claude-code',
+  'permission-reference': 'claude-code',
+  'model-decision-trigger': 'windsurf',
+  'glob-pattern': 'windsurf',
+  'persona-rule': 'windsurf',
+  'skill-chaining': 'github-copilot',
+  'context-gathering-protocol': 'claude-code',
+  'activation-instruction': 'claude-code', // universal but claude-code is primary
+  'working-set-limit': 'github-copilot',
+  'checkpoint-commit': 'github-copilot',
+  'progress-tracking': 'github-copilot',
+  'workspace-command': 'github-copilot',
+  'test-command': 'claude-code', // universal
+  'advisory-warning': 'windsurf',
+  'version-comment': 'windsurf',
+  'execution-flow-section': 'claude-code', // universal
+}
+
+/**
+ * Pattern for detecting code blocks that should be skipped
+ * Matches fenced code blocks (```...```) and inline code (`...`)
+ */
+const CODE_BLOCK_PATTERN = /```[\s\S]*?```|`[^`]+`/g
+
+// =============================================================================
+// Helper Functions
+// =============================================================================
+
+/**
+ * Represents a range that should be excluded from matching
+ */
+interface ExcludedRange {
+  start: number
+  end: number
+}
+
+/**
+ * Find all code block ranges in content that should be skipped
+ *
+ * @param content - The content to scan for code blocks
+ * @returns Array of excluded ranges
+ */
+function findCodeBlockRanges(content: string): ExcludedRange[] {
+  const ranges: ExcludedRange[] = []
+  const regex = new RegExp(CODE_BLOCK_PATTERN.source, 'g')
+  let match: RegExpExecArray | null
+
+  while ((match = regex.exec(content)) !== null) {
+    ranges.push({
+      start: match.index,
+      end: match.index + match[0].length,
+    })
+  }
+
+  return ranges
+}
+
+/**
+ * Check if a position falls within any excluded range
+ *
+ * @param position - Character position to check
+ * @param excludedRanges - Array of excluded ranges
+ * @returns True if position is within an excluded range
+ */
+function isInExcludedRange(position: number, excludedRanges: ExcludedRange[]): boolean {
+  return excludedRanges.some((range) => position >= range.start && position < range.end)
+}
+
+/**
+ * Calculate the line number for a character position
+ *
+ * @param content - The full content
+ * @param position - Character position
+ * @returns Line number (1-indexed)
+ */
+function getLineNumber(content: string, position: number): number {
+  const substring = content.slice(0, position)
+  const lines = substring.split('\n')
+  return lines.length
+}
+
+/**
+ * Create a fresh copy of a regex pattern with reset state
+ *
+ * @param pattern - The regex pattern to copy
+ * @returns A new RegExp with the same pattern and flags
+ */
+function createFreshRegex(pattern: RegExp): RegExp {
+  return new RegExp(pattern.source, pattern.flags)
+}
+
+/**
+ * Parse additional data from matched text based on construct type
+ *
+ * @param type - The type of construct
+ * @param rawText - The matched text
+ * @returns Extracted data object
+ */
+function parseConstructData(
+  type: SemanticConstructType,
+  rawText: string,
+): Record<string, unknown> {
+  const parsed: Record<string, unknown> = {}
+
+  switch (type) {
+    case 'agent-spawn': {
+      // Extract agent type if mentioned
+      const hasTaskTool = /Task\s+tool/i.test(rawText)
+      const hasFork = /context:\s*fork|fork\s+context/i.test(rawText)
+      const hasSpawn = /spawn/i.test(rawText)
+      parsed.mechanism = hasTaskTool ? 'task-tool' : hasFork ? 'context-fork' : hasSpawn ? 'spawn' : 'unknown'
+      break
+    }
+
+    case 'tool-call': {
+      // Extract tool name
+      const toolMatch = rawText.match(/(?:Read|Write|Edit|Grep|Glob|Bash|Task|WebFetch|WebSearch|AskUserQuestion)/i)
+      if (toolMatch) {
+        parsed.toolName = toolMatch[0]
+      }
+      break
+    }
+
+    case 'context-switch': {
+      // Extract context type
+      const isFork = /fork/i.test(rawText)
+      const isInherit = /inherit/i.test(rawText)
+      parsed.contextType = isFork ? 'fork' : isInherit ? 'inherit' : 'isolation'
+      break
+    }
+
+    case 'model-decision-trigger': {
+      // Check for USE WHEN pattern
+      parsed.hasUseWhen = /USE\s+WHEN/i.test(rawText)
+      parsed.hasTriggerField = /trigger:\s*model_decision/i.test(rawText)
+      break
+    }
+
+    case 'glob-pattern': {
+      // Try to extract glob pattern
+      const globMatch = rawText.match(/\*\*\/\*\.(?:ts|tsx|js|jsx|py|md)|src\/\*\*\/[^\s]*/i)
+      if (globMatch) {
+        parsed.pattern = globMatch[0]
+      }
+      break
+    }
+
+    case 'skill-chaining': {
+      // Extract part number if present
+      const partMatch = rawText.match(/Part\s+(\d+)\s+(?:of|→)\s+(\d+)/i)
+      if (partMatch && partMatch[1] && partMatch[2]) {
+        parsed.currentPart = Number.parseInt(partMatch[1], 10)
+        parsed.totalParts = Number.parseInt(partMatch[2], 10)
+      }
+      // Extract skill/prompt name if present
+      const skillMatch = rawText.match(/\/([a-z-]+)/i)
+      if (skillMatch && skillMatch[1]) {
+        parsed.skillName = skillMatch[1]
+      }
+      break
+    }
+
+    case 'working-set-limit': {
+      // Check for specific limit mentioned
+      const limitMatch = rawText.match(/(\d+)[-\s]?file/i)
+      if (limitMatch && limitMatch[1]) {
+        parsed.fileLimit = Number.parseInt(limitMatch[1], 10)
+      }
+      break
+    }
+
+    case 'version-comment': {
+      // Extract version number
+      const versionMatch = rawText.match(/Version:\s*([\d.]+)/i)
+      if (versionMatch && versionMatch[1]) {
+        parsed.version = versionMatch[1]
+      }
+      // Extract part info
+      const partMatch = rawText.match(/Part\s+(\d+)\s+of\s+(\d+)/i)
+      if (partMatch && partMatch[1] && partMatch[2]) {
+        parsed.currentPart = Number.parseInt(partMatch[1], 10)
+        parsed.totalParts = Number.parseInt(partMatch[2], 10)
+      }
+      break
+    }
+
+    case 'workspace-command': {
+      // Extract workspace action
+      const actionMatch = rawText.match(/@workspace\s+(analyze|find|show)/i)
+      if (actionMatch && actionMatch[1]) {
+        parsed.action = actionMatch[1].toLowerCase()
+      }
+      break
+    }
+
+    case 'test-command': {
+      // Extract test framework
+      if (/npm\s+(?:test|run\s+test)/i.test(rawText)) {
+        parsed.framework = 'npm'
+      } else if (/pytest/i.test(rawText)) {
+        parsed.framework = 'pytest'
+      } else if (/jest/i.test(rawText)) {
+        parsed.framework = 'jest'
+      } else if (/mocha/i.test(rawText)) {
+        parsed.framework = 'mocha'
+      } else if (/vitest/i.test(rawText)) {
+        parsed.framework = 'vitest'
+      }
+      break
+    }
+
+    case 'checkpoint-commit': {
+      // Check for specific patterns
+      parsed.hasStepNumber = /Step\s+\d+/i.test(rawText)
+      parsed.hasRollbackPlan = /rollback\s+plan/i.test(rawText)
+      break
+    }
+
+    case 'progress-tracking': {
+      // Check for checklist items
+      parsed.hasChecklist = /\[\s*[xX ]?\s*\]/.test(rawText)
+      parsed.hasProgressFile = /REFACTOR-PROGRESS\.md/i.test(rawText)
+      break
+    }
+
+    case 'permission-reference': {
+      // Identify permission type
+      parsed.isAdvisory = /advisory|rely\s+on\s+AI\s+compliance|cannot\s+be\s+enforced/i.test(rawText)
+      parsed.isAllow = /allowed?[- ]?tools|allow(?:ed)?:/i.test(rawText)
+      parsed.isDeny = /forbidden|deny:|not\s+allowed/i.test(rawText)
+      break
+    }
+
+    case 'persona-rule': {
+      // Extract persona name if present
+      const rulesMatch = rawText.match(/@rules:agent-([a-z-]+)/i)
+      if (rulesMatch && rulesMatch[1]) {
+        parsed.personaName = rulesMatch[1]
+      } else {
+        const agentMatch = rawText.match(/agent[:\s]+([a-z-]+)/i)
+        if (agentMatch && agentMatch[1]) {
+          parsed.personaName = agentMatch[1]
+        }
+      }
+      break
+    }
+
+    case 'context-gathering-protocol': {
+      // Check for Step 0
+      parsed.hasStep0 = /Step\s+0/i.test(rawText)
+      parsed.hasChecklist = /Checklist/i.test(rawText)
+      break
+    }
+
+    case 'activation-instruction': {
+      // Extract invocation command if present
+      const commandMatch = rawText.match(/\/([a-z-]+)/i)
+      if (commandMatch) {
+        parsed.command = commandMatch[1]
+      }
+      parsed.isManual = /Manual/i.test(rawText)
+      break
+    }
+
+    case 'advisory-warning': {
+      // Classify warning type
+      parsed.isEnforcementWarning = /not\s+enforced|cannot\s+be\s+enforced/i.test(rawText)
+      parsed.isEmulationWarning = /emulated|simulated/i.test(rawText)
+      parsed.isLimitationWarning = /not\s+supported|limitations?/i.test(rawText)
+      break
+    }
+
+    case 'execution-flow-section': {
+      // Identify section type
+      if (/Execution\s+Flow/i.test(rawText)) {
+        parsed.sectionType = 'execution-flow'
+      } else if (/Step-by-Step/i.test(rawText)) {
+        parsed.sectionType = 'step-by-step'
+      } else if (/Intermediate\s+State/i.test(rawText)) {
+        parsed.sectionType = 'intermediate-state'
+      } else if (/Verification\s+Points/i.test(rawText)) {
+        parsed.sectionType = 'verification-points'
+      }
+      break
+    }
+  }
+
+  return parsed
+}
+
+// =============================================================================
+// Detection Functions
+// =============================================================================
+
+/**
+ * Detect agent spawning patterns in content
+ */
+export function detectAgentSpawning(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'agent-spawn', excludedRanges)
+}
+
+/**
+ * Detect tool call patterns in content
+ */
+export function detectToolCalls(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'tool-call', excludedRanges)
+}
+
+/**
+ * Detect context switch patterns in content
+ */
+export function detectContextSwitches(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'context-switch', excludedRanges)
+}
+
+/**
+ * Detect permission reference patterns in content
+ */
+export function detectPermissionReferences(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'permission-reference', excludedRanges)
+}
+
+/**
+ * Detect model decision trigger patterns in content
+ */
+export function detectModelDecisionTriggers(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'model-decision-trigger', excludedRanges)
+}
+
+/**
+ * Detect glob patterns in content
+ */
+export function detectGlobPatterns(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'glob-pattern', excludedRanges)
+}
+
+/**
+ * Detect persona rule patterns in content
+ */
+export function detectPersonaRules(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'persona-rule', excludedRanges)
+}
+
+/**
+ * Detect skill chaining patterns in content
+ */
+export function detectSkillChaining(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'skill-chaining', excludedRanges)
+}
+
+/**
+ * Detect context gathering protocol patterns in content
+ */
+export function detectContextGatheringProtocols(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'context-gathering-protocol', excludedRanges)
+}
+
+/**
+ * Detect activation instruction patterns in content
+ */
+export function detectActivationInstructions(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'activation-instruction', excludedRanges)
+}
+
+/**
+ * Detect working set limit patterns in content
+ */
+export function detectWorkingSetLimits(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'working-set-limit', excludedRanges)
+}
+
+/**
+ * Detect checkpoint commit patterns in content
+ */
+export function detectCheckpointCommits(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'checkpoint-commit', excludedRanges)
+}
+
+/**
+ * Detect progress tracking patterns in content
+ */
+export function detectProgressTracking(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'progress-tracking', excludedRanges)
+}
+
+/**
+ * Detect workspace command patterns in content
+ */
+export function detectWorkspaceCommands(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'workspace-command', excludedRanges)
+}
+
+/**
+ * Detect test command patterns in content
+ */
+export function detectTestCommands(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'test-command', excludedRanges)
+}
+
+/**
+ * Detect advisory warning patterns in content
+ */
+export function detectAdvisoryWarnings(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'advisory-warning', excludedRanges)
+}
+
+/**
+ * Detect version comment patterns in content
+ */
+export function detectVersionComments(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'version-comment', excludedRanges)
+}
+
+/**
+ * Detect execution flow section patterns in content
+ */
+export function detectExecutionFlowSections(
+  content: string,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  return detectPattern(content, 'execution-flow-section', excludedRanges)
+}
+
+/**
+ * Generic pattern detection function
+ *
+ * @param content - The content to search
+ * @param type - The construct type to detect
+ * @param excludedRanges - Ranges to skip (code blocks)
+ * @returns Array of detected semantic constructs
+ */
+function detectPattern(
+  content: string,
+  type: SemanticConstructType,
+  excludedRanges: ExcludedRange[],
+): SemanticConstruct[] {
+  const constructs: SemanticConstruct[] = []
+  const pattern = createFreshRegex(PATTERNS[type])
+  let match: RegExpExecArray | null
+
+  while ((match = pattern.exec(content)) !== null) {
+    const start = match.index
+    const end = start + match[0].length
+
+    // Skip if match is within a code block
+    if (isInExcludedRange(start, excludedRanges)) {
+      continue
+    }
+
+    const location: ConstructLocation = {
+      start,
+      end,
+      line: getLineNumber(content, start),
+    }
+
+    constructs.push({
+      type,
+      platform: SOURCE_PLATFORMS[type],
+      source: 'body',
+      location,
+      rawText: match[0],
+      parsed: parseConstructData(type, match[0]),
+    })
+  }
+
+  return constructs
+}
+
+// =============================================================================
+// Overlap Handling
+// =============================================================================
+
+/**
+ * Priority order for overlapping constructs (higher = more specific)
+ * More specific patterns take precedence over generic ones
+ */
+const CONSTRUCT_PRIORITY: Record<SemanticConstructType, number> = {
+  'tool-call': 90,              // Specific tool references
+  'model-decision-trigger': 85, // USE WHEN is very specific
+  'activation-instruction': 80, // Specific invocation patterns
+  'workspace-command': 75,      // @workspace is specific
+  'version-comment': 75,        // HTML comments are specific
+  'glob-pattern': 70,           // File patterns
+  'persona-rule': 70,           // @rules: patterns
+  'skill-chaining': 70,         // Part X of Y patterns
+  'agent-spawn': 65,            // Task tool references
+  'context-switch': 65,         // Context fork/inherit
+  'checkpoint-commit': 60,      // Checkpoint patterns
+  'working-set-limit': 60,      // File limits
+  'progress-tracking': 55,      // Progress tracking
+  'context-gathering-protocol': 55,
+  'test-command': 50,           // Test commands
+  'permission-reference': 50,   // Permission references
+  'advisory-warning': 45,       // Advisory notes
+  'execution-flow-section': 40, // Generic section headers
+}
+
+/**
+ * Check if two constructs overlap
+ */
+function constructsOverlap(a: SemanticConstruct, b: SemanticConstruct): boolean {
+  return (
+    (a.location.start >= b.location.start && a.location.start < b.location.end) ||
+    (b.location.start >= a.location.start && b.location.start < a.location.end)
+  )
+}
+
+/**
+ * Filter overlapping constructs, keeping the higher priority (more specific) one
+ * When priorities are equal, prefer the longer match
+ */
+function filterOverlappingConstructs(constructs: SemanticConstruct[]): SemanticConstruct[] {
+  if (constructs.length <= 1) {
+    return constructs
+  }
+
+  // Sort by start position, then by priority (descending), then by length (descending)
+  const sorted = [...constructs].sort((a, b) => {
+    if (a.location.start !== b.location.start) {
+      return a.location.start - b.location.start
+    }
+    const priorityDiff = CONSTRUCT_PRIORITY[b.type] - CONSTRUCT_PRIORITY[a.type]
+    if (priorityDiff !== 0) {
+      return priorityDiff
+    }
+    return b.rawText.length - a.rawText.length
+  })
+
+  const result: SemanticConstruct[] = []
+  const skipped = new Set<number>()
+
+  for (let i = 0; i < sorted.length; i++) {
+    if (skipped.has(i)) {
+      continue
+    }
+
+    const current = sorted[i]
+    if (!current) {
+      continue
+    }
+
+    let keepCurrent = true
+
+    // Check against remaining constructs for overlaps
+    for (let j = i + 1; j < sorted.length; j++) {
+      if (skipped.has(j)) {
+        continue
+      }
+
+      const other = sorted[j]
+      if (!other) {
+        continue
+      }
+
+      if (constructsOverlap(current, other)) {
+        // Determine which one to keep based on priority and length
+        const currentPriority = CONSTRUCT_PRIORITY[current.type]
+        const otherPriority = CONSTRUCT_PRIORITY[other.type]
+
+        if (otherPriority > currentPriority) {
+          keepCurrent = false
+          break
+        } else if (otherPriority === currentPriority && other.rawText.length > current.rawText.length) {
+          keepCurrent = false
+          break
+        } else {
+          // Current wins, skip the other
+          skipped.add(j)
+        }
+      }
+    }
+
+    if (keepCurrent) {
+      result.push(current)
+    }
+  }
+
+  return result
+}
+
+// =============================================================================
+// Main Parser Function
+// =============================================================================
+
+/**
+ * Parse content for semantic constructs
+ *
+ * Analyzes markdown workflow content to identify platform-specific semantic
+ * constructs that may require transformation between AI assistant platforms.
+ *
+ * Features:
+ * - Skips constructs inside code blocks (fenced and inline)
+ * - Handles overlapping matches (prefers longer/more specific)
+ * - Tracks location info (start, end, line number)
+ * - Extracts parsed data from matched constructs
+ *
+ * @param content - The markdown content to parse
+ * @returns ContentAnalysis with all detected constructs
+ *
+ * @example
+ * ```typescript
+ * const analysis = parseContent(`
+ * Use the Glob tool to find files.
+ * This activates automatically when user mentions "optimize".
+ * `)
+ *
+ * // Returns:
+ * // {
+ * //   constructs: [
+ * //     { type: 'tool-call', rawText: 'Use the Glob tool', ... },
+ * //     { type: 'model-decision-trigger', rawText: 'activates automatically when user mentions', ... }
+ * //   ],
+ * //   rawContent: '...'
+ * // }
+ * ```
+ */
+export function parseContent(content: string): ContentAnalysis {
+  // Find code block ranges to exclude
+  const excludedRanges = findCodeBlockRanges(content)
+
+  // Collect all constructs from all detection functions
+  const allConstructs: SemanticConstruct[] = [
+    ...detectAgentSpawning(content, excludedRanges),
+    ...detectToolCalls(content, excludedRanges),
+    ...detectContextSwitches(content, excludedRanges),
+    ...detectPermissionReferences(content, excludedRanges),
+    ...detectModelDecisionTriggers(content, excludedRanges),
+    ...detectGlobPatterns(content, excludedRanges),
+    ...detectPersonaRules(content, excludedRanges),
+    ...detectSkillChaining(content, excludedRanges),
+    ...detectContextGatheringProtocols(content, excludedRanges),
+    ...detectActivationInstructions(content, excludedRanges),
+    ...detectWorkingSetLimits(content, excludedRanges),
+    ...detectCheckpointCommits(content, excludedRanges),
+    ...detectProgressTracking(content, excludedRanges),
+    ...detectWorkspaceCommands(content, excludedRanges),
+    ...detectTestCommands(content, excludedRanges),
+    ...detectAdvisoryWarnings(content, excludedRanges),
+    ...detectVersionComments(content, excludedRanges),
+    ...detectExecutionFlowSections(content, excludedRanges),
+  ]
+
+  // Filter overlapping constructs
+  const filteredConstructs = filterOverlappingConstructs(allConstructs)
+
+  // Sort by position for consistent output
+  filteredConstructs.sort((a, b) => a.location.start - b.location.start)
+
+  return {
+    constructs: filteredConstructs,
+    rawContent: content,
+  }
+}
+
+// =============================================================================
+// Utility Exports
+// =============================================================================
+
+/**
+ * Get all construct types
+ */
+export function getConstructTypes(): SemanticConstructType[] {
+  return Object.keys(PATTERNS) as SemanticConstructType[]
+}
+
+/**
+ * Get the source platform for a construct type
+ */
+export function getSourcePlatform(type: SemanticConstructType): Platform {
+  return SOURCE_PLATFORMS[type]
+}
+
+/**
+ * Check if content contains any semantic constructs
+ */
+export function hasSemanticConstructs(content: string): boolean {
+  const analysis = parseContent(content)
+  return analysis.constructs.length > 0
+}
+
+/**
+ * Get constructs filtered by platform
+ */
+export function getConstructsByPlatform(
+  analysis: ContentAnalysis,
+  platform: Platform,
+): SemanticConstruct[] {
+  return analysis.constructs.filter((c) => c.platform === platform)
+}
+
+/**
+ * Get constructs filtered by type
+ */
+export function getConstructsByType(
+  analysis: ContentAnalysis,
+  type: SemanticConstructType,
+): SemanticConstruct[] {
+  return analysis.constructs.filter((c) => c.type === type)
+}
diff --git a/packages/cli/src/lib/template-mapper/content-transformers.ts b/packages/cli/src/lib/template-mapper/content-transformers.ts
new file mode 100644
index 0000000..1c9b163
--- /dev/null
+++ b/packages/cli/src/lib/template-mapper/content-transformers.ts
@@ -0,0 +1,1079 @@
+/**
+ * Content Transformers for Platform-Specific Content Rewriting
+ *
+ * Transforms semantic constructs in workflow content for each target platform.
+ * The content parser (content-parser.ts) extracts constructs; transformers rewrite them.
+ *
+ * @module content-transformers
+ */
+
+import type {
+  Platform,
+  ContentTransformer,
+  ContentAnalysis,
+  TransformedContent,
+  TransformationWarning,
+  SemanticConstruct,
+  SemanticConstructType,
+} from './types.js'
+
+// =============================================================================
+// Tool Mapping Tables
+// =============================================================================
+
+/**
+ * Maps Claude Code tool names to human-readable action descriptions for Windsurf
+ */
+const TOOL_TO_ACTION: Record<string, string> = {
+  Glob: 'Find files using pattern search',
+  Grep: 'Search file contents',
+  Read: 'View file contents',
+  Write: 'Create or overwrite file',
+  Edit: 'Modify existing file',
+  Bash: 'Execute shell command',
+  Task: 'Delegate to separate execution',
+  WebFetch: 'Retrieve web content',
+  WebSearch: 'Search the web',
+  AskUserQuestion: 'Ask user for input',
+}
+
+/**
+ * Maps Claude Code tool names to generic recommendations for Copilot
+ */
+const TOOL_TO_RECOMMENDATION: Record<string, string> = {
+  Glob: 'search for files matching patterns',
+  Grep: 'search for content in files',
+  Read: 'read file contents',
+  Write: 'write to files',
+  Edit: 'edit files',
+  Bash: 'run shell commands as needed',
+  Task: 'break down into smaller steps',
+  WebFetch: 'access web resources if available',
+  WebSearch: 'search online if needed',
+  AskUserQuestion: 'ask user for clarification',
+}
+
+// =============================================================================
+// Replacement Tracking
+// =============================================================================
+
+/**
+ * Tracks replacements to avoid double-replacement
+ */
+interface Replacement {
+  start: number
+  end: number
+  original: string
+  replacement: string
+}
+
+/**
+ * Apply replacements to content, handling position shifts
+ * Processes replacements from end to start to maintain position accuracy
+ */
+function applyReplacements(content: string, replacements: Replacement[]): string {
+  // Sort by start position descending to process from end
+  const sorted = [...replacements].sort((a, b) => b.start - a.start)
+
+  let result = content
+  for (const r of sorted) {
+    result = result.slice(0, r.start) + r.replacement + result.slice(r.end)
+  }
+
+  return result
+}
+
+/**
+ * Check if a position overlaps with any existing replacement
+ */
+function overlapsWithExisting(
+  start: number,
+  end: number,
+  replacements: Replacement[],
+): boolean {
+  return replacements.some(
+    (r) =>
+      (start >= r.start && start < r.end) ||
+      (end > r.start && end <= r.end) ||
+      (start <= r.start && end >= r.end),
+  )
+}
+
+// =============================================================================
+// Claude Code Content Transformer
+// =============================================================================
+
+/**
+ * Claude Code Content Transformer
+ *
+ * Claude Code is the reference platform with the most capabilities.
+ * This transformer passes through most constructs but converts
+ * Windsurf-specific syntax if present and warns on Windsurf-only constructs.
+ */
+export class ClaudeCodeContentTransformer implements ContentTransformer {
+  platform: Platform = 'claude-code'
+
+  transform(analysis: ContentAnalysis, content: string): TransformedContent {
+    const warnings: TransformationWarning[] = []
+    const replacements: Replacement[] = []
+
+    for (const construct of analysis.constructs) {
+      switch (construct.type) {
+        case 'model-decision-trigger':
+          // Windsurf-specific - convert to description-based discovery
+          if (construct.parsed?.hasTriggerField) {
+            warnings.push({
+              category: 'EMULATED',
+              message: 'Windsurf trigger: model_decision converted to description-based activation',
+              details: 'Claude Code uses skill descriptions for auto-invocation. Add activation keywords to description.',
+              field: 'trigger',
+            })
+          }
+          break
+
+        case 'glob-pattern':
+          // Windsurf-specific globs field
+          if (construct.rawText.includes('globs:')) {
+            warnings.push({
+              category: 'UNSUPPORTED',
+              message: 'Windsurf globs: field not supported',
+              details: 'Claude Code does not support file-triggered activation. Use permissions patterns or description keywords.',
+              field: 'globs',
+            })
+          }
+          break
+
+        case 'skill-chaining':
+          // Convert Copilot /prompt format to Claude Code /skill-name
+          if (construct.rawText.includes('/prompt ')) {
+            const match = construct.rawText.match(/\/prompt\s+([a-z-]+)/i)
+            if (match?.[1]) {
+              const skillName = match[1]
+              replacements.push({
+                start: construct.location.start,
+                end: construct.location.end,
+                original: construct.rawText,
+                replacement: `/${skillName}`,
+              })
+              warnings.push({
+                category: 'EMULATED',
+                message: `Copilot /prompt ${skillName} converted to /${skillName}`,
+                details: 'Claude Code uses /skill-name format for skill invocation.',
+              })
+            }
+          }
+          break
+
+        case 'workspace-command':
+          // Convert @workspace to Claude Code search pattern
+          if (construct.parsed?.action) {
+            const action = construct.parsed.action as string
+            let replacement = ''
+            switch (action) {
+              case 'find':
+                replacement = 'Use Glob and Grep tools to search'
+                break
+              case 'analyze':
+                replacement = 'Analyze the codebase using Read, Glob, and Grep tools'
+                break
+              case 'show':
+                replacement = 'Use Read tool to display'
+                break
+              default:
+                replacement = 'Search codebase using available tools'
+            }
+            replacements.push({
+              start: construct.location.start,
+              end: construct.location.end,
+              original: construct.rawText,
+              replacement,
+            })
+            warnings.push({
+              category: 'EMULATED',
+              message: `Copilot ${construct.rawText} converted to tool-based search`,
+              details: 'Claude Code uses explicit tool calls instead of @workspace.',
+            })
+          } else if (construct.rawText.includes('@workspace')) {
+            replacements.push({
+              start: construct.location.start,
+              end: construct.location.end,
+              original: construct.rawText,
+              replacement: 'Search the codebase using Glob and Grep tools',
+            })
+            warnings.push({
+              category: 'EMULATED',
+              message: '@workspace converted to tool-based search',
+              details: 'Claude Code uses explicit tool calls instead of @workspace.',
+            })
+          }
+          break
+
+        case 'working-set-limit':
+          // Copilot-specific - not needed on Claude Code
+          warnings.push({
+            category: 'UNSUPPORTED',
+            message: 'Working set limit reference removed',
+            details: 'Claude Code has 200k token context - working set limits do not apply.',
+          })
+          break
+
+        // Pass through Claude Code native constructs
+        case 'agent-spawn':
+        case 'tool-call':
+        case 'context-switch':
+        case 'permission-reference':
+        case 'context-gathering-protocol':
+        case 'activation-instruction':
+        case 'test-command':
+        case 'execution-flow-section':
+        case 'checkpoint-commit':
+        case 'progress-tracking':
+          // Native to Claude Code - no transformation needed
+          break
+
+        case 'persona-rule':
+          // Windsurf @rules: syntax to Claude Code agent reference
+          if (construct.rawText.includes('@rules:agent-')) {
+            const match = construct.rawText.match(/@rules:agent-([a-z-]+)/i)
+            if (match?.[1]) {
+              const agentName = match[1]
+              replacements.push({
+                start: construct.location.start,
+                end: construct.location.end,
+                original: construct.rawText,
+                replacement: `Use the ${agentName} agent`,
+              })
+              warnings.push({
+                category: 'EMULATED',
+                message: `Windsurf @rules:agent-${agentName} converted to agent reference`,
+                details: 'Claude Code uses agent: field in frontmatter for persona activation.',
+              })
+            }
+          }
+          break
+
+        case 'advisory-warning':
+        case 'version-comment':
+          // These are informational - pass through
+          break
+      }
+    }
+
+    const transformedContent = applyReplacements(content, replacements)
+
+    return {
+      content: transformedContent,
+      warnings,
+    }
+  }
+}
+
+// =============================================================================
+// Windsurf Content Transformer
+// =============================================================================
+
+/**
+ * Windsurf Content Transformer
+ *
+ * Transforms constructs for Windsurf compatibility:
+ * - agent-spawn: Sequential execution with advisory note
+ * - tool-call: Rephrase as action descriptions
+ * - context-switch: Replace with single-session note
+ * - permission-reference: Add advisory compliance note
+ * - skill-chaining: Convert to /workflow-name format
+ * - context-gathering-protocol: Remove Step 0 (automatic via globs)
+ * - activation-instruction: Convert to /workflow-name format
+ * - workspace-command: Convert to natural language
+ */
+export class WindsurfContentTransformer implements ContentTransformer {
+  platform: Platform = 'windsurf'
+
+  transform(analysis: ContentAnalysis, content: string): TransformedContent {
+    const warnings: TransformationWarning[] = []
+    const replacements: Replacement[] = []
+
+    for (const construct of analysis.constructs) {
+      // Skip if already replaced at this position
+      if (overlapsWithExisting(construct.location.start, construct.location.end, replacements)) {
+        continue
+      }
+
+      switch (construct.type) {
+        case 'agent-spawn':
+          this.transformAgentSpawn(construct, replacements, warnings)
+          break
+
+        case 'tool-call':
+          this.transformToolCall(construct, replacements, warnings)
+          break
+
+        case 'context-switch':
+          this.transformContextSwitch(construct, replacements, warnings)
+          break
+
+        case 'permission-reference':
+          this.transformPermissionReference(construct, replacements, warnings)
+          break
+
+        case 'skill-chaining':
+          this.transformSkillChaining(construct, replacements, warnings)
+          break
+
+        case 'context-gathering-protocol':
+          this.transformContextGatheringProtocol(construct, replacements, warnings)
+          break
+
+        case 'activation-instruction':
+          this.transformActivationInstruction(construct, replacements, warnings)
+          break
+
+        case 'workspace-command':
+          this.transformWorkspaceCommand(construct, replacements, warnings)
+          break
+
+        // Native Windsurf constructs - pass through
+        case 'glob-pattern':
+        case 'model-decision-trigger':
+        case 'persona-rule':
+        case 'advisory-warning':
+        case 'version-comment':
+          // Native to Windsurf - no transformation needed
+          break
+
+        // Universal constructs - pass through
+        case 'test-command':
+        case 'execution-flow-section':
+        case 'checkpoint-commit':
+        case 'progress-tracking':
+          // Universal - no transformation needed
+          break
+
+        case 'working-set-limit':
+          // Copilot-specific - not applicable to Windsurf
+          warnings.push({
+            category: 'UNSUPPORTED',
+            message: 'Working set limit reference not applicable',
+            details: 'Windsurf does not have working set limits like GitHub Copilot.',
+          })
+          break
+      }
+    }
+
+    const transformedContent = applyReplacements(content, replacements)
+
+    return {
+      content: transformedContent,
+      warnings,
+    }
+  }
+
+  private transformAgentSpawn(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    // Extract the task description from context
+    const rawText = construct.rawText
+    let taskDescription = 'this task'
+
+    // Try to extract what the agent should handle
+    const handleMatch = rawText.match(/(?:to\s+)?(?:handle|for)\s+(.+)/i)
+    if (handleMatch?.[1]) {
+      taskDescription = handleMatch[1].trim()
+    }
+
+    const replacement = `Execute the following ${taskDescription} steps sequentially:
+
+> **NOTE:** Subagent spawning not available on Windsurf. Running in single Cascade session.`
+
+    replacements.push({
+      start: construct.location.start,
+      end: construct.location.end,
+      original: rawText,
+      replacement,
+    })
+
+    warnings.push({
+      category: 'EMULATED',
+      message: 'Agent spawning converted to sequential execution',
+      details: 'Windsurf does not support subagent spawning via Task tool. Work is inlined into single session.',
+    })
+  }
+
+  private transformToolCall(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    const toolName = construct.parsed?.toolName as string | undefined
+    if (!toolName) return
+
+    const action = TOOL_TO_ACTION[toolName] || `Perform ${toolName} operation`
+
+    // Try to extract the context/target from the raw text
+    const rawText = construct.rawText
+    let contextPart = ''
+
+    // Match patterns like "Use Glob tool to find files" -> extract "to find files"
+    const toMatch = rawText.match(/tool\s+to\s+(.+)/i)
+    if (toMatch?.[1]) {
+      contextPart = ` to ${toMatch[1]}`
+    }
+
+    // Match patterns like "Grep: pattern=\"query\" path=\"src/\"" -> extract parameters
+    const grepMatch = rawText.match(/pattern=["']([^"']+)["']\s*path=["']([^"']+)["']/i)
+    if (grepMatch?.[1] && grepMatch?.[2]) {
+      const pattern = grepMatch[1]
+      const path = grepMatch[2]
+      replacements.push({
+        start: construct.location.start,
+        end: construct.location.end,
+        original: rawText,
+        replacement: `Search for "${pattern}" in ${path}`,
+      })
+      warnings.push({
+        category: 'EMULATED',
+        message: `Tool call ${toolName} converted to action description`,
+        details: 'Windsurf Cascade does not use explicit tool references.',
+      })
+      return
+    }
+
+    replacements.push({
+      start: construct.location.start,
+      end: construct.location.end,
+      original: rawText,
+      replacement: action + contextPart,
+    })
+
+    warnings.push({
+      category: 'EMULATED',
+      message: `Tool call ${toolName} converted to action description`,
+      details: 'Windsurf Cascade does not use explicit tool references.',
+    })
+  }
+
+  private transformContextSwitch(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    replacements.push({
+      start: construct.location.start,
+      end: construct.location.end,
+      original: construct.rawText,
+      replacement: 'Executes in current Cascade session (no isolation available)',
+    })
+
+    warnings.push({
+      category: 'EMULATED',
+      message: 'Context isolation not available',
+      details: 'Windsurf does not support context: fork isolation. All work shares the same conversation context.',
+    })
+  }
+
+  private transformPermissionReference(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    // Don't replace the content, but add an advisory note if it's already an advisory
+    if (construct.parsed?.isAdvisory) {
+      // Already has advisory language - no change needed
+      return
+    }
+
+    // For non-advisory permission references, add the advisory note
+    const advisoryNote = '\n\n> **NOTE:** These restrictions rely on AI compliance and are NOT enforced by Windsurf.'
+
+    // We'll add the note after the permission reference
+    replacements.push({
+      start: construct.location.end,
+      end: construct.location.end,
+      original: '',
+      replacement: advisoryNote,
+    })
+
+    warnings.push({
+      category: 'SECURITY',
+      message: 'Permission restrictions are advisory only',
+      details: 'Windsurf cannot enforce tool restrictions. Added compliance note.',
+    })
+  }
+
+  private transformSkillChaining(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    const rawText = construct.rawText
+
+    // Convert /skill-name to /workflow-name format
+    const skillMatch = rawText.match(/\/([a-z-]+)/i)
+    if (skillMatch?.[1]) {
+      const skillName = skillMatch[1]
+      // Windsurf uses same /name format for workflows
+      if (skillName === 'prompt') {
+        // Copilot uses /prompt name, Windsurf uses /workflow-name
+        const nameMatch = rawText.match(/\/prompt\s+([a-z-]+)/i)
+        if (nameMatch?.[1]) {
+          replacements.push({
+            start: construct.location.start,
+            end: construct.location.end,
+            original: rawText,
+            replacement: `/${nameMatch[1]}`,
+          })
+          warnings.push({
+            category: 'EMULATED',
+            message: 'Copilot /prompt format converted to /workflow-name',
+            details: 'Windsurf uses /workflow-name for workflow invocation.',
+          })
+        }
+      }
+      // Regular /skill-name already compatible with Windsurf /workflow-name
+    }
+
+    // Handle "Part X of Y" and "Proceed to Part X" patterns - no change needed for Windsurf
+  }
+
+  private transformContextGatheringProtocol(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    // Remove Step 0 context gathering - Windsurf handles automatically via globs
+    if (construct.parsed?.hasStep0) {
+      // Find the extent of Step 0 section (until next heading or significant break)
+      replacements.push({
+        start: construct.location.start,
+        end: construct.location.end,
+        original: construct.rawText,
+        replacement: '', // Remove entirely
+      })
+
+      warnings.push({
+        category: 'EMULATED',
+        message: 'Step 0 context gathering removed',
+        details: 'Windsurf automatically gathers context via globs. Manual context acquisition not needed.',
+      })
+    }
+  }
+
+  private transformActivationInstruction(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    const rawText = construct.rawText
+
+    // Convert to /workflow-name format if it's a manual invocation
+    const commandMatch = rawText.match(/\/([a-z-]+)/i)
+    if (commandMatch?.[1] && construct.parsed?.isManual) {
+      // Already in correct format for Windsurf
+      return
+    }
+
+    // If it says "invoke this skill" convert to workflow terminology
+    if (/invoke\s+this\s+skill/i.test(rawText)) {
+      replacements.push({
+        start: construct.location.start,
+        end: construct.location.end,
+        original: rawText,
+        replacement: rawText.replace(/skill/gi, 'workflow'),
+      })
+    }
+  }
+
+  private transformWorkspaceCommand(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    const rawText = construct.rawText
+    let replacement = ''
+
+    // Convert @workspace commands to natural language for Windsurf
+    if (construct.parsed?.action) {
+      const action = construct.parsed.action as string
+      switch (action) {
+        case 'find':
+          replacement = 'Search across the codebase to find'
+          break
+        case 'analyze':
+          replacement = 'Analyze the codebase'
+          break
+        case 'show':
+          replacement = 'Display'
+          break
+        default:
+          replacement = 'Search the codebase'
+      }
+    } else {
+      replacement = 'Search the codebase'
+    }
+
+    // Preserve any text after @workspace
+    const afterWorkspace = rawText.replace(/@workspace\s*/i, '')
+    if (afterWorkspace && afterWorkspace !== rawText) {
+      replacement = `${replacement} ${afterWorkspace}`
+    }
+
+    replacements.push({
+      start: construct.location.start,
+      end: construct.location.end,
+      original: rawText,
+      replacement,
+    })
+
+    warnings.push({
+      category: 'EMULATED',
+      message: '@workspace converted to natural language',
+      details: 'Windsurf does not have @workspace command. Using natural language search instruction.',
+    })
+  }
+}
+
+// =============================================================================
+// GitHub Copilot Content Transformer
+// =============================================================================
+
+/**
+ * GitHub Copilot Content Transformer
+ *
+ * Transforms constructs for GitHub Copilot compatibility:
+ * - agent-spawn: Replace with manual handoff instructions
+ * - tool-call: Generalize to recommendations
+ * - context-switch: Remove entirely
+ * - glob-pattern: Add working set notes and applyTo pattern
+ * - skill-chaining: Convert to /prompt name format
+ * - Large context refs: Add batch instructions
+ */
+export class CopilotContentTransformer implements ContentTransformer {
+  platform: Platform = 'github-copilot'
+
+  transform(analysis: ContentAnalysis, content: string): TransformedContent {
+    const warnings: TransformationWarning[] = []
+    const replacements: Replacement[] = []
+
+    for (const construct of analysis.constructs) {
+      // Skip if already replaced at this position
+      if (overlapsWithExisting(construct.location.start, construct.location.end, replacements)) {
+        continue
+      }
+
+      switch (construct.type) {
+        case 'agent-spawn':
+          this.transformAgentSpawn(construct, replacements, warnings)
+          break
+
+        case 'tool-call':
+          this.transformToolCall(construct, replacements, warnings)
+          break
+
+        case 'context-switch':
+          this.transformContextSwitch(construct, replacements, warnings)
+          break
+
+        case 'glob-pattern':
+          this.transformGlobPattern(construct, replacements, warnings)
+          break
+
+        case 'skill-chaining':
+          this.transformSkillChaining(construct, replacements, warnings)
+          break
+
+        case 'permission-reference':
+          this.transformPermissionReference(construct, replacements, warnings)
+          break
+
+        case 'context-gathering-protocol':
+          this.transformContextGatheringProtocol(construct, replacements, warnings)
+          break
+
+        case 'model-decision-trigger':
+          this.transformModelDecisionTrigger(construct, replacements, warnings)
+          break
+
+        case 'persona-rule':
+          this.transformPersonaRule(construct, replacements, warnings)
+          break
+
+        // Native Copilot constructs - pass through
+        case 'workspace-command':
+        case 'working-set-limit':
+          // Native to Copilot - no transformation needed
+          break
+
+        // Universal constructs - pass through with potential batch notes
+        case 'test-command':
+        case 'execution-flow-section':
+        case 'checkpoint-commit':
+        case 'progress-tracking':
+          // May need batch instructions for large operations
+          this.addBatchNotesIfNeeded(construct, replacements, warnings)
+          break
+
+        case 'activation-instruction':
+          this.transformActivationInstruction(construct, replacements, warnings)
+          break
+
+        case 'advisory-warning':
+        case 'version-comment':
+          // Informational - pass through
+          break
+      }
+    }
+
+    const transformedContent = applyReplacements(content, replacements)
+
+    return {
+      content: transformedContent,
+      warnings,
+    }
+  }
+
+  private transformAgentSpawn(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    // Extract the task description from context
+    const rawText = construct.rawText
+    let taskDescription = 'the specified task'
+
+    // Try to extract what the agent should handle
+    const handleMatch = rawText.match(/(?:to\s+)?(?:handle|for)\s+(.+)/i)
+    if (handleMatch?.[1]) {
+      taskDescription = handleMatch[1].trim()
+    }
+
+    const replacement = `## Manual Handoff
+
+Create a separate chat session to handle: ${taskDescription}
+
+> **NOTE:** GitHub Copilot does not support subagent execution.`
+
+    replacements.push({
+      start: construct.location.start,
+      end: construct.location.end,
+      original: rawText,
+      replacement,
+    })
+
+    warnings.push({
+      category: 'EMULATED',
+      message: 'Agent spawning converted to manual handoff',
+      details: 'GitHub Copilot does not support Task tool. User must manually create separate chat session.',
+    })
+  }
+
+  private transformToolCall(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    const toolName = construct.parsed?.toolName as string | undefined
+    if (!toolName) return
+
+    const recommendation = TOOL_TO_RECOMMENDATION[toolName] || `perform ${toolName.toLowerCase()} operations`
+
+    // Extract context from the raw text
+    const rawText = construct.rawText
+    let contextPart = ''
+
+    const toMatch = rawText.match(/tool\s+to\s+(.+)/i)
+    if (toMatch?.[1]) {
+      contextPart = ` to ${toMatch[1]}`
+    }
+
+    // Convert to generic recommendation
+    replacements.push({
+      start: construct.location.start,
+      end: construct.location.end,
+      original: rawText,
+      replacement: recommendation.charAt(0).toUpperCase() + recommendation.slice(1) + contextPart,
+    })
+
+    warnings.push({
+      category: 'EMULATED',
+      message: `Tool reference ${toolName} converted to recommendation`,
+      details: 'GitHub Copilot does not expose specific tool names. Using generic action description.',
+    })
+  }
+
+  private transformContextSwitch(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    // Remove context switch references entirely - Copilot doesn't support this
+    replacements.push({
+      start: construct.location.start,
+      end: construct.location.end,
+      original: construct.rawText,
+      replacement: '', // Remove entirely
+    })
+
+    warnings.push({
+      category: 'UNSUPPORTED',
+      message: 'Context isolation removed',
+      details: 'GitHub Copilot does not support context isolation. Reference removed.',
+    })
+  }
+
+  private transformGlobPattern(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    const rawText = construct.rawText
+
+    // Check if this is a Windsurf globs: field or inline pattern
+    if (rawText.includes('globs:')) {
+      // Add working set note
+      const note = `
+
+> **Working Set Note:** GitHub Copilot has a 10-file limit. Prioritize most relevant files.
+> Use applyTo: patterns in frontmatter instead of globs:.`
+
+      replacements.push({
+        start: construct.location.end,
+        end: construct.location.end,
+        original: '',
+        replacement: note,
+      })
+
+      warnings.push({
+        category: 'LIMIT',
+        message: 'Glob patterns may exceed working set limit',
+        details: 'GitHub Copilot limits context to 10 files. Consider using applyTo: for file filtering.',
+      })
+    } else if (construct.parsed?.pattern) {
+      // Inline glob pattern - add batch instruction
+      const note = '\n\n> Process files matching this pattern in batches of 10 to stay within working set limits.'
+
+      replacements.push({
+        start: construct.location.end,
+        end: construct.location.end,
+        original: '',
+        replacement: note,
+      })
+    }
+  }
+
+  private transformSkillChaining(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    const rawText = construct.rawText
+
+    // Convert /skill-name to /prompt name format
+    const skillMatch = rawText.match(/\/([a-z-]+)/i)
+    if (skillMatch?.[1]) {
+      const skillName = skillMatch[1]
+      if (skillName !== 'prompt') {
+        replacements.push({
+          start: construct.location.start,
+          end: construct.location.end,
+          original: rawText,
+          replacement: `/prompt ${skillName}`,
+        })
+        warnings.push({
+          category: 'EMULATED',
+          message: `/${skillName} converted to /prompt ${skillName}`,
+          details: 'GitHub Copilot uses /prompt name format for prompt invocation.',
+        })
+      }
+    }
+
+    // Handle "Part X of Y" patterns - add batch processing note
+    if (construct.parsed?.totalParts && (construct.parsed.totalParts as number) > 1) {
+      const totalParts = construct.parsed.totalParts as number
+      if (totalParts > 3) {
+        const note = '\n\n> Consider processing in smaller batches due to context limitations.'
+        replacements.push({
+          start: construct.location.end,
+          end: construct.location.end,
+          original: '',
+          replacement: note,
+        })
+      }
+    }
+  }
+
+  private transformPermissionReference(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    // Copilot doesn't have permission enforcement either
+    if (!construct.parsed?.isAdvisory) {
+      const advisoryNote = '\n\n> **NOTE:** These restrictions are advisory and rely on AI compliance.'
+      replacements.push({
+        start: construct.location.end,
+        end: construct.location.end,
+        original: '',
+        replacement: advisoryNote,
+      })
+
+      warnings.push({
+        category: 'SECURITY',
+        message: 'Permission restrictions are advisory only',
+        details: 'GitHub Copilot cannot enforce tool or file restrictions.',
+      })
+    }
+  }
+
+  private transformContextGatheringProtocol(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    // Add batch processing note for context gathering
+    const batchNote = `
+
+> **Context Limit:** GitHub Copilot has limited context. Process files in groups of 10.
+> Prioritize: 1) Entry points 2) Core logic 3) Related utilities`
+
+    replacements.push({
+      start: construct.location.end,
+      end: construct.location.end,
+      original: '',
+      replacement: batchNote,
+    })
+
+    warnings.push({
+      category: 'LIMIT',
+      message: 'Context gathering needs batching',
+      details: 'GitHub Copilot 10-file limit requires processing context in batches.',
+    })
+  }
+
+  private transformModelDecisionTrigger(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    // Copilot uses infer: true instead of trigger: model_decision
+    if (construct.parsed?.hasTriggerField) {
+      warnings.push({
+        category: 'EMULATED',
+        message: 'trigger: model_decision converted to infer: true',
+        details: 'GitHub Copilot uses infer field for automatic activation.',
+      })
+    }
+  }
+
+  private transformPersonaRule(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    const rawText = construct.rawText
+
+    // Convert @rules:agent-name to natural language
+    if (rawText.includes('@rules:agent-')) {
+      const match = rawText.match(/@rules:agent-([a-z-]+)/i)
+      if (match?.[1]) {
+        const agentName = match[1].replace(/-/g, ' ')
+        replacements.push({
+          start: construct.location.start,
+          end: construct.location.end,
+          original: rawText,
+          replacement: `Act as a ${agentName}`,
+        })
+        warnings.push({
+          category: 'EMULATED',
+          message: 'Persona rule converted to natural language',
+          details: 'GitHub Copilot does not have @rules: directive. Using natural language persona instruction.',
+        })
+      }
+    }
+  }
+
+  private transformActivationInstruction(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    const rawText = construct.rawText
+
+    // Convert /skill-name to /prompt name format
+    const commandMatch = rawText.match(/\/([a-z-]+)/i)
+    if (commandMatch?.[1]) {
+      const skillName = commandMatch[1]
+      if (skillName !== 'prompt') {
+        const newInstruction = rawText.replace(`/${skillName}`, `/prompt ${skillName}`)
+        replacements.push({
+          start: construct.location.start,
+          end: construct.location.end,
+          original: rawText,
+          replacement: newInstruction,
+        })
+      }
+    }
+
+    // Convert "skill" terminology to "prompt"
+    if (/invoke\s+this\s+skill/i.test(rawText) && !rawText.includes('prompt')) {
+      replacements.push({
+        start: construct.location.start,
+        end: construct.location.end,
+        original: rawText,
+        replacement: rawText.replace(/skill/gi, 'prompt'),
+      })
+    }
+  }
+
+  private addBatchNotesIfNeeded(
+    construct: SemanticConstruct,
+    replacements: Replacement[],
+    warnings: TransformationWarning[],
+  ): void {
+    // For progress tracking with many items, add batch note
+    if (construct.type === 'progress-tracking' && construct.parsed?.hasChecklist) {
+      // Check if content suggests large number of items
+      const rawText = construct.rawText
+      const checkboxCount = (rawText.match(/\[\s*[xX ]?\s*\]/g) || []).length
+
+      if (checkboxCount > 10) {
+        const batchNote = '\n\n> Process checklist items in batches of 10 due to context limitations.'
+        replacements.push({
+          start: construct.location.end,
+          end: construct.location.end,
+          original: '',
+          replacement: batchNote,
+        })
+
+        warnings.push({
+          category: 'LIMIT',
+          message: 'Large checklist may exceed context',
+          details: 'Consider breaking into smaller segments.',
+        })
+      }
+    }
+  }
+}
+
+// =============================================================================
+// Factory Function
+// =============================================================================
+
+/**
+ * Create a content transformer for the specified platform
+ *
+ * @param platform - Target platform
+ * @returns Content transformer instance
+ */
+export function createContentTransformer(platform: Platform): ContentTransformer {
+  switch (platform) {
+    case 'claude-code':
+      return new ClaudeCodeContentTransformer()
+    case 'windsurf':
+      return new WindsurfContentTransformer()
+    case 'github-copilot':
+      return new CopilotContentTransformer()
+    default:
+      throw new Error(`Unknown platform: ${platform}`)
+  }
+}
diff --git a/packages/cli/src/lib/template-mapper/index.ts b/packages/cli/src/lib/template-mapper/index.ts
new file mode 100644
index 0000000..df378f7
--- /dev/null
+++ b/packages/cli/src/lib/template-mapper/index.ts
@@ -0,0 +1,129 @@
+/**
+ * Template Mapper Module
+ *
+ * Cross-platform template conversion system for transforming templates
+ * between Claude Code, Windsurf, and GitHub Copilot formats.
+ *
+ * @module template-mapper
+ */
+
+// Re-export all types
+export type {
+  // Platform types
+  Platform,
+  CompatibilityStatus,
+
+  // Schema types
+  PlatformCompatibility,
+  EmulationPattern,
+  Permissions,
+  HookConfig,
+  LifecycleHooks,
+  Handoff,
+  TemplateMetadata,
+  ParsedTemplate,
+
+  // Transformation types
+  WarningCategory,
+  TransformationWarning,
+  TransformationResult,
+
+  // Adapter interface
+  PlatformAdapter,
+
+  // Options
+  TransformOptions,
+  ParseOptions,
+
+  // Engine types
+  ConversionResult,
+  MappingEngine,
+
+  // Validation types
+  ValidationSeverity,
+  ValidationIssue,
+  SchemaValidator,
+
+  // Platform-specific output types
+  ClaudeCodeOutput,
+  WindsurfOutput,
+  GitHubCopilotOutput,
+
+  // Phase 5: Semantic content types
+  SemanticConstructType,
+  ConstructLocation,
+  SemanticConstruct,
+  ContentAnalysis,
+
+  // Phase 5: Content transformer types
+  ContentTransformer,
+  TransformedContent,
+} from './types.js'
+
+// Re-export constants
+export {
+  PLATFORMS,
+  PLATFORM_LIMITS,
+  CLAUDE_CODE_TOOLS,
+  WINDSURF_TRIGGERS,
+  COPILOT_MODES,
+} from './types.js'
+
+// Parser exports
+export {
+  parseTemplate,
+  parseTemplateString,
+  isValidTemplate,
+  extractFrontmatter,
+  ParseError,
+} from './parser.js'
+
+// Validator exports will be added when implemented
+// export { validateSchema, validateForPlatform } from './validator.js'
+
+// Engine exports will be added when implemented
+// export { createMappingEngine } from './engine.js'
+
+// Adapter exports
+export {ClaudeCodeAdapter} from './adapters/claude-code.js'
+export {WindsurfAdapter} from './adapters/windsurf.js'
+
+// GitHub Copilot adapter will be added in future phase
+// export { GitHubCopilotAdapter } from './adapters/github-copilot.js'
+
+// Content parser exports (Phase 5)
+export {
+  parseContent,
+  hasSemanticConstructs,
+  getConstructsByPlatform,
+  getConstructsByType,
+  getConstructTypes,
+  getSourcePlatform,
+  // Individual detection functions
+  detectAgentSpawning,
+  detectToolCalls,
+  detectContextSwitches,
+  detectPermissionReferences,
+  detectModelDecisionTriggers,
+  detectGlobPatterns,
+  detectPersonaRules,
+  detectSkillChaining,
+  detectContextGatheringProtocols,
+  detectActivationInstructions,
+  detectWorkingSetLimits,
+  detectCheckpointCommits,
+  detectProgressTracking,
+  detectWorkspaceCommands,
+  detectTestCommands,
+  detectAdvisoryWarnings,
+  detectVersionComments,
+  detectExecutionFlowSections,
+} from './content-parser.js'
+
+// Content transformer exports (Phase 5)
+export {
+  ClaudeCodeContentTransformer,
+  WindsurfContentTransformer,
+  CopilotContentTransformer,
+  createContentTransformer,
+} from './content-transformers.js'
diff --git a/packages/cli/src/lib/template-mapper/parser.ts b/packages/cli/src/lib/template-mapper/parser.ts
new file mode 100644
index 0000000..b1deb90
--- /dev/null
+++ b/packages/cli/src/lib/template-mapper/parser.ts
@@ -0,0 +1,370 @@
+/**
+ * Template Parser
+ *
+ * Parses template files with YAML frontmatter and markdown content.
+ * Uses gray-matter for frontmatter extraction.
+ */
+
+import matter from 'gray-matter'
+import {readFile} from 'node:fs/promises'
+import {resolve} from 'node:path'
+
+import type {ParsedTemplate, ParseOptions, TemplateMetadata, ValidationIssue} from './types.js'
+
+/**
+ * Error thrown when parsing fails
+ */
+export class ParseError extends Error {
+  sourcePath: string | undefined
+  line: number | undefined
+  column: number | undefined
+
+  constructor(
+    message: string,
+    sourcePath?: string,
+    line?: number,
+    column?: number,
+  ) {
+    super(message)
+    this.name = 'ParseError'
+    if (sourcePath !== undefined) {
+      this.sourcePath = sourcePath
+    }
+
+    if (line !== undefined) {
+      this.line = line
+    }
+
+    if (column !== undefined) {
+      this.column = column
+    }
+  }
+}
+
+/**
+ * Normalize array fields that can be string or string[]
+ * Converts comma-separated strings to arrays
+ */
+function normalizeArrayField(value: unknown): string[] | undefined {
+  if (value === undefined || value === null) {
+    return undefined
+  }
+
+  if (Array.isArray(value)) {
+    return value.map(String)
+  }
+
+  if (typeof value === 'string') {
+    // Split by comma if contains commas, otherwise return single-item array
+    if (value.includes(',')) {
+      return value.split(',').map((s) => s.trim()).filter(Boolean)
+    }
+
+    return [value]
+  }
+
+  return undefined
+}
+
+/**
+ * Normalize metadata fields for consistent processing
+ */
+function normalizeMetadata(raw: Record<string, unknown>): TemplateMetadata {
+  const metadata: TemplateMetadata = {}
+
+  // Core fields - direct copy
+  if (raw.name !== undefined) metadata.name = String(raw.name)
+  if (raw.description !== undefined) metadata.description = String(raw.description)
+  if (raw.version !== undefined) metadata.version = String(raw.version)
+
+  // Claude Code fields
+  const allowedTools = normalizeArrayField(raw['allowed-tools'])
+  if (allowedTools !== undefined) {
+    metadata['allowed-tools'] = allowedTools
+  }
+
+  if (raw.model !== undefined) metadata.model = String(raw.model)
+  if (raw.context !== undefined) {
+    const ctx = String(raw.context)
+    if (ctx === 'inherit' || ctx === 'fork') {
+      metadata.context = ctx
+    }
+  }
+
+  if (raw.agent !== undefined) metadata.agent = String(raw.agent)
+  if (raw.permissions !== undefined && typeof raw.permissions === 'object') {
+    const perms = raw.permissions as Record<string, unknown>
+    metadata.permissions = {}
+    const allowPerms = normalizeArrayField(perms.allow)
+    if (allowPerms !== undefined) {
+      metadata.permissions.allow = allowPerms
+    }
+
+    const denyPerms = normalizeArrayField(perms.deny)
+    if (denyPerms !== undefined) {
+      metadata.permissions.deny = denyPerms
+    }
+  }
+
+  if (raw['disable-model-invocation'] !== undefined) {
+    metadata['disable-model-invocation'] = Boolean(raw['disable-model-invocation'])
+  }
+
+  if (raw['argument-hint'] !== undefined) {
+    metadata['argument-hint'] = String(raw['argument-hint'])
+  }
+
+  if (raw.hooks !== undefined && typeof raw.hooks === 'object') {
+    metadata.hooks = raw.hooks as NonNullable<TemplateMetadata['hooks']>
+  }
+
+  if (raw.language !== undefined) metadata.language = String(raw.language)
+
+  // Windsurf fields
+  if (raw.trigger !== undefined) {
+    const trigger = String(raw.trigger)
+    if (['manual', 'always_on', 'model_decision', 'glob'].includes(trigger)) {
+      metadata.trigger = trigger as NonNullable<TemplateMetadata['trigger']>
+    }
+  }
+
+  const globs = normalizeArrayField(raw.globs)
+  if (globs !== undefined) {
+    metadata.globs = globs
+  }
+
+  const labels = normalizeArrayField(raw.labels)
+  if (labels !== undefined) {
+    metadata.labels = labels
+  }
+
+  if (raw.alwaysApply !== undefined) metadata.alwaysApply = Boolean(raw.alwaysApply)
+  if (raw.author !== undefined) metadata.author = String(raw.author)
+
+  // GitHub Copilot fields
+  const applyTo = normalizeArrayField(raw.applyTo)
+  if (applyTo !== undefined) {
+    metadata.applyTo = applyTo
+  }
+
+  const excludeAgent = normalizeArrayField(raw.excludeAgent)
+  if (excludeAgent !== undefined) {
+    metadata.excludeAgent = excludeAgent
+  }
+
+  if (raw.mode !== undefined) {
+    const mode = String(raw.mode)
+    if (['agent', 'ask', 'edit'].includes(mode)) {
+      metadata.mode = mode as NonNullable<TemplateMetadata['mode']>
+    }
+  }
+
+  const tools = normalizeArrayField(raw.tools)
+  if (tools !== undefined) {
+    metadata.tools = tools
+  }
+
+  if (raw.infer !== undefined) metadata.infer = Boolean(raw.infer)
+  if (raw.target !== undefined) {
+    const target = String(raw.target)
+    if (target === 'vscode' || target === 'github-copilot') {
+      metadata.target = target
+    }
+  }
+
+  if (raw.metadata !== undefined && typeof raw.metadata === 'object') {
+    metadata.metadata = raw.metadata as Record<string, string>
+  }
+
+  if (raw.handoffs !== undefined && Array.isArray(raw.handoffs)) {
+    metadata.handoffs = raw.handoffs as NonNullable<TemplateMetadata['handoffs']>
+  }
+
+  if (raw['mcp-servers'] !== undefined && typeof raw['mcp-servers'] === 'object') {
+    metadata['mcp-servers'] = raw['mcp-servers'] as Record<string, unknown>
+  }
+
+  // Cross-platform fields
+  if (raw.platforms !== undefined) {
+    const platforms = normalizeArrayField(raw.platforms)
+    if (platforms !== undefined) {
+      const filteredPlatforms = platforms.filter(
+        (p) => ['claude-code', 'windsurf', 'github-copilot'].includes(p),
+      ) as NonNullable<TemplateMetadata['platforms']>
+      if (filteredPlatforms.length > 0) {
+        metadata.platforms = filteredPlatforms
+      }
+    }
+  }
+
+  if (raw.compatibility !== undefined && typeof raw.compatibility === 'object') {
+    metadata.compatibility = raw.compatibility as NonNullable<TemplateMetadata['compatibility']>
+  }
+
+  if (raw.emulation !== undefined && typeof raw.emulation === 'object') {
+    metadata.emulation = raw.emulation as NonNullable<TemplateMetadata['emulation']>
+  }
+
+  return metadata
+}
+
+/**
+ * Parse a template file from disk
+ *
+ * @param filePath Path to the template file
+ * @param options Parse options
+ * @returns Parsed template with metadata and content
+ * @throws ParseError if file cannot be read or parsed
+ */
+export async function parseTemplate(
+  filePath: string,
+  options: ParseOptions = {},
+): Promise<ParsedTemplate> {
+  const {basePath} = options
+  const resolvedPath = basePath ? resolve(basePath, filePath) : resolve(filePath)
+
+  let content: string
+  try {
+    content = await readFile(resolvedPath, 'utf8')
+  } catch (error) {
+    if ((error as NodeJS.ErrnoException).code === 'ENOENT') {
+      throw new ParseError(`File not found: ${resolvedPath}`, resolvedPath)
+    }
+
+    throw new ParseError(
+      `Failed to read file: ${(error as Error).message}`,
+      resolvedPath,
+    )
+  }
+
+  try {
+    const result = parseTemplateString(content, options)
+    return {
+      ...result,
+      sourcePath: resolvedPath,
+    }
+  } catch (error) {
+    if (error instanceof ParseError) {
+      error.sourcePath = resolvedPath
+      throw error
+    }
+
+    throw new ParseError(
+      `Failed to parse file: ${(error as Error).message}`,
+      resolvedPath,
+    )
+  }
+}
+
+/**
+ * Parse a template from string content
+ *
+ * @param content Template content (YAML frontmatter + markdown)
+ * @param options Parse options
+ * @returns Parsed template with metadata and content
+ * @throws ParseError if content cannot be parsed
+ */
+export function parseTemplateString(
+  content: string,
+  options: ParseOptions = {},
+): ParsedTemplate {
+  // Check for frontmatter delimiters
+  const trimmed = content.trim()
+  if (!trimmed.startsWith('---')) {
+    throw new ParseError(
+      'Template must start with YAML frontmatter (---). ' +
+      'Ensure your template begins with --- followed by YAML metadata.',
+    )
+  }
+
+  let parsed: matter.GrayMatterFile<string>
+  try {
+    parsed = matter(content)
+  } catch (error) {
+    const message = (error as Error).message
+    // Try to extract line number from YAML error
+    const lineMatch = message.match(/at line (\d+)/)
+    const parseError = new ParseError(`Invalid YAML frontmatter: ${message}`)
+
+    if (lineMatch && lineMatch[1]) {
+      parseError.line = Number.parseInt(lineMatch[1], 10)
+    }
+
+    throw parseError
+  }
+
+  // Normalize the raw metadata
+  const metadata = normalizeMetadata(parsed.data)
+
+  // Validate required fields if requested
+  if (options.validateRequired !== false) {
+    const issues = validateRequiredFields(metadata)
+    const errors = issues.filter((i) => i.severity === 'error')
+    if (errors.length > 0) {
+      const fieldNames = errors.map((e) => e.field).filter((f): f is string => f !== undefined)
+      throw new ParseError(
+        `Missing required fields: ${fieldNames.join(', ')}. ` +
+        errors.map((e) => e.message).join(' '),
+      )
+    }
+  }
+
+  return {
+    metadata,
+    content: parsed.content.trim(),
+  }
+}
+
+/**
+ * Validate that required fields are present
+ */
+function validateRequiredFields(metadata: TemplateMetadata): ValidationIssue[] {
+  const issues: ValidationIssue[] = []
+
+  // Description is strongly recommended for all platforms
+  if (!metadata.description) {
+    issues.push({
+      severity: 'warning',
+      field: 'description',
+      message: 'Description field is strongly recommended for all platforms',
+      suggestion: 'Add a description explaining what this template does',
+    })
+  }
+
+  // Note: We don't require 'name' here because it's only required for Claude Code,
+  // and Windsurf uses filename. Platform-specific validation happens in adapters.
+
+  return issues
+}
+
+/**
+ * Check if a file appears to be a valid template (has frontmatter)
+ *
+ * @param content File content to check
+ * @returns True if content appears to be a template
+ */
+export function isValidTemplate(content: string): boolean {
+  const trimmed = content.trim()
+  if (!trimmed.startsWith('---')) {
+    return false
+  }
+
+  // Check for closing frontmatter delimiter
+  const secondDelimiter = trimmed.indexOf('---', 3)
+  return secondDelimiter > 3
+}
+
+/**
+ * Extract just the frontmatter from a template without full parsing
+ *
+ * @param content Template content
+ * @returns Raw frontmatter data object
+ */
+export function extractFrontmatter(content: string): Record<string, unknown> | null {
+  try {
+    const parsed = matter(content)
+    return parsed.data
+  } catch {
+    return null
+  }
+}
diff --git a/packages/cli/src/lib/template-mapper/types.ts b/packages/cli/src/lib/template-mapper/types.ts
new file mode 100644
index 0000000..527c2b0
--- /dev/null
+++ b/packages/cli/src/lib/template-mapper/types.ts
@@ -0,0 +1,571 @@
+/**
+ * Template Mapper Types
+ *
+ * Core type definitions for the cross-platform template conversion system.
+ * Implements the superset schema from STANDARD-SCHEMA.md and platform
+ * adapter interfaces from PLATFORM-ADAPTERS.md.
+ */
+
+// =============================================================================
+// Platform Identifiers
+// =============================================================================
+
+/**
+ * Supported target platforms for template conversion
+ */
+export type Platform = 'claude-code' | 'windsurf' | 'github-copilot'
+
+/**
+ * All supported platforms as a constant array
+ */
+export const PLATFORMS: readonly Platform[] = ['claude-code', 'windsurf', 'github-copilot'] as const
+
+// =============================================================================
+// Core Schema Types (Superset)
+// =============================================================================
+
+/**
+ * Compatibility status for a platform
+ */
+export type CompatibilityStatus = 'full' | 'partial' | 'unsupported'
+
+/**
+ * Per-platform compatibility information
+ */
+export interface PlatformCompatibility {
+  status: CompatibilityStatus
+  notes?: string
+}
+
+/**
+ * Emulation pattern for a specific capability gap
+ */
+export interface EmulationPattern {
+  pattern: string
+  fallback: string
+  limitations?: string[]
+}
+
+/**
+ * Permissions structure for Claude Code
+ */
+export interface Permissions {
+  allow?: string[]
+  deny?: string[]
+}
+
+/**
+ * Hook configuration for lifecycle events (Claude Code 2.1.0+)
+ */
+export interface HookConfig {
+  matcher?: string
+  once?: boolean
+  hooks: Array<{
+    type: string
+    command: string
+    timeout?: number
+  }>
+}
+
+/**
+ * Lifecycle hooks for skills
+ */
+export interface LifecycleHooks {
+  PreToolUse?: HookConfig[]
+  PostToolUse?: HookConfig[]
+  Stop?: HookConfig[]
+}
+
+/**
+ * Handoff configuration for GitHub Copilot agents
+ */
+export interface Handoff {
+  target: string
+  button_label: string
+  prompt?: string
+}
+
+/**
+ * Superset YAML frontmatter specification
+ * Captures ALL fields from all three platforms (Claude Code, Windsurf, GitHub Copilot)
+ */
+export interface TemplateMetadata {
+  // ================================
+  // Core Fields (Universal)
+  // ================================
+  name?: string
+  description?: string
+  version?: string
+
+  // ================================
+  // Claude Code Fields
+  // ================================
+  'allowed-tools'?: string[]
+  model?: string
+  context?: 'inherit' | 'fork'
+  agent?: string
+  permissions?: Permissions
+  'disable-model-invocation'?: boolean
+  'argument-hint'?: string
+  hooks?: LifecycleHooks
+  language?: string
+
+  // ================================
+  // Windsurf Fields
+  // ================================
+  trigger?: 'manual' | 'always_on' | 'model_decision' | 'glob'
+  globs?: string[]
+  labels?: string[]
+  alwaysApply?: boolean
+  author?: string
+
+  // ================================
+  // GitHub Copilot Fields
+  // ================================
+  applyTo?: string | string[]
+  excludeAgent?: string | string[]
+  mode?: 'agent' | 'ask' | 'edit'
+  tools?: string[]
+  infer?: boolean
+  target?: 'vscode' | 'github-copilot'
+  metadata?: Record<string, string>
+  handoffs?: Handoff[]
+  'mcp-servers'?: Record<string, unknown>
+
+  // ================================
+  // Cross-Platform Fields
+  // ================================
+  platforms?: Platform[]
+  compatibility?: Partial<Record<Platform, PlatformCompatibility>>
+  emulation?: Record<string, EmulationPattern>
+}
+
+/**
+ * Parsed template with frontmatter and body content
+ */
+export interface ParsedTemplate {
+  /** Parsed YAML frontmatter */
+  metadata: TemplateMetadata
+  /** Raw markdown body content (after frontmatter) */
+  content: string
+  /** Original file path (if loaded from file) */
+  sourcePath?: string
+  /** Phase 5 addition: Parsed semantic constructs from content */
+  contentAnalysis?: ContentAnalysis
+}
+
+// =============================================================================
+// Transformation Types
+// =============================================================================
+
+/**
+ * Warning categories for transformation issues
+ */
+export type WarningCategory =
+  | 'UNSUPPORTED'  // Feature doesn't exist on target platform
+  | 'EMULATED'     // Feature is approximated
+  | 'LIMIT'        // Platform constraint exceeded
+  | 'SECURITY'     // Advisory-only restriction
+  | 'DEGRADED'     // Reduced functionality
+
+/**
+ * Warning generated during transformation
+ */
+export interface TransformationWarning {
+  category: WarningCategory
+  message: string
+  details?: string
+  field?: string
+}
+
+/**
+ * Result of a platform transformation
+ */
+export interface TransformationResult {
+  /** Target platform */
+  platform: Platform
+  /** Generated files (path -> content) */
+  files: Map<string, string>
+  /** Warnings generated during transformation */
+  warnings: TransformationWarning[]
+  /** Whether transformation succeeded */
+  success: boolean
+  /** Error message if transformation failed */
+  error?: string
+}
+
+// =============================================================================
+// Platform Adapter Interface
+// =============================================================================
+
+/**
+ * Platform adapter interface
+ *
+ * Adapters transform templates from the standard format to platform-native formats.
+ * Each adapter handles:
+ * - Field mapping (superset -> platform native)
+ * - Emulation patterns (for unsupported features)
+ * - Output structure (platform-specific file locations)
+ * - Validation (platform-specific constraints)
+ * - Warning generation (for degraded features)
+ */
+export interface PlatformAdapter {
+  /** The platform this adapter targets */
+  readonly platform: Platform
+
+  /**
+   * Transform a parsed template to platform-native format
+   * @param template Parsed template with metadata and content
+   * @param options Transformation options
+   * @returns Transformation result with generated files and warnings
+   */
+  transform(template: ParsedTemplate, options?: TransformOptions): TransformationResult
+
+  /**
+   * Validate a template for this platform
+   * @param template Parsed template to validate
+   * @returns Array of validation warnings/errors
+   */
+  validate(template: ParsedTemplate): TransformationWarning[]
+
+  /**
+   * Get the output path for the main generated file
+   * @param template Parsed template
+   * @returns Relative path where main file should be written
+   */
+  getOutputPath(template: ParsedTemplate): string
+}
+
+// =============================================================================
+// Conversion Options
+// =============================================================================
+
+/**
+ * Options for template transformation
+ */
+export interface TransformOptions {
+  /** Target platform(s) for conversion. If not specified, uses template's `platforms` field or all platforms */
+  targetPlatforms?: Platform[]
+
+  /** Fail on any incompatibility (default: false, generates warnings instead) */
+  strict?: boolean
+
+  /** Output directory root (default: current directory) */
+  outputDir?: string
+
+  /** Include compatibility notes in output (default: true) */
+  includeCompatibilityNotes?: boolean
+
+  /** Include emulation pattern documentation (default: true) */
+  includeEmulationDocs?: boolean
+
+  /** Dry run - generate output but don't write files (default: false) */
+  dryRun?: boolean
+}
+
+/**
+ * Options for parsing templates
+ */
+export interface ParseOptions {
+  /** Whether to validate required fields (default: true) */
+  validateRequired?: boolean
+
+  /** Custom base path for resolving relative paths */
+  basePath?: string
+}
+
+// =============================================================================
+// Mapping Engine Interface
+// =============================================================================
+
+/**
+ * Overall conversion result for all platforms
+ */
+export interface ConversionResult {
+  /** Source template path */
+  sourcePath: string
+
+  /** Parsed template */
+  template: ParsedTemplate
+
+  /** Results per platform */
+  results: Map<Platform, TransformationResult>
+
+  /** All warnings across all platforms */
+  allWarnings: TransformationWarning[]
+
+  /** Whether all transformations succeeded */
+  success: boolean
+}
+
+/**
+ * Mapping engine interface
+ *
+ * The mapping engine orchestrates the full conversion pipeline:
+ * 1. Parse: YAML frontmatter + markdown -> ParsedTemplate
+ * 2. Validate: Check schema compliance, compatibility markers
+ * 3. Transform: Apply platform adapter rules
+ * 4. Emulate: Apply workaround patterns for missing features
+ * 5. Generate: Write platform-specific files
+ */
+export interface MappingEngine {
+  /**
+   * Parse a template file
+   * @param filePath Path to template file
+   * @param options Parse options
+   * @returns Parsed template
+   */
+  parse(filePath: string, options?: ParseOptions): Promise<ParsedTemplate>
+
+  /**
+   * Parse template from string content
+   * @param content Template content (YAML frontmatter + markdown)
+   * @param options Parse options
+   * @returns Parsed template
+   */
+  parseString(content: string, options?: ParseOptions): ParsedTemplate
+
+  /**
+   * Convert a template to all target platforms
+   * @param template Parsed template or path to template file
+   * @param options Conversion options
+   * @returns Conversion result with all platform outputs
+   */
+  convert(
+    template: ParsedTemplate | string,
+    options?: TransformOptions
+  ): Promise<ConversionResult>
+
+  /**
+   * Get the adapter for a specific platform
+   * @param platform Target platform
+   * @returns Platform adapter instance
+   */
+  getAdapter(platform: Platform): PlatformAdapter
+
+  /**
+   * Register a custom platform adapter
+   * @param adapter Platform adapter to register
+   */
+  registerAdapter(adapter: PlatformAdapter): void
+}
+
+// =============================================================================
+// Validation Types
+// =============================================================================
+
+/**
+ * Validation severity levels
+ */
+export type ValidationSeverity = 'error' | 'warning' | 'info'
+
+/**
+ * Validation issue
+ */
+export interface ValidationIssue {
+  severity: ValidationSeverity
+  message: string
+  field?: string
+  suggestion?: string
+}
+
+/**
+ * Schema validator interface
+ */
+export interface SchemaValidator {
+  /**
+   * Validate template metadata against the superset schema
+   * @param metadata Template metadata to validate
+   * @returns Array of validation issues
+   */
+  validate(metadata: TemplateMetadata): ValidationIssue[]
+
+  /**
+   * Check if metadata has all required fields for a platform
+   * @param metadata Template metadata
+   * @param platform Target platform
+   * @returns Array of missing required fields
+   */
+  checkRequired(metadata: TemplateMetadata, platform: Platform): string[]
+}
+
+// =============================================================================
+// Platform-Specific Output Types
+// =============================================================================
+
+/**
+ * Claude Code skill output structure
+ */
+export interface ClaudeCodeOutput {
+  skillPath: string            // .claude/skills/{name}/SKILL.md
+  settingsPath?: string        // .claude/settings.json (if permissions specified)
+  agentPath?: string          // .claude/agents/{name}.md (if agent specified)
+}
+
+/**
+ * Windsurf output structure
+ */
+export interface WindsurfOutput {
+  workflowPath: string         // .windsurf/workflows/{name}.md
+  personaRulePath?: string     // .windsurf/rules/agent-{name}.md (if agent specified)
+  permissionRulePath?: string  // .windsurf/rules/permissions-{name}.md (if permissions specified)
+}
+
+/**
+ * GitHub Copilot output structure
+ */
+export interface GitHubCopilotOutput {
+  promptPath: string           // .github/prompts/{name}.prompt.md
+  instructionsPath?: string    // .github/instructions/{name}.instructions.md (if applyTo specified)
+  copilotInstructionsPath?: string  // .github/copilot-instructions.md (if alwaysApply)
+}
+
+// =============================================================================
+// Constants
+// =============================================================================
+
+/**
+ * Platform-specific file size limits
+ */
+export const PLATFORM_LIMITS = {
+  windsurf: {
+    maxFileSize: 12000,        // 12,000 characters per file
+    maxWorkflowCount: 100,     // Practical limit
+  },
+  'github-copilot': {
+    maxWorkingSetFiles: 10,    // 10 files in working set
+    maxContextFiles: 20,       // 20 files in context
+    maxContextChars: 6000,     // ~6,000 character context window
+    maxLinesPerFile: 782,      // Quality degrades above this
+    maxLinesAbsolute: 6000,    // Absolute max lines per file
+  },
+  'claude-code': {
+    // Claude Code has generous limits
+    maxContextTokens: 200000,  // 200k token context
+  },
+} as const
+
+/**
+ * Valid tool names for Claude Code
+ */
+export const CLAUDE_CODE_TOOLS = [
+  'Bash',
+  'Read',
+  'Write',
+  'Edit',
+  'MultiEdit',
+  'Glob',
+  'Grep',
+  'Task',
+  'Skill',
+  'LSP',
+  'LS',
+  'WebFetch',
+  'WebSearch',
+  'NotebookRead',
+  'NotebookEdit',
+  'TodoRead',
+  'TodoWrite',
+  'MCPSearch',
+  'Computer',
+  'EnterPlanMode',
+  'ExitPlanMode',
+  'AskUserQuestion',
+] as const
+
+/**
+ * Valid trigger types for Windsurf
+ */
+export const WINDSURF_TRIGGERS = ['manual', 'always_on', 'model_decision', 'glob'] as const
+
+/**
+ * Valid modes for GitHub Copilot
+ */
+export const COPILOT_MODES = ['agent', 'ask', 'edit'] as const
+
+// =============================================================================
+// Phase 5: Semantic Content Types
+// =============================================================================
+
+/**
+ * Semantic construct types identified in workflow content
+ */
+export type SemanticConstructType =
+  | 'agent-spawn'
+  | 'tool-call'
+  | 'context-switch'
+  | 'permission-reference'
+  | 'model-decision-trigger'
+  | 'glob-pattern'
+  | 'persona-rule'
+  | 'skill-chaining'
+  | 'context-gathering-protocol'
+  | 'activation-instruction'
+  | 'working-set-limit'
+  | 'checkpoint-commit'
+  | 'progress-tracking'
+  | 'workspace-command'
+  | 'test-command'
+  | 'advisory-warning'
+  | 'version-comment'
+  | 'execution-flow-section'
+
+/**
+ * Location information for a semantic construct
+ */
+export interface ConstructLocation {
+  /** Character offset from start of content */
+  start: number
+  /** Character offset of end of match */
+  end: number
+  /** Line number (1-indexed) */
+  line: number
+}
+
+/**
+ * Semantic construct identified in workflow content
+ */
+export interface SemanticConstruct {
+  /** Type of semantic construct */
+  type: SemanticConstructType
+  /** Source platform that uses this syntax */
+  platform: Platform
+  /** Where construct was found (frontmatter or body) */
+  source: 'frontmatter' | 'body'
+  /** Location in content */
+  location: ConstructLocation
+  /** Original matched text */
+  rawText: string
+  /** Extracted data from the match */
+  parsed: Record<string, unknown>
+}
+
+/**
+ * Result of parsing content for semantic constructs
+ */
+export interface ContentAnalysis {
+  /** All semantic constructs found */
+  constructs: SemanticConstruct[]
+  /** Original raw content */
+  rawContent: string
+}
+
+// =============================================================================
+// Phase 5: Content Transformer Types
+// =============================================================================
+
+/**
+ * Content transformer interface for platform-specific content rewriting
+ */
+export interface ContentTransformer {
+  platform: Platform
+  transform(analysis: ContentAnalysis, content: string): TransformedContent
+}
+
+/**
+ * Result of content transformation
+ */
+export interface TransformedContent {
+  content: string
+  warnings: TransformationWarning[]
+}
diff --git a/packages/cli/src/lib/watch-templates.ts b/packages/cli/src/lib/watch-templates.ts
new file mode 100644
index 0000000..725ddb9
--- /dev/null
+++ b/packages/cli/src/lib/watch-templates.ts
@@ -0,0 +1,83 @@
+#!/usr/bin/env node
+/**
+ * Watch templates directory and copy changes to dist.
+ * Used for development workflow to auto-sync template changes.
+ */
+
+import {watch} from 'chokidar'
+import {copyFile, mkdir} from 'node:fs/promises'
+import {dirname, join, relative} from 'node:path'
+import {fileURLToPath} from 'node:url'
+
+const __dirname = dirname(fileURLToPath(import.meta.url))
+const SRC_TEMPLATES = join(__dirname, '..', 'templates')
+const DIST_TEMPLATES = join(__dirname, '..', '..', 'dist', 'templates')
+
+/**
+ * Copy a file from src/templates to dist/templates preserving structure.
+ */
+async function copyTemplate(filePath: string): Promise<void> {
+  const relativePath = relative(SRC_TEMPLATES, filePath)
+  const destPath = join(DIST_TEMPLATES, relativePath)
+
+  try {
+    await mkdir(dirname(destPath), {recursive: true})
+    await copyFile(filePath, destPath)
+    logChange('copied', relativePath)
+  } catch (error) {
+    logError(`Failed to copy ${relativePath}`, error)
+  }
+}
+
+/**
+ * Log a change with timestamp.
+ */
+function logChange(action: string, path: string): void {
+  const timestamp = new Date().toLocaleTimeString()
+  const supportsColor = process.stdout.isTTY
+  if (supportsColor) {
+    console.log(`\u001B[2m[${timestamp}]\u001B[0m \u001B[32m${action}\u001B[0m ${path}`)
+  } else {
+    console.log(`[${timestamp}] ${action} ${path}`)
+  }
+}
+
+/**
+ * Log an error.
+ */
+function logError(message: string, error: unknown): void {
+  const timestamp = new Date().toLocaleTimeString()
+  console.error(`[${timestamp}] \u001B[31merror\u001B[0m ${message}:`, error)
+}
+
+/**
+ * Start watching templates directory.
+ */
+function startWatching(): void {
+  console.log('Watching templates for changes...')
+  console.log(`  Source: ${SRC_TEMPLATES}`)
+  console.log(`  Dest:   ${DIST_TEMPLATES}`)
+  console.log('')
+
+  const watcher = watch(SRC_TEMPLATES, {
+    ignoreInitial: true,
+    persistent: true,
+  })
+
+  watcher.on('add', copyTemplate)
+  watcher.on('change', copyTemplate)
+  watcher.on('error', (error) => logError('Watcher error', error))
+
+  // Handle graceful shutdown
+  process.on('SIGINT', () => {
+    console.log('\nStopping template watcher...')
+    watcher.close().then(() => process.exit(0))
+  })
+
+  process.on('SIGTERM', () => {
+    watcher.close().then(() => process.exit(0))
+  })
+}
+
+// Run if executed directly
+startWatching()
diff --git a/packages/cli/test/lib/template-mapper/adapters/claude-code.test.ts b/packages/cli/test/lib/template-mapper/adapters/claude-code.test.ts
new file mode 100644
index 0000000..2e315db
--- /dev/null
+++ b/packages/cli/test/lib/template-mapper/adapters/claude-code.test.ts
@@ -0,0 +1,301 @@
+import {expect} from 'chai'
+import {describe, it} from 'mocha'
+
+import {ClaudeCodeAdapter} from '../../../../src/lib/template-mapper/adapters/claude-code.js'
+import type {ParsedTemplate} from '../../../../src/lib/template-mapper/types.js'
+
+describe('Claude Code Adapter', () => {
+  const adapter = new ClaudeCodeAdapter()
+
+  describe('platform', () => {
+    it('should report claude-code as platform', () => {
+      expect(adapter.platform).to.equal('claude-code')
+    })
+  })
+
+  describe('getOutputPath', () => {
+    it('should generate correct skill path', () => {
+      const template: ParsedTemplate = {
+        metadata: {name: 'test-skill'},
+        content: 'Test content',
+      }
+
+      const path = adapter.getOutputPath(template)
+
+      expect(path).to.equal('.claude/skills/test-skill/SKILL.md')
+    })
+
+    it('should handle missing name with fallback', () => {
+      const template: ParsedTemplate = {
+        metadata: {},
+        content: 'Test content',
+      }
+
+      const path = adapter.getOutputPath(template)
+
+      expect(path).to.equal('.claude/skills/unnamed-skill/SKILL.md')
+    })
+  })
+
+  describe('validate', () => {
+    it('should warn when name is missing', () => {
+      const template: ParsedTemplate = {
+        metadata: {description: 'No name'},
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) => w.field === 'name')).to.be.true
+    })
+
+    it('should warn about dropped Windsurf fields', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'test',
+          trigger: 'model_decision',
+          globs: ['*.ts'],
+          labels: ['test'],
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) => w.field === 'trigger')).to.be.true
+      expect(warnings.some((w) => w.field === 'globs')).to.be.true
+      expect(warnings.some((w) => w.field === 'labels')).to.be.true
+    })
+
+    it('should warn about dropped Copilot fields', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'test',
+          applyTo: ['**/*.ts'],
+          excludeAgent: ['code-review'],
+          mode: 'agent',
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) => w.field === 'applyTo')).to.be.true
+      expect(warnings.some((w) => w.field === 'excludeAgent')).to.be.true
+      expect(warnings.some((w) => w.field === 'mode')).to.be.true
+    })
+
+    it('should warn about unknown model', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'test',
+          model: 'unknown-model',
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) => w.field === 'model' && w.category === 'DEGRADED')).to.be.true
+    })
+
+    it('should accept valid models', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'test',
+          model: 'opus',
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) => w.field === 'model' && w.category === 'DEGRADED')).to.be.false
+    })
+
+    it('should warn about project-scoped permissions', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'test',
+          permissions: {
+            allow: ['Read(**)'],
+          },
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) => w.field === 'permissions' && w.category === 'SECURITY')).to.be.true
+    })
+  })
+
+  describe('transform', () => {
+    it('should generate SKILL.md with correct structure', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'my-skill',
+          description: 'A test skill',
+          version: '1.0.0',
+        },
+        content: '# My Skill\n\nDo something useful.',
+      }
+
+      const result = adapter.transform(template)
+
+      expect(result.success).to.be.true
+      expect(result.files.has('.claude/skills/my-skill/SKILL.md')).to.be.true
+
+      const content = result.files.get('.claude/skills/my-skill/SKILL.md')!
+      expect(content).to.include('---')
+      expect(content).to.include('name: my-skill')
+      expect(content).to.include('description: A test skill')
+      expect(content).to.include('version: "1.0.0"')
+      expect(content).to.include('# My Skill')
+      expect(content).to.include('Do something useful.')
+    })
+
+    it('should include allowed-tools in frontmatter', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'tool-skill',
+          'allowed-tools': ['Read', 'Write', 'Bash(git *)'],
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.claude/skills/tool-skill/SKILL.md')!
+
+      expect(content).to.include('allowed-tools:')
+      expect(content).to.include('- Read')
+      expect(content).to.include('- Write')
+      expect(content).to.include('- Bash(git *)')
+    })
+
+    it('should include model and context fields', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'config-skill',
+          model: 'opus',
+          context: 'fork',
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.claude/skills/config-skill/SKILL.md')!
+
+      expect(content).to.include('model: opus')
+      expect(content).to.include('context: fork')
+    })
+
+    it('should include agent reference', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'agent-skill',
+          agent: 'custom-reviewer',
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.claude/skills/agent-skill/SKILL.md')!
+
+      expect(content).to.include('agent: custom-reviewer')
+      expect(result.warnings.some((w) => w.message.includes('agent: custom-reviewer'))).to.be.true
+    })
+
+    it('should generate settings.json when permissions specified', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'secure-skill',
+          permissions: {
+            allow: ['Read(**/*.ts)', 'Write(src/**)'],
+            deny: ['Read(.env)'],
+          },
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+
+      expect(result.files.has('.claude/settings.json')).to.be.true
+
+      const settings = JSON.parse(result.files.get('.claude/settings.json')!)
+      expect(settings.permissions.allow).to.deep.equal(['Read(**/*.ts)', 'Write(src/**)'])
+      expect(settings.permissions.deny).to.deep.equal(['Read(.env)'])
+    })
+
+    it('should not generate settings.json when no permissions', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'simple-skill',
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+
+      expect(result.files.has('.claude/settings.json')).to.be.false
+    })
+
+    it('should fail when name is missing', () => {
+      const template: ParsedTemplate = {
+        metadata: {description: 'No name'},
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+
+      expect(result.success).to.be.false
+      expect(result.error).to.include('missing required fields')
+    })
+
+    it('should drop Windsurf/Copilot fields from output', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'cross-platform',
+          description: 'Test',
+          trigger: 'model_decision',
+          globs: ['*.ts'],
+          applyTo: ['**/*.ts'],
+          mode: 'agent',
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.claude/skills/cross-platform/SKILL.md')!
+
+      // Should not include dropped fields
+      expect(content).to.not.include('trigger:')
+      expect(content).to.not.include('globs:')
+      expect(content).to.not.include('applyTo:')
+      expect(content).to.not.include('mode:')
+
+      // Should include native fields
+      expect(content).to.include('name: cross-platform')
+      expect(content).to.include('description: Test')
+    })
+
+    it('should include optional Claude Code fields', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'full-skill',
+          'disable-model-invocation': true,
+          'argument-hint': '<file-path> [options]',
+          language: 'japanese',
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.claude/skills/full-skill/SKILL.md')!
+
+      expect(content).to.include('disable-model-invocation: true')
+      expect(content).to.include('argument-hint: "<file-path> [options]"')
+      expect(content).to.include('language: japanese')
+    })
+  })
+})
diff --git a/packages/cli/test/lib/template-mapper/adapters/windsurf.test.ts b/packages/cli/test/lib/template-mapper/adapters/windsurf.test.ts
new file mode 100644
index 0000000..e64042c
--- /dev/null
+++ b/packages/cli/test/lib/template-mapper/adapters/windsurf.test.ts
@@ -0,0 +1,353 @@
+import {expect} from 'chai'
+import {describe, it} from 'mocha'
+
+import {WindsurfAdapter} from '../../../../src/lib/template-mapper/adapters/windsurf.js'
+import type {ParsedTemplate} from '../../../../src/lib/template-mapper/types.js'
+
+describe('Windsurf Adapter', () => {
+  const adapter = new WindsurfAdapter()
+
+  describe('platform', () => {
+    it('should report windsurf as platform', () => {
+      expect(adapter.platform).to.equal('windsurf')
+    })
+  })
+
+  describe('getOutputPath', () => {
+    it('should generate correct workflow path', () => {
+      const template: ParsedTemplate = {
+        metadata: {name: 'test-workflow'},
+        content: 'Test content',
+      }
+
+      const path = adapter.getOutputPath(template)
+
+      expect(path).to.equal('.windsurf/workflows/test-workflow.md')
+    })
+
+    it('should handle missing name with fallback', () => {
+      const template: ParsedTemplate = {
+        metadata: {},
+        content: 'Test content',
+      }
+
+      const path = adapter.getOutputPath(template)
+
+      expect(path).to.equal('.windsurf/workflows/unnamed-workflow.md')
+    })
+  })
+
+  describe('validate', () => {
+    it('should warn when description is missing', () => {
+      const template: ParsedTemplate = {
+        metadata: {name: 'no-desc'},
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) => w.field === 'description')).to.be.true
+    })
+
+    it('should warn about emulated allowed-tools', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          description: 'test',
+          'allowed-tools': ['Read', 'Write'],
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) =>
+        w.field === 'allowed-tools' && w.category === 'EMULATED',
+      )).to.be.true
+    })
+
+    it('should warn about emulated context: fork', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          description: 'test',
+          context: 'fork',
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) =>
+        w.field === 'context' && w.category === 'EMULATED',
+      )).to.be.true
+    })
+
+    it('should warn about emulated agent', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          description: 'test',
+          agent: 'custom-agent',
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) =>
+        w.field === 'agent' && w.category === 'EMULATED',
+      )).to.be.true
+    })
+
+    it('should warn about advisory permissions', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          description: 'test',
+          permissions: {
+            deny: ['Read(.env)'],
+          },
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) =>
+        w.field === 'permissions' && w.category === 'SECURITY',
+      )).to.be.true
+    })
+
+    it('should warn about dropped model field', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          description: 'test',
+          model: 'opus',
+        },
+        content: 'Content',
+      }
+
+      const warnings = adapter.validate(template)
+
+      expect(warnings.some((w) =>
+        w.field === 'model' && w.category === 'UNSUPPORTED',
+      )).to.be.true
+    })
+  })
+
+  describe('transform', () => {
+    it('should generate workflow file with correct structure', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'my-workflow',
+          description: 'A test workflow',
+          version: '1.0.0',
+        },
+        content: '# My Workflow\n\nDo something useful.',
+      }
+
+      const result = adapter.transform(template)
+
+      expect(result.success).to.be.true
+      expect(result.files.has('.windsurf/workflows/my-workflow.md')).to.be.true
+
+      const content = result.files.get('.windsurf/workflows/my-workflow.md')!
+      expect(content).to.include('---')
+      expect(content).to.include('description: A test workflow')
+      expect(content).to.include('trigger: model_decision')
+      expect(content).to.include('<!-- Version: 1.0.0 -->')
+      expect(content).to.include('# My Workflow')
+    })
+
+    it('should include native Windsurf fields', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          description: 'Test',
+          trigger: 'glob',
+          globs: ['**/*.ts', '**/*.tsx'],
+          labels: ['typescript', 'refactoring'],
+          author: 'Test Author',
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.windsurf/workflows/unnamed-workflow.md')!
+
+      expect(content).to.include('trigger: glob')
+      expect(content).to.include('globs:')
+      expect(content).to.include('"**/*.ts"')
+      expect(content).to.include('labels:')
+      expect(content).to.include('- typescript')
+      expect(content).to.include('author: "Test Author"')
+    })
+
+    it('should generate tool restrictions section for allowed-tools', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'restricted-workflow',
+          description: 'Restricted workflow',
+          'allowed-tools': ['Read', 'Grep', 'Bash(git *)'],
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.windsurf/workflows/restricted-workflow.md')!
+
+      expect(content).to.include('## Tool Restrictions (Advisory)')
+      expect(content).to.include('NOT enforced by Windsurf')
+      expect(content).to.include('Read files')
+      expect(content).to.include('Shell commands: `git *`')
+    })
+
+    it('should generate context isolation markers for fork', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'isolated-workflow',
+          description: 'Isolated workflow',
+          context: 'fork',
+        },
+        content: '## Steps\n\n1. Do something',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.windsurf/workflows/isolated-workflow.md')!
+
+      expect(content).to.include('[CONTEXT: Isolated Execution')
+      expect(content).to.include('[END CONTEXT: Return to normal session]')
+    })
+
+    it('should generate agent persona rule file', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'agent-workflow',
+          description: 'Workflow with agent',
+          agent: 'security-reviewer',
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+
+      // Should have main workflow
+      expect(result.files.has('.windsurf/workflows/agent-workflow.md')).to.be.true
+
+      // Should have agent rule file
+      expect(result.files.has('.windsurf/rules/agent-security-reviewer.md')).to.be.true
+
+      const agentRule = result.files.get('.windsurf/rules/agent-security-reviewer.md')!
+      expect(agentRule).to.include('trigger: manual')
+      expect(agentRule).to.include('Security Reviewer Persona')
+      expect(agentRule).to.include('@rules:agent-security-reviewer')
+    })
+
+    it('should generate permissions warning rule file', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'secure-workflow',
+          description: 'Secure workflow',
+          permissions: {
+            deny: ['Read(.env)', 'Write(secrets/**)'],
+          },
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+
+      // Should have main workflow
+      expect(result.files.has('.windsurf/workflows/secure-workflow.md')).to.be.true
+
+      // Should have permissions rule file
+      expect(result.files.has('.windsurf/rules/permissions-secure-workflow.md')).to.be.true
+
+      const permsRule = result.files.get('.windsurf/rules/permissions-secure-workflow.md')!
+      expect(permsRule).to.include('trigger: glob')
+      expect(permsRule).to.include('.env')
+      expect(permsRule).to.include('SECURITY WARNING')
+    })
+
+    it('should include compatibility notes', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'compat-workflow',
+          description: 'Test',
+          compatibility: {
+            windsurf: {
+              status: 'partial',
+              notes: 'Subagent spawning not supported',
+            },
+          },
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.windsurf/workflows/compat-workflow.md')!
+
+      expect(content).to.include('## Platform Compatibility Note')
+      expect(content).to.include('partial support')
+      expect(content).to.include('Subagent spawning not supported')
+    })
+
+    it('should generate agent reference in main workflow', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'ref-workflow',
+          description: 'Test',
+          agent: 'code-reviewer',
+        },
+        content: 'Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.windsurf/workflows/ref-workflow.md')!
+
+      expect(content).to.include('## Agent Persona')
+      expect(content).to.include('**code-reviewer**')
+      expect(content).to.include('@rules:agent-code-reviewer')
+    })
+
+    it('should warn about character limit when exceeded', () => {
+      // Create a large template
+      const largeContent = 'X'.repeat(15000)
+      const template: ParsedTemplate = {
+        metadata: {
+          description: 'Large workflow',
+        },
+        content: largeContent,
+      }
+
+      const result = adapter.transform(template)
+
+      expect(result.warnings.some((w) =>
+        w.category === 'LIMIT' && w.message.includes('12000 character limit'),
+      )).to.be.true
+    })
+
+    it('should convert hooks to manual workflow steps', () => {
+      const template: ParsedTemplate = {
+        metadata: {
+          name: 'hooks-workflow',
+          description: 'Test',
+          hooks: {
+            PreToolUse: [{
+              matcher: 'Write|Edit',
+              hooks: [{type: 'command', command: 'npm run lint'}],
+            }],
+            Stop: [{
+              hooks: [{type: 'command', command: 'npm test'}],
+            }],
+          },
+        },
+        content: '## Main Content',
+      }
+
+      const result = adapter.transform(template)
+      const content = result.files.get('.windsurf/workflows/hooks-workflow.md')!
+
+      expect(content).to.include('## Pre-Execution Checks')
+      expect(content).to.include('npm run lint')
+      expect(content).to.include('## Post-Execution Validation')
+      expect(content).to.include('npm test')
+    })
+  })
+})
diff --git a/packages/cli/test/lib/template-mapper/content-parser.test.ts b/packages/cli/test/lib/template-mapper/content-parser.test.ts
new file mode 100644
index 0000000..8918da3
--- /dev/null
+++ b/packages/cli/test/lib/template-mapper/content-parser.test.ts
@@ -0,0 +1,811 @@
+import {expect} from 'chai'
+import {describe, it} from 'mocha'
+
+import {
+  parseContent,
+  hasSemanticConstructs,
+  getConstructsByPlatform,
+  getConstructsByType,
+  getConstructTypes,
+  getSourcePlatform,
+} from '../../../src/lib/template-mapper/content-parser.js'
+
+describe('Content Parser', () => {
+  describe('parseContent', () => {
+    it('should return empty constructs for plain markdown', () => {
+      const content = `# Simple Heading
+
+This is just regular markdown content without any platform-specific constructs.
+
+- List item 1
+- List item 2
+
+Some more text here.`
+
+      const analysis = parseContent(content)
+
+      expect(analysis.rawContent).to.equal(content)
+      // May have some matches for generic patterns like "progress" in some edge cases
+      // The important thing is no false positives for specific platform syntax
+    })
+
+    it('should detect multiple construct types in content', () => {
+      const content = `Use the Glob tool to find files.
+When tests pass, spawn a new agent to verify.
+This workflow activates automatically when user mentions "optimize".`
+
+      const analysis = parseContent(content)
+
+      expect(analysis.constructs.length).to.be.greaterThan(0)
+
+      const types = analysis.constructs.map((c) => c.type)
+      expect(types).to.include('tool-call')
+      expect(types).to.include('agent-spawn')
+    })
+
+    it('should skip constructs inside fenced code blocks', () => {
+      const content = `Here is some code:
+
+\`\`\`typescript
+// Use the Glob tool here
+const result = await Glob('**/*.ts')
+spawn agent task
+\`\`\`
+
+Regular text after code block.`
+
+      const analysis = parseContent(content)
+
+      // Should not detect tool-call or agent-spawn from inside code block
+      const toolCalls = analysis.constructs.filter((c) => c.type === 'tool-call')
+      const agentSpawns = analysis.constructs.filter((c) => c.type === 'agent-spawn')
+
+      // No matches should come from inside the code block
+      for (const tc of toolCalls) {
+        expect(tc.location.start).to.not.be.within(
+          content.indexOf('```typescript'),
+          content.lastIndexOf('```'),
+        )
+      }
+      for (const as of agentSpawns) {
+        expect(as.location.start).to.not.be.within(
+          content.indexOf('```typescript'),
+          content.lastIndexOf('```'),
+        )
+      }
+    })
+
+    it('should skip constructs inside inline code', () => {
+      const content = `You can run \`npm test\` to verify.
+The \`Task tool\` is used internally.
+Regular npm test command here.`
+
+      const analysis = parseContent(content)
+
+      // Should detect the "Regular npm test" but not the ones in inline code
+      const testCommands = analysis.constructs.filter((c) => c.type === 'test-command')
+
+      // Verify we get the one outside inline code
+      const outsideCodeMatch = testCommands.find((c) => c.rawText === 'npm test')
+      expect(outsideCodeMatch).to.exist
+    })
+
+    it('should track correct line numbers', () => {
+      const content = `Line 1
+Line 2
+Use the Glob tool here.
+Line 4`
+
+      const analysis = parseContent(content)
+
+      const toolCall = analysis.constructs.find((c) => c.type === 'tool-call')
+      expect(toolCall).to.exist
+      if (toolCall) {
+        expect(toolCall.location.line).to.equal(3)
+      }
+    })
+
+    it('should sort constructs by position', () => {
+      const content = `npm test first.
+Then spawn agent.
+Finally use Glob tool.`
+
+      const analysis = parseContent(content)
+
+      for (let i = 1; i < analysis.constructs.length; i++) {
+        const current = analysis.constructs[i]
+        const previous = analysis.constructs[i - 1]
+        if (current && previous) {
+          expect(current.location.start).to.be.at.least(previous.location.start)
+        }
+      }
+    })
+  })
+
+  describe('Agent Spawning Detection', () => {
+    it('should detect "spawn agent" pattern', () => {
+      const content = 'You can spawn a new agent to handle this task.'
+      const analysis = parseContent(content)
+
+      const spawns = analysis.constructs.filter((c) => c.type === 'agent-spawn')
+      expect(spawns.length).to.be.greaterThan(0)
+      expect(spawns[0]?.parsed?.mechanism).to.equal('spawn')
+    })
+
+    it('should detect Task tool reference', () => {
+      // Task tool reference detected as tool-call since "Use the Task tool" is a tool call pattern
+      // The subagent reference is detected as agent-spawn
+      const content = 'Use the Task tool to delegate work to a subagent.'
+      const analysis = parseContent(content)
+
+      const toolCalls = analysis.constructs.filter((c) => c.type === 'tool-call')
+      const spawns = analysis.constructs.filter((c) => c.type === 'agent-spawn')
+      expect(toolCalls.length).to.be.greaterThan(0)
+      expect(toolCalls[0]?.parsed?.toolName).to.equal('Task')
+      expect(spawns.length).to.be.greaterThan(0) // subagent is detected as agent-spawn
+    })
+
+    it('should detect context: fork pattern as context-switch', () => {
+      // context: fork is now detected as context-switch, not agent-spawn
+      const content = 'This skill uses context: fork for isolation.'
+      const analysis = parseContent(content)
+
+      const switches = analysis.constructs.filter((c) => c.type === 'context-switch')
+      expect(switches.length).to.be.greaterThan(0)
+      expect(switches[0]?.parsed?.contextType).to.equal('fork')
+    })
+
+    it('should detect subagent reference', () => {
+      const content = 'The subagent will handle security review.'
+      const analysis = parseContent(content)
+
+      const spawns = analysis.constructs.filter((c) => c.type === 'agent-spawn')
+      expect(spawns.length).to.be.greaterThan(0)
+    })
+
+    it('should detect parallel agent pattern', () => {
+      const content = 'Run parallel agent for concurrent processing.'
+      const analysis = parseContent(content)
+
+      const spawns = analysis.constructs.filter((c) => c.type === 'agent-spawn')
+      expect(spawns.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Tool Call Detection', () => {
+    it('should detect "use X tool" pattern', () => {
+      const content = 'Use the Read tool to view file contents.'
+      const analysis = parseContent(content)
+
+      const toolCalls = analysis.constructs.filter((c) => c.type === 'tool-call')
+      expect(toolCalls.length).to.be.greaterThan(0)
+      expect(toolCalls[0]?.parsed?.toolName).to.equal('Read')
+    })
+
+    it('should detect various tool names', () => {
+      const tools = ['Read', 'Write', 'Edit', 'Grep', 'Glob', 'Bash', 'Task', 'WebFetch', 'WebSearch']
+
+      for (const tool of tools) {
+        const content = `Use the ${tool} tool here.`
+        const analysis = parseContent(content)
+
+        const toolCalls = analysis.constructs.filter((c) => c.type === 'tool-call')
+        expect(toolCalls.length, `Should detect ${tool} tool`).to.be.greaterThan(0)
+      }
+    })
+
+    it('should detect tool function call syntax', () => {
+      const content = 'Call Glob("**/*.ts") to find TypeScript files.'
+      const analysis = parseContent(content)
+
+      const toolCalls = analysis.constructs.filter((c) => c.type === 'tool-call')
+      expect(toolCalls.length).to.be.greaterThan(0)
+      expect(toolCalls[0]?.parsed?.toolName).to.equal('Glob')
+    })
+  })
+
+  describe('Context Switch Detection', () => {
+    it('should detect context: fork', () => {
+      const content = 'This skill uses context: fork for isolation.'
+      const analysis = parseContent(content)
+
+      const switches = analysis.constructs.filter((c) => c.type === 'context-switch')
+      expect(switches.length).to.be.greaterThan(0)
+      expect(switches[0]?.parsed?.contextType).to.equal('fork')
+    })
+
+    it('should detect context: inherit', () => {
+      const content = 'Using context: inherit to share state.'
+      const analysis = parseContent(content)
+
+      const switches = analysis.constructs.filter((c) => c.type === 'context-switch')
+      expect(switches.length).to.be.greaterThan(0)
+      expect(switches[0]?.parsed?.contextType).to.equal('inherit')
+    })
+
+    it('should detect isolated context reference', () => {
+      const content = 'Run in an isolated context for safety.'
+      const analysis = parseContent(content)
+
+      const switches = analysis.constructs.filter((c) => c.type === 'context-switch')
+      expect(switches.length).to.be.greaterThan(0)
+    })
+
+    it('should detect fresh/clean context patterns', () => {
+      const content = 'Start with a fresh context for this task.'
+      const analysis = parseContent(content)
+
+      const switches = analysis.constructs.filter((c) => c.type === 'context-switch')
+      expect(switches.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Permission Reference Detection', () => {
+    it('should detect allowed-tools reference', () => {
+      const content = 'Set allowed-tools to restrict operations.'
+      const analysis = parseContent(content)
+
+      const perms = analysis.constructs.filter((c) => c.type === 'permission-reference')
+      expect(perms.length).to.be.greaterThan(0)
+      expect(perms[0]?.parsed?.isAllow).to.be.true
+    })
+
+    it('should detect advisory restriction warning', () => {
+      const content = 'NOTE: These rely on AI compliance and cannot be enforced.'
+      const analysis = parseContent(content)
+
+      const perms = analysis.constructs.filter((c) => c.type === 'permission-reference')
+      expect(perms.length).to.be.greaterThan(0)
+      expect(perms[0]?.parsed?.isAdvisory).to.be.true
+    })
+
+    it('should detect forbidden operations', () => {
+      const content = 'forbidden operations include file deletion.'
+      const analysis = parseContent(content)
+
+      const perms = analysis.constructs.filter((c) => c.type === 'permission-reference')
+      expect(perms.length).to.be.greaterThan(0)
+      expect(perms[0]?.parsed?.isDeny).to.be.true
+    })
+  })
+
+  describe('Model Decision Trigger Detection', () => {
+    it('should detect USE WHEN pattern', () => {
+      const content = 'USE WHEN creating git commits.'
+      const analysis = parseContent(content)
+
+      const triggers = analysis.constructs.filter((c) => c.type === 'model-decision-trigger')
+      expect(triggers.length).to.be.greaterThan(0)
+      expect(triggers[0]?.parsed?.hasUseWhen).to.be.true
+    })
+
+    it('should detect trigger: model_decision', () => {
+      const content = 'Set trigger: model_decision in frontmatter.'
+      const analysis = parseContent(content)
+
+      const triggers = analysis.constructs.filter((c) => c.type === 'model-decision-trigger')
+      expect(triggers.length).to.be.greaterThan(0)
+      expect(triggers[0]?.parsed?.hasTriggerField).to.be.true
+    })
+
+    it('should detect auto-activation patterns', () => {
+      const content = 'This workflow activates automatically when needed.'
+      const analysis = parseContent(content)
+
+      const triggers = analysis.constructs.filter((c) => c.type === 'model-decision-trigger')
+      expect(triggers.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Glob Pattern Detection', () => {
+    it('should detect globs: array syntax', () => {
+      const content = 'Set globs: ["src/**/*.ts"] for context.'
+      const analysis = parseContent(content)
+
+      const globs = analysis.constructs.filter((c) => c.type === 'glob-pattern')
+      expect(globs.length).to.be.greaterThan(0)
+    })
+
+    it('should detect glob patterns in content', () => {
+      const content = 'Find all files matching the glob pattern **/*.tsx in components.'
+      const analysis = parseContent(content)
+
+      const globs = analysis.constructs.filter((c) => c.type === 'glob-pattern')
+      expect(globs.length).to.be.greaterThan(0)
+      // Glob pattern detection captures the syntax, parsed data extraction is separate
+    })
+
+    it('should detect src/** pattern', () => {
+      const content = 'Search src/**/utils for helper functions.'
+      const analysis = parseContent(content)
+
+      const globs = analysis.constructs.filter((c) => c.type === 'glob-pattern')
+      expect(globs.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Persona Rule Detection', () => {
+    it('should detect @rules:agent- pattern', () => {
+      const content = 'Activate the persona with @rules:agent-security-specialist first.'
+      const analysis = parseContent(content)
+
+      const personas = analysis.constructs.filter((c) => c.type === 'persona-rule')
+      expect(personas.length).to.be.greaterThan(0)
+      expect(personas[0]?.parsed?.personaName).to.equal('security-specialist')
+    })
+
+    it('should detect specialized agent reference', () => {
+      const content = 'Use a specialized agent for this task.'
+      const analysis = parseContent(content)
+
+      const personas = analysis.constructs.filter((c) => c.type === 'persona-rule')
+      expect(personas.length).to.be.greaterThan(0)
+    })
+
+    it('should detect custom agent pattern', () => {
+      const content = 'Create a custom agent for code review.'
+      const analysis = parseContent(content)
+
+      const personas = analysis.constructs.filter((c) => c.type === 'persona-rule')
+      expect(personas.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Skill Chaining Detection', () => {
+    it('should detect Part X of Y pattern', () => {
+      const content = 'Part 1 of 4: Core Authentication Module'
+      const analysis = parseContent(content)
+
+      const chains = analysis.constructs.filter((c) => c.type === 'skill-chaining')
+      expect(chains.length).to.be.greaterThan(0)
+      expect(chains[0]?.parsed?.currentPart).to.equal(1)
+      expect(chains[0]?.parsed?.totalParts).to.equal(4)
+    })
+
+    it('should detect /prompt skill-name pattern', () => {
+      const content = `Proceed with the next step:
+/prompt refactor-auth`
+      const analysis = parseContent(content)
+
+      const chains = analysis.constructs.filter((c) => c.type === 'skill-chaining')
+      expect(chains.length).to.be.greaterThan(0)
+      expect(chains[0]?.parsed?.skillName).to.equal('prompt')
+    })
+
+    it('should detect Proceed to Part X', () => {
+      const content = 'When done, Proceed to Part 2.'
+      const analysis = parseContent(content)
+
+      const chains = analysis.constructs.filter((c) => c.type === 'skill-chaining')
+      expect(chains.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Context Gathering Protocol Detection', () => {
+    it('should detect Step 0 pattern', () => {
+      const content = 'Step 0: Gather file context before analysis.'
+      const analysis = parseContent(content)
+
+      const protocols = analysis.constructs.filter((c) => c.type === 'context-gathering-protocol')
+      expect(protocols.length).to.be.greaterThan(0)
+      expect(protocols[0]?.parsed?.hasStep0).to.be.true
+    })
+
+    it('should detect Context Gathering Protocol header', () => {
+      const content = '### Context Gathering Protocol\n\nGather files first.'
+      const analysis = parseContent(content)
+
+      const protocols = analysis.constructs.filter((c) => c.type === 'context-gathering-protocol')
+      expect(protocols.length).to.be.greaterThan(0)
+    })
+
+    it('should detect Context Checklist', () => {
+      const content = 'Context Checklist:\n- [ ] All API routes identified'
+      const analysis = parseContent(content)
+
+      const protocols = analysis.constructs.filter((c) => c.type === 'context-gathering-protocol')
+      expect(protocols.length).to.be.greaterThan(0)
+      expect(protocols[0]?.parsed?.hasChecklist).to.be.true
+    })
+  })
+
+  describe('Activation Instruction Detection', () => {
+    it('should detect Manual invocation pattern', () => {
+      const content = 'Manual invocation: /commit-helper'
+      const analysis = parseContent(content)
+
+      const activations = analysis.constructs.filter((c) => c.type === 'activation-instruction')
+      expect(activations.length).to.be.greaterThan(0)
+      expect(activations[0]?.parsed?.isManual).to.be.true
+    })
+
+    it('should detect When to invoke section', () => {
+      const content = 'When to invoke: Use when user mentions "optimize".'
+      const analysis = parseContent(content)
+
+      const activations = analysis.constructs.filter((c) => c.type === 'activation-instruction')
+      expect(activations.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Working Set Limit Detection', () => {
+    it('should detect 10-file limit reference', () => {
+      const content = 'GitHub Copilot has a 10-file limit.'
+      const analysis = parseContent(content)
+
+      const limits = analysis.constructs.filter((c) => c.type === 'working-set-limit')
+      expect(limits.length).to.be.greaterThan(0)
+      expect(limits[0]?.parsed?.fileLimit).to.equal(10)
+    })
+
+    it('should detect working set reference', () => {
+      const content = 'Add files to the working set for analysis.'
+      const analysis = parseContent(content)
+
+      const limits = analysis.constructs.filter((c) => c.type === 'working-set-limit')
+      expect(limits.length).to.be.greaterThan(0)
+    })
+
+    it('should detect batch files pattern', () => {
+      const content = 'Process files in batch of 10 to avoid exceeds limit.'
+      const analysis = parseContent(content)
+
+      const limits = analysis.constructs.filter((c) => c.type === 'working-set-limit')
+      expect(limits.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Checkpoint Commit Detection', () => {
+    it('should detect Checkpoint: pattern', () => {
+      const content = 'Checkpoint: Create commit before next phase.'
+      const analysis = parseContent(content)
+
+      const checkpoints = analysis.constructs.filter((c) => c.type === 'checkpoint-commit')
+      expect(checkpoints.length).to.be.greaterThan(0)
+    })
+
+    it('should detect rollback plan reference', () => {
+      const content = 'Rollback plan: Revert to checkpoint if needed.'
+      const analysis = parseContent(content)
+
+      const checkpoints = analysis.constructs.filter((c) => c.type === 'checkpoint-commit')
+      expect(checkpoints.length).to.be.greaterThan(0)
+      expect(checkpoints[0]?.parsed?.hasRollbackPlan).to.be.true
+    })
+
+    it('should detect Step N: Checkpoint pattern', () => {
+      const content = 'Step 5: Checkpoint commit for phase 1.'
+      const analysis = parseContent(content)
+
+      const checkpoints = analysis.constructs.filter((c) => c.type === 'checkpoint-commit')
+      expect(checkpoints.length).to.be.greaterThan(0)
+      expect(checkpoints[0]?.parsed?.hasStepNumber).to.be.true
+    })
+  })
+
+  describe('Progress Tracking Detection', () => {
+    it('should detect REFACTOR-PROGRESS.md reference', () => {
+      const content = 'Create REFACTOR-PROGRESS.md to track work.'
+      const analysis = parseContent(content)
+
+      const progress = analysis.constructs.filter((c) => c.type === 'progress-tracking')
+      expect(progress.length).to.be.greaterThan(0)
+      expect(progress[0]?.parsed?.hasProgressFile).to.be.true
+    })
+
+    it('should detect checklist items', () => {
+      const content = '- [x] Step 1 completed\n- [ ] Step 2 pending'
+      const analysis = parseContent(content)
+
+      const progress = analysis.constructs.filter((c) => c.type === 'progress-tracking')
+      expect(progress.length).to.be.greaterThan(0)
+      expect(progress[0]?.parsed?.hasChecklist).to.be.true
+    })
+
+    it('should detect Progress Tracking header', () => {
+      const content = '## Progress Tracking\n\nTrack completion here.'
+      const analysis = parseContent(content)
+
+      const progress = analysis.constructs.filter((c) => c.type === 'progress-tracking')
+      expect(progress.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Workspace Command Detection', () => {
+    it('should detect @workspace command', () => {
+      const content = 'Use @workspace to search the codebase.'
+      const analysis = parseContent(content)
+
+      const workspace = analysis.constructs.filter((c) => c.type === 'workspace-command')
+      expect(workspace.length).to.be.greaterThan(0)
+    })
+
+    it('should detect @workspace analyze', () => {
+      const content = '@workspace analyze database access patterns.'
+      const analysis = parseContent(content)
+
+      const workspace = analysis.constructs.filter((c) => c.type === 'workspace-command')
+      expect(workspace.length).to.be.greaterThan(0)
+      expect(workspace[0]?.parsed?.action).to.equal('analyze')
+    })
+
+    it('should detect @workspace find', () => {
+      const content = '@workspace find all API endpoints.'
+      const analysis = parseContent(content)
+
+      const workspace = analysis.constructs.filter((c) => c.type === 'workspace-command')
+      expect(workspace.length).to.be.greaterThan(0)
+      expect(workspace[0]?.parsed?.action).to.equal('find')
+    })
+  })
+
+  describe('Test Command Detection', () => {
+    it('should detect npm test', () => {
+      const content = 'Run npm test to verify changes.'
+      const analysis = parseContent(content)
+
+      const tests = analysis.constructs.filter((c) => c.type === 'test-command')
+      expect(tests.length).to.be.greaterThan(0)
+      expect(tests[0]?.parsed?.framework).to.equal('npm')
+    })
+
+    it('should detect pytest', () => {
+      const content = 'Execute pytest for Python tests.'
+      const analysis = parseContent(content)
+
+      const tests = analysis.constructs.filter((c) => c.type === 'test-command')
+      expect(tests.length).to.be.greaterThan(0)
+      expect(tests[0]?.parsed?.framework).to.equal('pytest')
+    })
+
+    it('should detect jest', () => {
+      const content = 'Run jest for unit tests.'
+      const analysis = parseContent(content)
+
+      const tests = analysis.constructs.filter((c) => c.type === 'test-command')
+      expect(tests.length).to.be.greaterThan(0)
+      expect(tests[0]?.parsed?.framework).to.equal('jest')
+    })
+
+    it('should detect vitest', () => {
+      const content = 'Using vitest for modern testing.'
+      const analysis = parseContent(content)
+
+      const tests = analysis.constructs.filter((c) => c.type === 'test-command')
+      expect(tests.length).to.be.greaterThan(0)
+      expect(tests[0]?.parsed?.framework).to.equal('vitest')
+    })
+  })
+
+  describe('Advisory Warning Detection', () => {
+    it('should detect "not enforced" warning', () => {
+      const content = 'NOTE: These restrictions are not enforced by platform.'
+      const analysis = parseContent(content)
+
+      const warnings = analysis.constructs.filter((c) => c.type === 'advisory-warning')
+      expect(warnings.length).to.be.greaterThan(0)
+      expect(warnings[0]?.parsed?.isEnforcementWarning).to.be.true
+    })
+
+    it('should detect emulated pattern', () => {
+      const content = 'This behavior is emulated on this platform.'
+      const analysis = parseContent(content)
+
+      const warnings = analysis.constructs.filter((c) => c.type === 'advisory-warning')
+      expect(warnings.length).to.be.greaterThan(0)
+      expect(warnings[0]?.parsed?.isEmulationWarning).to.be.true
+    })
+
+    it('should detect "not supported" warning', () => {
+      const content = 'This feature is not supported here.'
+      const analysis = parseContent(content)
+
+      const warnings = analysis.constructs.filter((c) => c.type === 'advisory-warning')
+      expect(warnings.length).to.be.greaterThan(0)
+      expect(warnings[0]?.parsed?.isLimitationWarning).to.be.true
+    })
+  })
+
+  describe('Version Comment Detection', () => {
+    it('should detect Version comment', () => {
+      const content = '<!-- Version: 1.0.0 -->\n\nContent here.'
+      const analysis = parseContent(content)
+
+      const versions = analysis.constructs.filter((c) => c.type === 'version-comment')
+      expect(versions.length).to.be.greaterThan(0)
+      expect(versions[0]?.parsed?.version).to.equal('1.0.0')
+    })
+
+    it('should detect Part comment', () => {
+      const content = '<!-- Part 2 of 4: API Routes -->\n\nContent.'
+      const analysis = parseContent(content)
+
+      const versions = analysis.constructs.filter((c) => c.type === 'version-comment')
+      expect(versions.length).to.be.greaterThan(0)
+      expect(versions[0]?.parsed?.currentPart).to.equal(2)
+      expect(versions[0]?.parsed?.totalParts).to.equal(4)
+    })
+
+    it('should detect Adapted from comment', () => {
+      const content = '<!-- Adapted from Claude Code skill -->\n\nWorkflow.'
+      const analysis = parseContent(content)
+
+      const versions = analysis.constructs.filter((c) => c.type === 'version-comment')
+      expect(versions.length).to.be.greaterThan(0)
+    })
+  })
+
+  describe('Execution Flow Section Detection', () => {
+    it('should detect Execution Flow header', () => {
+      const content = '## Execution Flow\n\n1. First step...'
+      const analysis = parseContent(content)
+
+      const flows = analysis.constructs.filter((c) => c.type === 'execution-flow-section')
+      expect(flows.length).to.be.greaterThan(0)
+      expect(flows[0]?.parsed?.sectionType).to.equal('execution-flow')
+    })
+
+    it('should detect Step-by-Step Execution', () => {
+      const content = '### Step-by-Step Execution\n\nDetailed steps.'
+      const analysis = parseContent(content)
+
+      const flows = analysis.constructs.filter((c) => c.type === 'execution-flow-section')
+      expect(flows.length).to.be.greaterThan(0)
+      expect(flows[0]?.parsed?.sectionType).to.equal('step-by-step')
+    })
+
+    it('should detect Verification Points', () => {
+      const content = '## Verification Points\n\nCheck these conditions.'
+      const analysis = parseContent(content)
+
+      const flows = analysis.constructs.filter((c) => c.type === 'execution-flow-section')
+      expect(flows.length).to.be.greaterThan(0)
+      expect(flows[0]?.parsed?.sectionType).to.equal('verification-points')
+    })
+  })
+
+  describe('Utility Functions', () => {
+    describe('hasSemanticConstructs', () => {
+      it('should return true for content with constructs', () => {
+        const content = 'Use the Glob tool here.'
+        expect(hasSemanticConstructs(content)).to.be.true
+      })
+
+      it('should return false for plain content', () => {
+        // Very minimal content unlikely to match anything
+        const content = 'Hello world'
+        expect(hasSemanticConstructs(content)).to.be.false
+      })
+    })
+
+    describe('getConstructsByPlatform', () => {
+      it('should filter constructs by platform', () => {
+        const content = `Use the Glob tool (Claude Code).
+@workspace search (Copilot).
+USE WHEN creating commits (Windsurf).`
+
+        const analysis = parseContent(content)
+
+        const claudeConstructs = getConstructsByPlatform(analysis, 'claude-code')
+        const copilotConstructs = getConstructsByPlatform(analysis, 'github-copilot')
+        const windsurfConstructs = getConstructsByPlatform(analysis, 'windsurf')
+
+        expect(claudeConstructs.every((c) => c.platform === 'claude-code')).to.be.true
+        expect(copilotConstructs.every((c) => c.platform === 'github-copilot')).to.be.true
+        expect(windsurfConstructs.every((c) => c.platform === 'windsurf')).to.be.true
+      })
+    })
+
+    describe('getConstructsByType', () => {
+      it('should filter constructs by type', () => {
+        const content = `Use Glob tool and Read tool.
+Also spawn agent.`
+
+        const analysis = parseContent(content)
+
+        const toolCalls = getConstructsByType(analysis, 'tool-call')
+        expect(toolCalls.every((c) => c.type === 'tool-call')).to.be.true
+      })
+    })
+
+    describe('getConstructTypes', () => {
+      it('should return all construct types', () => {
+        const types = getConstructTypes()
+
+        expect(types).to.include('agent-spawn')
+        expect(types).to.include('tool-call')
+        expect(types).to.include('context-switch')
+        expect(types).to.include('model-decision-trigger')
+        expect(types.length).to.equal(18) // All 18 construct types
+      })
+    })
+
+    describe('getSourcePlatform', () => {
+      it('should return correct platform for each type', () => {
+        expect(getSourcePlatform('agent-spawn')).to.equal('claude-code')
+        expect(getSourcePlatform('model-decision-trigger')).to.equal('windsurf')
+        expect(getSourcePlatform('workspace-command')).to.equal('github-copilot')
+      })
+    })
+  })
+
+  describe('Edge Cases', () => {
+    it('should handle empty content', () => {
+      const analysis = parseContent('')
+      expect(analysis.constructs).to.be.an('array').that.is.empty
+      expect(analysis.rawContent).to.equal('')
+    })
+
+    it('should handle content with only code blocks', () => {
+      const content = `\`\`\`typescript
+Use Glob tool here
+spawn agent
+npm test
+\`\`\``
+
+      const analysis = parseContent(content)
+      // All constructs should be skipped as they are in code block
+      expect(analysis.constructs.length).to.equal(0)
+    })
+
+    it('should handle nested code blocks correctly', () => {
+      const content = `Outside: npm test
+
+\`\`\`markdown
+Inside markdown code block: npm test
+\`\`\`
+
+Outside again: jest`
+
+      const analysis = parseContent(content)
+
+      // Should detect the outside instances but not the inside one
+      const tests = analysis.constructs.filter((c) => c.type === 'test-command')
+      expect(tests.length).to.be.greaterThan(0)
+
+      // Verify no match is from inside the code block
+      for (const test of tests) {
+        const codeBlockStart = content.indexOf('```markdown')
+        const codeBlockEnd = content.indexOf('```', codeBlockStart + 10) + 3
+        expect(
+          test.location.start < codeBlockStart || test.location.start >= codeBlockEnd,
+          'Match should not be from inside code block',
+        ).to.be.true
+      }
+    })
+
+    it('should handle multiple constructs on same line', () => {
+      const content = 'Use Glob tool then npm test'
+
+      const analysis = parseContent(content)
+
+      expect(analysis.constructs.length).to.be.at.least(2)
+    })
+
+    it('should handle multi-line patterns', () => {
+      const content = `Part 1 of 3: Introduction
+
+This is the first part.
+
+Part 2 of 3: Implementation
+
+This is the second part.`
+
+      const analysis = parseContent(content)
+
+      const chains = analysis.constructs.filter((c) => c.type === 'skill-chaining')
+      expect(chains.length).to.equal(2)
+    })
+
+    it('should prefer longer/more specific matches when overlapping', () => {
+      // "Use the Glob tool" should match as tool-call, not just generic patterns
+      const content = 'Use the Glob tool to find TypeScript files.'
+
+      const analysis = parseContent(content)
+
+      const toolCalls = analysis.constructs.filter((c) => c.type === 'tool-call')
+      expect(toolCalls.length).to.be.greaterThan(0)
+      expect(toolCalls[0]?.rawText).to.include('Glob tool')
+    })
+  })
+})
diff --git a/packages/cli/test/lib/template-mapper/content-transformers.test.ts b/packages/cli/test/lib/template-mapper/content-transformers.test.ts
new file mode 100644
index 0000000..3c61829
--- /dev/null
+++ b/packages/cli/test/lib/template-mapper/content-transformers.test.ts
@@ -0,0 +1,579 @@
+import {expect} from 'chai'
+import {describe, it} from 'mocha'
+
+import {parseContent} from '../../../src/lib/template-mapper/content-parser.js'
+import {
+  ClaudeCodeContentTransformer,
+  WindsurfContentTransformer,
+  CopilotContentTransformer,
+  createContentTransformer,
+} from '../../../src/lib/template-mapper/content-transformers.js'
+
+describe('Content Transformers', () => {
+  describe('ClaudeCodeContentTransformer', () => {
+    const transformer = new ClaudeCodeContentTransformer()
+
+    it('should have correct platform identifier', () => {
+      expect(transformer.platform).to.equal('claude-code')
+    })
+
+    it('should pass through Claude Code native constructs unchanged', () => {
+      const content = `Use the Glob tool to find files.
+Then spawn a new agent to handle analysis.
+Set context: fork for isolation.`
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      // Native constructs should remain unchanged
+      expect(result.content).to.include('Use the Glob tool')
+      expect(result.content).to.include('spawn a new agent')
+      expect(result.content).to.include('context: fork')
+    })
+
+    it('should convert @workspace commands to tool-based search', () => {
+      const content = 'Use @workspace to search for authentication patterns.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.not.include('@workspace')
+      expect(result.content).to.include('Search')
+      expect(result.warnings).to.have.lengthOf.at.least(1)
+      expect(result.warnings.some((w) => w.category === 'EMULATED')).to.be.true
+    })
+
+    it('should convert Copilot /prompt format to /skill-name', () => {
+      const content = `After completion, run:
+/prompt refactor-auth`
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('/refactor-auth')
+      expect(result.content).to.not.include('/prompt refactor-auth')
+    })
+
+    it('should warn about Windsurf-specific globs field', () => {
+      const content = 'Set globs: ["src/**/*.ts"] for context gathering.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.warnings.some((w) =>
+        w.category === 'UNSUPPORTED' && w.message.includes('globs'),
+      )).to.be.true
+    })
+
+    it('should warn about working set limits not applying', () => {
+      const content = 'GitHub Copilot has a 10-file limit in working set.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.warnings.some((w) =>
+        w.category === 'UNSUPPORTED' && w.message.includes('Working set'),
+      )).to.be.true
+    })
+
+    it('should convert Windsurf @rules:agent- to agent reference', () => {
+      const content = 'First, activate @rules:agent-security-specialist.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('security-specialist agent')
+      expect(result.warnings.some((w) => w.category === 'EMULATED')).to.be.true
+    })
+  })
+
+  describe('WindsurfContentTransformer', () => {
+    const transformer = new WindsurfContentTransformer()
+
+    it('should have correct platform identifier', () => {
+      expect(transformer.platform).to.equal('windsurf')
+    })
+
+    it('should convert agent spawning to sequential execution', () => {
+      const content = 'Then spawn agent to handle security review.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('Execute the following')
+      expect(result.content).to.include('sequentially')
+      expect(result.content).to.include('NOTE')
+      expect(result.content).to.include('Subagent spawning not available')
+      expect(result.warnings.some((w) =>
+        w.category === 'EMULATED' && w.message.includes('sequential'),
+      )).to.be.true
+    })
+
+    it('should rephrase tool calls as action descriptions', () => {
+      const content = 'Use the Glob tool to find TypeScript files.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('Find files using pattern search')
+      expect(result.content).to.not.include('Glob tool')
+    })
+
+    it('should transform Grep tool calls with parameters', () => {
+      // Use a pattern that matches the tool-call detection
+      const content = 'Use the Grep tool to search for patterns'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      // Should convert to natural language
+      expect(result.content).to.include('Search file contents')
+      expect(result.warnings.some((w) =>
+        w.category === 'EMULATED' && w.message.includes('Tool call'),
+      )).to.be.true
+    })
+
+    it('should replace context switch with Cascade session note', () => {
+      const content = 'Run in isolated context for safety.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('current Cascade session')
+      expect(result.content).to.include('no isolation available')
+    })
+
+    it('should add advisory note to permission references', () => {
+      const content = 'Set allowed-tools to restrict operations.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('NOTE')
+      expect(result.content).to.include('AI compliance')
+      expect(result.warnings.some((w) => w.category === 'SECURITY')).to.be.true
+    })
+
+    it('should pass through Windsurf-native globs without transformation', () => {
+      const content = 'Uses globs: ["**/*.ts"] for file matching.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      // Native constructs should remain
+      expect(result.content).to.include('globs:')
+    })
+
+    it('should pass through model_decision trigger', () => {
+      const content = 'Set trigger: model_decision for auto-activation.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('trigger: model_decision')
+    })
+
+    it('should convert @workspace to natural language', () => {
+      const content = '@workspace find all API endpoints.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.not.include('@workspace')
+      expect(result.content).to.include('find')
+    })
+
+    it('should remove Step 0 context gathering protocol', () => {
+      const content = 'Step 0: Gather context before starting.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.not.include('Step 0')
+      expect(result.warnings.some((w) =>
+        w.message.includes('Step 0') && w.message.includes('removed'),
+      )).to.be.true
+    })
+
+    it('should convert /prompt format to /workflow-name', () => {
+      const content = `Next step:
+/prompt refactor-utils`
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('/refactor-utils')
+      expect(result.content).to.not.include('/prompt refactor-utils')
+    })
+  })
+
+  describe('CopilotContentTransformer', () => {
+    const transformer = new CopilotContentTransformer()
+
+    it('should have correct platform identifier', () => {
+      expect(transformer.platform).to.equal('github-copilot')
+    })
+
+    it('should convert agent spawning to manual handoff', () => {
+      const content = 'Then spawn agent to handle security review.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('Manual Handoff')
+      expect(result.content).to.include('separate chat session')
+      expect(result.content).to.include('NOTE')
+      expect(result.content).to.include('GitHub Copilot does not support')
+    })
+
+    it('should generalize tool calls to recommendations', () => {
+      const content = 'Use the Glob tool to find files.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('Search for files matching patterns')
+      expect(result.content).to.not.include('Glob tool')
+    })
+
+    it('should remove context switch references entirely', () => {
+      const content = 'Run in isolated context for safety.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.not.include('isolated context')
+      expect(result.warnings.some((w) =>
+        w.category === 'UNSUPPORTED' && w.message.includes('isolation'),
+      )).to.be.true
+    })
+
+    it('should add working set notes to glob patterns', () => {
+      const content = 'Set globs: ["**/*.ts"] for context.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('10-file limit')
+      expect(result.content).to.include('applyTo')
+    })
+
+    it('should convert /skill-name to /prompt name format', () => {
+      const content = `Next step:
+/refactor-auth`
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('/prompt refactor-auth')
+    })
+
+    it('should pass through @workspace commands natively', () => {
+      const content = '@workspace find all API endpoints.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      // @workspace is native to Copilot
+      expect(result.content).to.include('@workspace')
+    })
+
+    it('should pass through working set limit references', () => {
+      const content = 'Respect the 10-file limit in working set.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('10-file limit')
+    })
+
+    it('should add batch instructions to context gathering', () => {
+      const content = '### Context Gathering Protocol\n\nGather all files.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      // Context gathering should include limit/batch notes
+      expect(result.content).to.include('Context Limit')
+      expect(result.warnings.some((w) => w.category === 'LIMIT')).to.be.true
+    })
+
+    it('should convert @rules:agent- to natural language', () => {
+      const content = 'Activate @rules:agent-security-specialist first.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('Act as a security specialist')
+      expect(result.content).to.not.include('@rules:agent-')
+    })
+
+    it('should convert trigger: model_decision to infer recommendation', () => {
+      const content = 'Set trigger: model_decision for activation.'
+
+      const analysis = parseContent(content)
+      const result = transformer.transform(analysis, content)
+
+      expect(result.warnings.some((w) =>
+        w.message.includes('infer'),
+      )).to.be.true
+    })
+  })
+
+  describe('createContentTransformer factory', () => {
+    it('should create ClaudeCodeContentTransformer for claude-code', () => {
+      const transformer = createContentTransformer('claude-code')
+      expect(transformer.platform).to.equal('claude-code')
+      expect(transformer).to.be.instanceOf(ClaudeCodeContentTransformer)
+    })
+
+    it('should create WindsurfContentTransformer for windsurf', () => {
+      const transformer = createContentTransformer('windsurf')
+      expect(transformer.platform).to.equal('windsurf')
+      expect(transformer).to.be.instanceOf(WindsurfContentTransformer)
+    })
+
+    it('should create CopilotContentTransformer for github-copilot', () => {
+      const transformer = createContentTransformer('github-copilot')
+      expect(transformer.platform).to.equal('github-copilot')
+      expect(transformer).to.be.instanceOf(CopilotContentTransformer)
+    })
+
+    it('should throw for unknown platform', () => {
+      expect(() => createContentTransformer('unknown' as any)).to.throw('Unknown platform')
+    })
+  })
+
+  describe('Warning Generation', () => {
+    it('should generate warnings for emulated constructs on Windsurf', () => {
+      const content = `Use the Glob tool to find files.
+Then spawn a new agent.
+Run in isolated context.`
+
+      const analysis = parseContent(content)
+      const transformer = new WindsurfContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      const emulatedWarnings = result.warnings.filter((w) => w.category === 'EMULATED')
+      expect(emulatedWarnings.length).to.be.greaterThan(0)
+    })
+
+    it('should generate warnings for unsupported constructs on Copilot', () => {
+      const content = 'Run in isolated context for safety.'
+
+      const analysis = parseContent(content)
+      const transformer = new CopilotContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      const unsupportedWarnings = result.warnings.filter((w) => w.category === 'UNSUPPORTED')
+      expect(unsupportedWarnings.length).to.be.greaterThan(0)
+    })
+
+    it('should generate security warnings for permission references', () => {
+      const content = 'Set allowed-tools to restrict access.'
+
+      const analysis = parseContent(content)
+
+      const windsurfTransformer = new WindsurfContentTransformer()
+      const windsurfResult = windsurfTransformer.transform(analysis, content)
+      expect(windsurfResult.warnings.some((w) => w.category === 'SECURITY')).to.be.true
+
+      const copilotTransformer = new CopilotContentTransformer()
+      const copilotResult = copilotTransformer.transform(analysis, content)
+      expect(copilotResult.warnings.some((w) => w.category === 'SECURITY')).to.be.true
+    })
+
+    it('should generate limit warnings for glob patterns on Copilot', () => {
+      const content = 'Use globs: ["**/*.ts"] for comprehensive search.'
+
+      const analysis = parseContent(content)
+      const transformer = new CopilotContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      expect(result.warnings.some((w) => w.category === 'LIMIT')).to.be.true
+    })
+  })
+
+  describe('Edge Cases', () => {
+    it('should handle empty content', () => {
+      const content = ''
+      const analysis = parseContent(content)
+
+      const claudeTransformer = new ClaudeCodeContentTransformer()
+      const claudeResult = claudeTransformer.transform(analysis, content)
+      expect(claudeResult.content).to.equal('')
+      expect(claudeResult.warnings).to.be.an('array')
+
+      const windsurfTransformer = new WindsurfContentTransformer()
+      const windsurfResult = windsurfTransformer.transform(analysis, content)
+      expect(windsurfResult.content).to.equal('')
+
+      const copilotTransformer = new CopilotContentTransformer()
+      const copilotResult = copilotTransformer.transform(analysis, content)
+      expect(copilotResult.content).to.equal('')
+    })
+
+    it('should handle content with no semantic constructs', () => {
+      const content = 'This is plain markdown with no special constructs.'
+
+      const analysis = parseContent(content)
+
+      const transformer = new WindsurfContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.equal(content)
+      expect(result.warnings).to.be.an('array')
+    })
+
+    it('should handle multiple constructs on same line', () => {
+      const content = 'Use Glob tool then spawn agent for analysis.'
+
+      const analysis = parseContent(content)
+      const transformer = new WindsurfContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      // Both constructs should be transformed
+      expect(result.content).to.not.include('Glob tool')
+      expect(result.content).to.not.include('spawn agent')
+      expect(result.warnings.length).to.be.greaterThan(1)
+    })
+
+    it('should preserve non-construct content', () => {
+      const content = `# Workflow Title
+
+This is a description paragraph.
+
+## Steps
+
+1. Use the Glob tool to find files.
+2. Process the results.
+3. Generate output.
+
+## Notes
+
+Some additional information here.`
+
+      const analysis = parseContent(content)
+      const transformer = new WindsurfContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      // Structure should be preserved
+      expect(result.content).to.include('# Workflow Title')
+      expect(result.content).to.include('## Steps')
+      expect(result.content).to.include('## Notes')
+      expect(result.content).to.include('Process the results')
+      expect(result.content).to.include('Generate output')
+    })
+
+    it('should not double-replace overlapping constructs', () => {
+      const content = 'Use the Task tool to spawn a subagent.'
+
+      const analysis = parseContent(content)
+      const transformer = new WindsurfContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      // Should transform coherently without mangling
+      expect(result.content).to.be.a('string')
+      expect(result.content.length).to.be.greaterThan(0)
+    })
+
+    it('should handle constructs at beginning of content', () => {
+      const content = 'spawn agent for review, then proceed.'
+
+      const analysis = parseContent(content)
+      const transformer = new WindsurfContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('Execute')
+      expect(result.content).to.include('then proceed')
+    })
+
+    it('should handle constructs at end of content', () => {
+      const content = 'After analysis, spawn agent'
+
+      const analysis = parseContent(content)
+      const transformer = new WindsurfContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('After analysis')
+    })
+  })
+
+  describe('Advisory Section Generation for Windsurf', () => {
+    it('should add proper advisory notes for tool restrictions', () => {
+      const content = 'Set allowed-tools: Read, Glob only.'
+
+      const analysis = parseContent(content)
+      const transformer = new WindsurfContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('NOTE')
+      expect(result.content).to.include('AI compliance')
+      expect(result.content).to.include('NOT enforced')
+    })
+  })
+
+  describe('Context Decomposition for Copilot', () => {
+    it('should handle large context references with batch instructions', () => {
+      const content = `### Context Gathering Protocol
+
+Gather comprehensive context from:
+- All API routes
+- Database models
+- Service layer
+- Utility functions
+- Test files`
+
+      const analysis = parseContent(content)
+      const transformer = new CopilotContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      // Context gathering should include limit/batch notes
+      expect(result.content).to.include('Context Limit')
+      expect(result.warnings.some((w) => w.category === 'LIMIT')).to.be.true
+    })
+
+    it('should handle multi-part workflows with batch notes', () => {
+      const content = 'Part 1 of 5: Initial Analysis'
+
+      const analysis = parseContent(content)
+      const transformer = new CopilotContentTransformer()
+      const result = transformer.transform(analysis, content)
+
+      expect(result.content).to.include('smaller batches')
+    })
+  })
+
+  describe('Integration with Platform Adapters', () => {
+    it('should work with parsed content from content-parser', () => {
+      const content = `# Security Review Workflow
+
+Use the Glob tool to find authentication files.
+Then spawn agent to review security patterns.
+Set context: fork for isolated analysis.`
+
+      // Parse content
+      const analysis = parseContent(content)
+
+      // Claude Code - mostly pass through
+      const claudeTransformer = new ClaudeCodeContentTransformer()
+      const claudeResult = claudeTransformer.transform(analysis, content)
+      expect(claudeResult.content).to.include('Glob tool')
+      expect(claudeResult.content).to.include('spawn agent')
+
+      // Windsurf - transform constructs
+      const windsurfTransformer = new WindsurfContentTransformer()
+      const windsurfResult = windsurfTransformer.transform(analysis, content)
+      expect(windsurfResult.content).to.include('Find files')
+      expect(windsurfResult.content).to.include('sequentially')
+      expect(windsurfResult.content).to.include('Cascade session')
+
+      // Copilot - different transformations
+      const copilotTransformer = new CopilotContentTransformer()
+      const copilotResult = copilotTransformer.transform(analysis, content)
+      expect(copilotResult.content).to.include('Manual Handoff')
+      // Glob tool is transformed to recommendation
+      expect(copilotResult.content).to.include('Search for files matching patterns')
+    })
+  })
+})
diff --git a/packages/cli/test/lib/template-mapper/parser.test.ts b/packages/cli/test/lib/template-mapper/parser.test.ts
new file mode 100644
index 0000000..d3fa51d
--- /dev/null
+++ b/packages/cli/test/lib/template-mapper/parser.test.ts
@@ -0,0 +1,293 @@
+import {expect} from 'chai'
+import {describe, it} from 'mocha'
+
+import {
+  parseTemplateString,
+  isValidTemplate,
+  extractFrontmatter,
+  ParseError,
+} from '../../../src/lib/template-mapper/parser.js'
+
+describe('Template Parser', () => {
+  describe('parseTemplateString', () => {
+    it('should parse a valid template with frontmatter', () => {
+      const content = `---
+name: test-skill
+description: A test skill
+version: "1.0.0"
+---
+
+# Test Content
+
+This is the body.`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.name).to.equal('test-skill')
+      expect(result.metadata.description).to.equal('A test skill')
+      expect(result.metadata.version).to.equal('1.0.0')
+      expect(result.content).to.include('# Test Content')
+      expect(result.content).to.include('This is the body.')
+    })
+
+    it('should parse allowed-tools as array', () => {
+      const content = `---
+name: tool-test
+allowed-tools:
+  - Read
+  - Write
+  - Bash(git *)
+---
+
+Content`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata['allowed-tools']).to.deep.equal([
+        'Read',
+        'Write',
+        'Bash(git *)',
+      ])
+    })
+
+    it('should normalize comma-separated applyTo to array', () => {
+      const content = `---
+name: apply-test
+applyTo: "**/*.ts,**/*.tsx"
+---
+
+Content`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.applyTo).to.deep.equal(['**/*.ts', '**/*.tsx'])
+    })
+
+    it('should parse Windsurf-specific fields', () => {
+      const content = `---
+description: Test workflow
+trigger: model_decision
+globs:
+  - "**/*.py"
+labels:
+  - python
+  - testing
+alwaysApply: false
+author: "Test Author"
+---
+
+Content`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.trigger).to.equal('model_decision')
+      expect(result.metadata.globs).to.deep.equal(['**/*.py'])
+      expect(result.metadata.labels).to.deep.equal(['python', 'testing'])
+      expect(result.metadata.alwaysApply).to.equal(false)
+      expect(result.metadata.author).to.equal('Test Author')
+    })
+
+    it('should parse GitHub Copilot-specific fields', () => {
+      const content = `---
+description: Test prompt
+applyTo:
+  - "**/*.ts"
+excludeAgent:
+  - code-review
+mode: agent
+---
+
+Content`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.applyTo).to.deep.equal(['**/*.ts'])
+      expect(result.metadata.excludeAgent).to.deep.equal(['code-review'])
+      expect(result.metadata.mode).to.equal('agent')
+    })
+
+    it('should parse Claude Code permissions', () => {
+      const content = `---
+name: secure-skill
+permissions:
+  allow:
+    - Read(**/*.ts)
+    - Write(src/**)
+  deny:
+    - Read(.env)
+    - Write(config/production.json)
+---
+
+Content`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.permissions?.allow).to.deep.equal([
+        'Read(**/*.ts)',
+        'Write(src/**)',
+      ])
+      expect(result.metadata.permissions?.deny).to.deep.equal([
+        'Read(.env)',
+        'Write(config/production.json)',
+      ])
+    })
+
+    it('should parse cross-platform fields', () => {
+      const content = `---
+name: cross-platform-skill
+platforms:
+  - claude-code
+  - windsurf
+compatibility:
+  claude-code:
+    status: full
+    notes: "Full support"
+  windsurf:
+    status: partial
+    notes: "Emulated"
+---
+
+Content`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.platforms).to.deep.equal(['claude-code', 'windsurf'])
+      expect(result.metadata.compatibility?.['claude-code']?.status).to.equal('full')
+      expect(result.metadata.compatibility?.windsurf?.status).to.equal('partial')
+    })
+
+    it('should parse context field correctly', () => {
+      const content = `---
+name: forked-skill
+context: fork
+---
+
+Content`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.context).to.equal('fork')
+    })
+
+    it('should throw ParseError for missing frontmatter', () => {
+      const content = `# No Frontmatter
+
+This template has no frontmatter.`
+
+      expect(() => parseTemplateString(content)).to.throw(ParseError)
+      expect(() => parseTemplateString(content)).to.throw(/must start with YAML frontmatter/)
+    })
+
+    it('should throw ParseError for invalid YAML', () => {
+      // YAML with explicit syntax error (duplicate key with inconsistent indent)
+      const content = `---
+name: broken
+name:
+  - invalid structure
+---
+
+Content`
+
+      expect(() => parseTemplateString(content)).to.throw(ParseError, /Invalid YAML/)
+    })
+
+    it('should handle empty content after frontmatter', () => {
+      const content = `---
+name: empty-body
+---
+`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.name).to.equal('empty-body')
+      expect(result.content).to.equal('')
+    })
+
+    it('should warn for missing description but not throw', () => {
+      const content = `---
+name: no-description
+---
+
+Content`
+
+      // Should not throw - description is recommended but not required
+      const result = parseTemplateString(content)
+      expect(result.metadata.name).to.equal('no-description')
+    })
+
+    it('should filter invalid platform values', () => {
+      const content = `---
+name: invalid-platform
+platforms:
+  - claude-code
+  - invalid-platform
+  - windsurf
+---
+
+Content`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.platforms).to.deep.equal(['claude-code', 'windsurf'])
+    })
+
+    it('should parse model and agent fields', () => {
+      const content = `---
+name: model-test
+model: opus
+agent: custom-reviewer
+---
+
+Content`
+
+      const result = parseTemplateString(content)
+
+      expect(result.metadata.model).to.equal('opus')
+      expect(result.metadata.agent).to.equal('custom-reviewer')
+    })
+  })
+
+  describe('isValidTemplate', () => {
+    it('should return true for valid template', () => {
+      const content = `---
+name: valid
+---
+Content`
+
+      expect(isValidTemplate(content)).to.be.true
+    })
+
+    it('should return false for content without frontmatter', () => {
+      expect(isValidTemplate('# Just markdown')).to.be.false
+      expect(isValidTemplate('No frontmatter here')).to.be.false
+    })
+
+    it('should return false for incomplete frontmatter', () => {
+      expect(isValidTemplate('---\nname: incomplete')).to.be.false
+      expect(isValidTemplate('---')).to.be.false
+    })
+  })
+
+  describe('extractFrontmatter', () => {
+    it('should extract frontmatter data', () => {
+      const content = `---
+name: extract-test
+version: "2.0.0"
+---
+
+Content`
+
+      const data = extractFrontmatter(content)
+
+      expect(data).to.not.be.null
+      expect(data?.name).to.equal('extract-test')
+      expect(data?.version).to.equal('2.0.0')
+    })
+
+    it('should return empty object for content without frontmatter', () => {
+      // gray-matter returns empty object for content without frontmatter delimiters
+      const result = extractFrontmatter('not valid yaml frontmatter')
+      expect(result).to.deep.equal({})
+    })
+  })
+})
